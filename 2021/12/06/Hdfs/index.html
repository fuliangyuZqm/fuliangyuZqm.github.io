<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Hdfs, fuliangyu">
    <meta name="description" content="基础架构
使用场景：一次写入，多次读取，适合数据分析，不适合多次修改
HDFS（Hadoop Distributed File System）是一个开源系统，可以满足大文件处理的需求和流式数据的访问，可进行文件存储与传递，并且允许文件通过网">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Hdfs | fuliangyu</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">fuliangyu</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-image" style="zoom: 0.6;"></i>
      
      <span>相册</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">fuliangyu</div>
        <div class="logo-desc">
            
            blog
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-image"></i>
			
			相册
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/fuliangyuZqm/fuliangyuZqm.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/fuliangyuZqm/fuliangyuZqm.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/17.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Hdfs</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Hdfs/">
                                <span class="chip bg-color">Hdfs</span>
                            </a>
                        
                            <a href="/tags/Hadoop/">
                                <span class="chip bg-color">Hadoop</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Hadoop/" class="post-category">
                                Hadoop
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-12-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-02-23
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    16.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    58 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h2><blockquote>
<p>使用场景：一次写入，多次读取，适合数据分析，不适合多次修改</p>
<p>HDFS（Hadoop Distributed File System）是一个开源系统，可以满足大文件处理的需求和流式数据的访问，可进行文件存储与传递，并且允许文件通过网络在多台主机上进行共享。HDFS文件系统主要分为两部分：NameNode、SecondaryNameNode(StandByNameNode)和DataNode。</p>
<p>HDFS的主要特点包括：</p>
<ol>
<li>存取超大文件；</li>
<li>流式数据访问，即数据批量读取；</li>
<li>检测和快速应对硬件故障（高可用）；</li>
<li>简单一致模型，即为了降低系统复杂度，对文件采用一次性多次读写的逻辑设计，即文件一旦写入、关闭，就再也不能修改—–（追加式写入）；</li>
<li>程序采用数据就近原则分配节点执行（选择最近的节点副本数据返回给读文件的客户端）；</li>
<li>高容错性：数据自动保存多个副本，副本丢失后自动恢复。</li>
</ol>
</blockquote>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>HDFS采用主从架构进行管理，一个HDFS集群具有一个NameNode，一个SecondaryNode（StandByNameNode），至少一个DataNode，这些节点分别承担Master和Worker的任务。</p>
<ul>
<li><p>NameNode（名字节点）：相当于HDFS的核心大脑。它用于存储HDFS的元数据（数据的数据，包括文件目录、文件名、文件属性等）、管理文件系统的命名空间以及保存整个文件系统的空间命名镜像（也称文件系统镜像FSImage），也就是说Namenode负责保存整个hdfs系统的目录树和存放在目录树的文件信息以及保存有空间命名镜像的编辑日志（EditLogs），客户端请求写入数据或者更改移动复制文件是，NameNode只对元数据操作记录而不对数据块操作记录，从NameNode中可以获得每个文件每个块所在的DataNode，但是这些信息不会永久存储，NameNode会在每次系统启动时动态重建这些信息。</p>
</li>
<li><p>SecondaryNode（第二名字节点）：由于整个文件系统比较庞大，读写数据比较多，因此空间命名镜像会越变越大，频繁对其进行操作会使系统运行变慢。于是HDFS将每一次对数据节点的操作都记录在NameNode的空间命名镜像的编辑日志（editLog）里，SecondaryNode负责定期合并FSImage和编辑日志（editLog）。SecondaryNode通常运行在另一台机器上，因为合并操作需要耗费大量的CPU时间以及和NameNode相当的内存，并且是定时合并，所以它的据落一定后于NameNode；当NameNode完全崩溃时，会出现数据丢失。通常解决方法是拷贝NFS中的备份元数据到SecondaryNode，将其作为新的主NameNode</p>
</li>
</ul>
<blockquote>
<p>从以上描述中可以看出：SecondaryNode并不能被用作NameNode，只是，在活动NameNode故障之后，替代原有NameNode成为新的活动NameNode  ——— 相当于冷备（会丢数据）</p>
</blockquote>
<ul>
<li>DataNode（数据节点）：是HDFS主从架构的从角色、文件系统的工作节点、存储文件数据块的节点。在NameNode的命令下进行I/O任务、存储和提取块，响应客户端的一系列数据操作，并且DataNode会周期性地向NameNode汇报自身存储的数据块信息，更新NameNode中的元数据信息，接受NameNode的指令，完成对存储数据块的操作</li>
</ul>
<p><img src="/images/image-20201217153642584.png" alt="image-20201217153642584"></p>
<h3 id="HDFS-1-0和2-0"><a href="#HDFS-1-0和2-0" class="headerlink" title="HDFS 1.0和2.0"></a>HDFS 1.0和2.0</h3><p>从1.0到2.0的改进主要是HDFS HA和HDFS联邦两个新特性</p>
<p><img src="/images/20180422134228737" alt="img"></p>
<h4 id="HA（热备—–-2-0）"><a href="#HA（热备—–-2-0）" class="headerlink" title="HA（热备—– 2.0）"></a>HA（热备—– 2.0）</h4><p>对于分布式文件系统HDFS ，NN是系统的核心节点，存储了各类元数据信息，并负责管理文件系统的命名空间和客户端对文件的访问。但是，在HDFS1.0中，只存在一个NN，一旦发生“单点故障”，就会导致整个系统失效。虽然有个SNN，但是它并不是NN的热备份，<strong>SNN主要功能在于周期性的从NN中获取FsImage和EditLog，进行合并后再发送给NN，替换掉原来的FsImage，以防止EditLog文件过大，导致NN失败恢复时消耗太多时间。合并后的FsImage在SNN中也保存一份，当NN失效时，可以利用SNN中的FsImage进行恢复</strong>。</p>
<p>SNN无法提供热备份功能，在NN发生故障时，会出现丢失数据的问题，仍需要停机恢复。HDFS2.0采用了HA（High Availability）架构。在HA集群中，一般设置两个NN，其中一个处于活跃（Active）状态，另一个处于待命（Standby）状态。处于Active状态的NN负责对外处理所有客户端的请求，处于Standby状态的NN作为热备份节点，保存了足够多的元数据，在Active节点发生故障时，可以在不丢失数据的情况下立即切换到活跃状态对外提供服务。</p>
<p><img src="/images/20180422134259919" alt="img"></p>
<p>由于Standby NN是Active NN的热备，这就要求Active NN的状态信息必须实时同步到StandbyNN。针对状态元数据同步问题，hdfs可以借助一个共享存储系统来实现，如NFS(NetworkFile System)、QJM(Quorum Journal Manager)或者Zookeeper。</p>
<p>Active NN将更新数据写入到共享存储系统，Standby NN会一直监听该系统，一旦发现有新的写入，就立即从存储系统中读取这些数据并加载到自己内存中，从而保证自己的元数据时刻与Active NN一致。</p>
<p>NN保存了数据块到实际存储位置的映射信息，即每个数据块是由哪个DN存储的。当一个DN加入到集群中时，它会把自己所包含的数据块列表给NN，定期通过心跳方式，汇报NN中最新的块映射。为了实现故障时的快速切换，就要保证StandbyNN中也包含最新的块映射信息，这就需要DN配置Active和Standby两个NN的地址，DN同时把块的位置和心跳信息发送到两个NN上。</p>
<p>同时，为了防止出现脑裂，还要保证在任何时刻都只有一个NN处于Active状态，需要Zookeeper实现。</p>
<h4 id="HDFS联邦"><a href="#HDFS联邦" class="headerlink" title="HDFS联邦"></a>HDFS联邦</h4><p>虽然HDFS HA解决了单点故障问题，但是还是有以下问题：</p>
<ol>
<li> 系统扩展性方面，元数据存储在NameNode内存中，当文件过多，会导致NameNode的内存成为整个hdfs的性能瓶颈。</li>
<li> 整体性能方面，吞吐量受单个NN的影响，访问hdfs的连接过多，单个NameNode会成为集群的性能上限。</li>
<li> 隔离性方面，一个程序可能会影响其他运行的程序，如一个程序消耗过多资源导致其他程序无法顺利运行。HDFS HA本质上还是单名称节点。</li>
</ol>
<blockquote>
<p>HDFS联邦可以解决以上三个问题</p>
<p>在HDFS联邦中有多个相互独立的NN，可以水平扩展HDFS的命名空间保存服务，NN只需要进行自己的命名空间和块的管理，不需要彼此协调沟通，但是每个DN要向集群中所有的NN注册，并周期性的发送心跳信息和块信息，报告自己的状态。</p>
</blockquote>
<p>HDFS联邦拥有多个独立的命名空间，其中，每一个命名空间管理属于自己的一组块，这些属于同一个命名空间的块组成一个“块池”。每个DN会为多个块池提供块的存储，块池中的各个块实际上是存储在不同DN中的。</p>
<blockquote>
<p>HDFS的Namespace（命名空间）用于记录系统中目录、文件、块之间的映射关系。</p>
</blockquote>
<blockquote>
<p>主要由namespace（命名空间）和Block Storage（块的存储）两层组成</p>
</blockquote>
<ol>
<li><p>namespace：由目录、文件、块组成；支持创建、删除、修改、列举命名空间相关系统的操作</p>
</li>
<li><p>Block Storage：<strong>block management：</strong>块的管理，在namenode中完成，通过控制注册和阶段性的心跳来保证datanode正常运行；处理块的信息报告，维护块的位置信息创建，修改，删除，查询块管理副本和副本位置</p>
</li>
</ol>
<p><img src="/images/20180422134339308" alt="img"></p>
<p>HDFS的底层存储是可以水平拓展的，但namespace不可以，当前的namespace只能放在单个NameNode上，NameNode存储了这个分布式文件系统的元数据信息，NameNode自身堆内存的上限，限制了集群中的数据块，文件和目录的数目。</p>
<ol>
<li>多个NameNode共用一个集群里的DataNode上的资源，而每个NameNode的哦可以单独对外提供服务。</li>
<li>每个NameNode都会定义一个存储池，有单独的id，每个DataNode都为所有存储池提供存储。</li>
<li>DataNode会按照存储池id向其对应的NameNode汇报块信息，也会会ibao所有NameNode本地存储可用资源情况。</li>
<li>如果要客户端方便的访问若干个NameNode的资源，可以使用客户端挂载表，把不同的目录映射到不同的NameNode，NameNode上必须存在相应的目录。</li>
</ol>
<p>解决了HDFS单节点如下问题</p>
<ol>
<li>namespace命名空间限制：namenode把所有元数据存储在内存中，单个namenode所能存储的对象（文件+块）有限制</li>
<li>性能瓶颈（吞吐量）：整个hdfs文件系统的吞吐量受限于单个namenode的吞吐量</li>
<li>隔离问题：无法隔离应用程序，一个实验程序，可能影响整个集群</li>
<li>单点故障</li>
</ol>
<p>简而言之就是</p>
<ul>
<li>NN的压力过大，内存受限</li>
<li>元数据进行分治，复用DN存储</li>
<li>元数据访问隔离性</li>
<li>DN目录隔离了block</li>
</ul>
<blockquote>
<p>单个NameNode的内存上限仍旧是DataNode的数目限制</p>
<p>HDFS Federation并没有完全解决单点故障问题。虽然namenode/namespace存在多个，但对于单个namenode来说，仍然存在单点故障。如果某个namenode挂掉了，其管理的相应文件便不可以访问。<br>Federation中每个namenode仍然像之前一样，配有一个secondary namenode，以便主namenode挂掉后，用于还原元数据信息</p>
</blockquote>
<h3 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h3><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ballwql/p/8944025.html">https://www.cnblogs.com/ballwql/p/8944025.html</a></p>
<p>与一般文件系统一样，HDFS也有块（block）的概念，HDFS上的文件也被划分为块大小的多个分块作为独立的存储单元，与通常的磁盘文件系统不同的是：</p>
<p><strong>HDFS中小于一个块大小的文件不会占据整个块的空间（当一个1MB的文件存储在一个128MB的块中时，文件只使用1MB的磁盘空间，而不是128MB），但是小文件索引和大文件（小于一个块）的索引在NameNode中占用的空间大小是一样的</strong></p>
<p>设置数据块的好处：</p>
<ol>
<li>数据可以被拆成很多快，分开存储在不同节点，这就使得一个文件的大小可以大于集群任意节点磁盘的容量 </li>
<li>对同一文件的块进行副本备份，当某个文件的快的副本出现错误，NameNode就会快速进行重备份和更换，提高数据存储的容错能力</li>
<li>使用抽象块概念而非整个文件作为存储单元，简化存储子系统的设计</li>
</ol>
<p>集群存储有大文件也有小文件，那块大小该如何设计呢，这里应该要考虑2个准则：</p>
<blockquote>
<ol>
<li>减少内存占用：对于Namenode来说，单个节点的NameNode内存有限，文件块越多，元数据信息越大，占用内存越多，如果文件数量级很大的话，元数据可能会超出NameNode的内存上限；</li>
<li>减少硬盘寻道时间： 数据块在硬盘为连续存储，对于普通SATA盘，随机寻址较慢， 如果块设置过小，一个文件的块总数会越多，查找数据的时候硬盘寻址时间会加长，无法保证hdfs的吞吐量；如果块设置过大，集群启动时，DataNode加载会很慢，同时，对多副本来说，在副本出问题时，快越大，系统恢复时间越长；并且会影响MR的执行效率（切片机制）。</li>
</ol>
</blockquote>
<h4 id="HDFS里面为什么一般设置块大小为64MB或128MB？"><a href="#HDFS里面为什么一般设置块大小为64MB或128MB？" class="headerlink" title="HDFS里面为什么一般设置块大小为64MB或128MB？"></a>HDFS里面为什么一般设置块大小为64MB或128MB？</h4><blockquote>
<p>hdfs2.0之前块大小都是64M，之后是128M</p>
</blockquote>
<h5 id="为什么不能远少于64MB？"><a href="#为什么不能远少于64MB？" class="headerlink" title="为什么不能远少于64MB？"></a>为什么不能远少于64MB？</h5><p>（1）<strong>减少硬盘寻道时间。</strong>HDFS设计前提是应对大数据量操作，数据块大小设置过小，那需要读取的数据块数量就会增多，间接增加底层硬盘的寻道时间</p>
<p>（2）<strong>减少NameNode内存消耗。</strong>由于NameNode记录着DataNode中的数据块信息，若数据块大小设置过小，则数据块数量增多，需要维护的数据块信息就会增多，从而消耗NameNode的内存。</p>
<h5 id="为什么不能远大于64MB？"><a href="#为什么不能远大于64MB？" class="headerlink" title="为什么不能远大于64MB？"></a>为什么不能远大于64MB？</h5><p>（1）<strong>崩溃重启问题。</strong>系统需要重新启动，启动过程中需要重新加载数据，数据块越大，数据加载时间越长，系统恢复过程越长</p>
<p>（2）<strong>监管时间问题。</strong>NameNode监管其他节点的情况，每个节点会周期性的与NameNode进行汇报通信（心跳机制）。如果某一个节点保持沉默的时间超过一个<strong>预设的时间间隔</strong>，NameNode会记录这个节点状态为死亡，并将该节点的数据转发给别的节点。这个“预设时间间隔”是从数据块的角度大致估算的。（加入对64MB的数据块，我可以假设你10分钟之内无论如何也能解决完了吧，超过10分钟还没反应，那我就认为你出故障或已经死了。）64MB大小的数据块，其时间尚可较为精准地估计，如果我将数据块大小设为640MB甚至上G，那这个“预设的时间间隔”便不好估算，估长估短对系统都会造成不必要的损失和资源浪费。</p>
<p>（3）<strong>问题分解问题。</strong>数据量的大小与问题解决的复杂度呈线性关系。对于同一个算法，处理的数据量越大，时间复杂度越高。</p>
<p>（4）<strong>约束Map输出。</strong>在Map Reduce框架里，Map之后的数据是要经过排序才执行Reduce操作的。这通常涉及到归并排序，而归并排序的算法思想便是“对小文件进行排序，然后将小文件归并成大文件”，因此“小文件”不宜过大。</p>
<blockquote>
<p>HDFS的块设置的如此之大主要还是为了<strong>减小寻址开销</strong>的，《Hadoop权威指南》中有一段话：</p>
<p>  HDFS的块比磁盘块大，其目的是为了最小化寻址开销。如果块设置得足够大，从<strong>磁盘传输数据的时间</strong>可以明显大于<strong>定位这个块开始位置所需的时间</strong>。这样，传输一个由多个块组成的文件的时间就<strong>取决于磁盘传输速率</strong>。</p>
<p>  我们做一个估计计算，如果寻址时间为10ms左右，而传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们需要设置块大小为100MB左右。而默认的块大小实际为64MB，但是很多情况下HDFS使用128MB的块设置。<strong>以后随着新一代磁盘驱动器传输速率的提升，块的大小将被设置得更大。</strong></p>
<p>  <strong>但是，该参数也不会设置得过大。MapReduce中的map任务通常一次处理一个块中的数据，因此，如果任务数太少（少于集群中的节点数量），作业的运行速度就会变慢。</strong></p>
</blockquote>
<h3 id="数据写入和存储"><a href="#数据写入和存储" class="headerlink" title="数据写入和存储"></a>数据写入和存储</h3><p> <strong>Block、Packet和Chunk</strong>。Block上面有描述，Packet和Chunk如下：</p>
<ol>
<li><strong>Packet</strong>：其比块要小很多，可以理解为Linux操作系统最小盘块概念，一般为64KB，由参数<code>dfs.write.packet.size</code>控制，是client向Datanode写入数据的粒度，即client向Datanode写数据时不是一次以Block为单位写的，而是被分成若干Packet，放入pipeline顺序追加写入到Block中，示意图如下：<img src="/images/275962-20180520092742990-1205691265.png" alt="packet"></li>
<li><strong>Chunk</strong>: 比Packet更小，是针对Packet数据校验粒度来设计的，一般是512B,由参数<code>io.bytes.per.checksum</code>控制，同时还带有一个4B的校验值，所以可以认为一个Chunk是516B</li>
</ol>
<blockquote>
<p>在client端向DataNode传数据的时候，HDFSOutputStream会有一个chunk buff，写满一个chunk后，会计算校验和并写入当前的chunk。之后再把带有校验和的chunk写入packet，当一个packet写满后，packet会进入dataQueue队列，其他的DataNode就是从这个dataQueue获取client端上传的数据并存储的。同时一个DataNode成功存储一个packet后之后会返回一个ack packet，放入ack Queue中。</p>
</blockquote>
<blockquote>
<p>Hadoop默认对3个副本的存放策略  </p>
<p>第一块：在本机器的HDFS目录下存储一个Block<br>第二块：不同Rack(机架)的某个DataNode上存储一个Block<br>第三块：在该机器的同一个Rack下的某台机器上存储最后一个Block</p>
<p>更能多副本：随机节点</p>
</blockquote>
<h4 id="数据写入"><a href="#数据写入" class="headerlink" title="数据写入"></a>数据写入</h4><p><img src="/images/20180716221908696" alt="HDFS读流程"></p>
<ol>
<li>客户端向NameNode发出写文件请求。</li>
<li>检查是否已存在文件、检查权限。若通过检查，<strong>直接先将操作写入EditLog</strong>，并返回输出流对象。<br>（注：WAL，write ahead log，先写Log，再写内存，因为EditLog记录的是最新的HDFS客户端执行所有的写操作。如果后续真实写操作失败了，由于在真实写操作之前，操作就被写入EditLog中了，故EditLog中仍会有记录，我们不用担心后续client读不到相应的数据块，因为在第5步中DataNode收到块后会有一返回确认信息，若没写成功，发送端没收到确认信息，会一直重试，直到成功）</li>
<li>client端<strong>按128MB的块切分文件</strong>。</li>
<li>client将NameNode返回的分配的可写的<strong>DataNode列表</strong>和<strong>Data数据</strong>一同发送给最近的第一个DataNode节点，此后client端和NameNode分配的多个DataNode构成pipeline管道，client端向输出流对象中写数据。client每向第一个DataNode写入一个packet，这个packet便会直接在pipeline里传给第二个、第三个…DataNode。<br>（注：并不是写好一个块或一整个文件后才向后分发）</li>
<li>每个DataNode写完一个块后，会返回<strong>确认信息</strong>。<br>（注：并不是每写完一个packet后就返回确认信息，因为packet中的每个chunk都携带校验信息，没必要每写一个就汇报一下，这样效率太慢。正确的做法是写完一个block块后，对校验信息进行汇总分析，就能得出是否有块写错的情况发生）</li>
<li>写完数据，关闭输输出流。</li>
<li>发送完成信号给NameNode。<br>（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性）</li>
</ol>
<h4 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h4><p><img src="/images/20180716231213892" alt="HDFS读流程"></p>
<ol>
<li>client访问NameNode，查询元数据信息，获得这个文件的数据块位置列表，返回输入流对象。</li>
<li>就近挑选一台datanode服务器，请求建立输入流 。</li>
<li>DataNode向输入流中中写数据，以packet为单位来校验。</li>
<li>关闭输入流</li>
</ol>
<h3 id="压缩算法"><a href="#压缩算法" class="headerlink" title="压缩算法"></a>压缩算法</h3><h4 id="Gzip压缩"><a href="#Gzip压缩" class="headerlink" title="Gzip压缩"></a>Gzip压缩</h4><blockquote>
<p>优点：压缩率比较高，而且压缩/解压速度也比较快；hadoop本身支持，在应用中处理gzip格式的文件就和直接处理文本一样；有hadoop native库；大部分linux系统都自带gzip命令，使用方便。</p>
<p>缺点：不支持split —– 数据倾斜</p>
</blockquote>
<blockquote>
<p>应用场景：当每个文件压缩之后在130M以内的（1个块大小内），都可以考虑用gzip压缩格式。譬如说一天或者一个小时的日志压缩成一个gzip文件，运行mapreduce程序的时候通过多个gzip文件达到并发。hive程序，streaming程序，和java写的mapreduce程序完全和文本处理一样，压缩之后原来的程序不需要做任何修改。</p>
</blockquote>
<h4 id="Lzo压缩"><a href="#Lzo压缩" class="headerlink" title="Lzo压缩"></a>Lzo压缩</h4><blockquote>
<p> 优点：压缩/解压速度也比较快，合理的压缩率；支持split，是hadoop中最流行的压缩格式；支持hadoop native库；可以在linux系统下安装lzop命令，使用方便。</p>
<p>缺点：压缩率比gzip要低一些；hadoop本身不支持，需要安装；在应用中对lzo格式的文件需要做一些特殊处理（为了支持split需要建索引，还需要指定inputformat为lzo格式）。</p>
<p>应用场景：一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，lzo优点越越明显。</p>
</blockquote>
<h4 id="Bzip2"><a href="#Bzip2" class="headerlink" title="Bzip2"></a>Bzip2</h4><blockquote>
<p>优点：支持split；具有很高的压缩率，比gzip压缩率都高；hadoop本身支持，但不支持native；在linux系统下自带bzip2命令，使用方便。</p>
<p> 缺点：压缩/解压速度慢；不支持native。</p>
<p> 应用场景：适合对速度要求不高，但需要较高的压缩率的时候，可以作为mapreduce作业的输出格式；或者输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；或者对单个很大的文本文件想压缩减少存储空间，同时又需要支持split，而且兼容之前的应用程序（即应用程序不需要修改）的情况。</p>
</blockquote>
<h4 id="Snappy"><a href="#Snappy" class="headerlink" title="Snappy"></a>Snappy</h4><blockquote>
<p>优点：高速压缩速度和合理的压缩率；支持hadoop native库。</p>
<p> 缺点：不支持split；压缩率比gzip要低；hadoop本身不支持，需要安装；linux系统下没有对应的命令。</p>
<p>应用场景：当mapreduce作业的map输出的数据比较大的时候，作为map到reduce的中间数据的压缩格式；或者作为一个mapreduce作业的输出和另外一个mapreduce作业的输入。</p>
</blockquote>
<p><img src="/images/hadoop-ys-all.png" alt="Alt text"></p>
<blockquote>
<p>在hadoop中如果是单文件压缩后在200M（接近一个块大小）左右建议使用gzip压缩，</p>
<p>如果是单文件压缩之后大于400M建议使用可split的lzo or bzip2压缩，这样在进行mapreduce的时候可以并行处理这个压缩文件。像在hbase中各列族可以使用snappy这种压缩算法，压缩解压都很快。</p>
</blockquote>
<h3 id="数据损坏"><a href="#数据损坏" class="headerlink" title="数据损坏"></a>数据损坏</h3><p>在namenode中对于进行数据块副本的管理都是在<strong>FSnameSystem</strong>（命名空间镜像）中，这里面有一个成员变量 corruptReplicats，存储着损坏数据与DataNode的映射，当某个数据块损坏后（DataNode可以通过数据块扫描器获知，通过心跳发送给namenode）,namenode会将损坏的数据块加到corrupReplicats中，当损坏的数据块在DataNode上删除（重备份），NameNode会在corrutpReplicatS中也删除。</p>
<p>当部分副本出现损坏时，namenode进行数据块复制，在这个过程中有一个数据结构叫做underReplicatedBlocks对象，其中就有list保存需要进行数据块复制的数据块，对于数据块复制是有优先级的，underReplicatedBlocks的getPriority()会返回数据块的优先级，等待复制的对象从underReplicatsBlocks中读取出来之后会生成复制请求，并将请求放入FSnameSystem.pendingReplications中。pendlingReplication是一个数据块到数据块复制信息pendingBlockInfo的映射，pendlingReplication保存了数据块复制的时间和复制副本数，如果复制没成功会被重新插入到underReplicatedBlocks对象中，重新产生复制请求。</p>
<h3 id="数据负载均衡"><a href="#数据负载均衡" class="headerlink" title="数据负载均衡"></a>数据负载均衡</h3><p>Hadoop的HDFS集群非常容易出现机器与机器之间磁盘利用率不平衡的情况，例如：当集群内新增、删除节点，或者某个节点机器内硬盘存储达到饱和值。当数据不平衡时，Map任务可能会分配到没有存储数据的机器，这将导致网络带宽的消耗，也无法很好的进行本地计算。</p>
<p>当HDFS负载不均衡时，需要对HDFS进行数据的负载均衡调整，即对各节点机器上数据的存储分布进行调整。从而让数据均匀的分布在各个DataNode上，均衡IO性能，防止热点的发生。进行数据的负载均衡调整，必须要满足如下原则：</p>
<ul>
<li>数据平衡不能导致数据块减少，数据块备份丢失</li>
<li>管理员可以中止数据平衡进程</li>
<li>每次移动的数据量以及占用的网络资源，必须是可控的</li>
<li>数据均衡过程，不能影响namenode的正常工作</li>
</ul>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>数据均衡过程的核心是一个数据均衡算法，该数据均衡算法将不断迭代数据均衡逻辑，直至集群内数据均衡为止。该数据均衡算法每次迭代的逻辑如下：</p>
<p><img src="/images/20200820110439911.png" alt="img"></p>
<ol>
<li>数据均衡服务（Rebalancing Server）首先要求 NameNode 生成 DataNode 数据分布分析报告，获取每个DataNode磁盘使用情况</li>
<li>Rebalancing Server汇总需要移动的数据分布情况，计算具体数据块迁移路线图。数据块迁移路线图，确保网络内最短路径</li>
<li>开始数据块迁移任务，Proxy Source Data Node复制一块需要移动数据块</li>
<li>将复制的数据块复制到目标DataNode上</li>
<li>删除原始数据块</li>
<li>目标DataNode向Proxy Source Data Node确认该数据块迁移完成</li>
<li>Proxy Source Data Node向Rebalancing Server确认本次数据块迁移完成。然后继续执行这个过程，直至集群达到数据均衡标准</li>
</ol>
<h3 id="小文件解决方案"><a href="#小文件解决方案" class="headerlink" title="小文件解决方案"></a>小文件解决方案</h3><h4 id="Hadoop-Archive"><a href="#Hadoop-Archive" class="headerlink" title="Hadoop Archive"></a>Hadoop Archive</h4><p><a target="_blank" rel="noopener" href="https://www.iteblog.com/archives/tag/hadoop/">Hadoop</a> Archives (HAR files)是在 Hadoop 0.18.0 版本中引入的，它的出现是为了缓解大量小文件消耗 NameNode 内存的问题。HAR 文件是通过在 HDFS 上构建一个层次化的文件系统来工作。一个 HAR 文件是通过 hadoop 的 archive 命令来创建，而这个命令实 际上也是运行了一个 MapReduce 任务来将小文件打包成 HAR 文件。对客户端来说，使用 HAR 文件没有任何影响。所有的原始文件都可见并且可访问的（通过 har://URL），但在 HDFS 端它内部的文件数减少了，架构如下：</p>
<p><img src="/images/har.png" alt="img"></p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment">#archiveName  的名字后缀只能是  har      输入目录   输出目录（会自己生成）</span>
hadoop archive -archiveName test.har -p /litter /output
<span class="token comment">#查看 har 文件的内容（har是由几个文档合成的，那么har中就有几个文档）</span>
hdfs dfs -ls har:///output/test.har<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>使用HAR时需要两点，第一，对小文件进行存档后，原文件并不会自动被删除，需要用户自己删除；第二，创建HAR文件的过程实际上是在运行一个mapreduce作业，因而需要有一个hadoop集群运行此命令。</p>
<p>此外，HAR还有一些缺陷：一旦创建，Archives便不可改变。要增加或移除里面的文件，必须重新创建归档文件；要归档的文件名中不能有空格，否则会抛出异常，可以将空格用其他符号替换(使用-Dhar.space.replacement.enable=true 和-Dhar.space.replacement参数)</p>
</blockquote>
<h4 id="Sequence-file"><a href="#Sequence-file" class="headerlink" title="Sequence file"></a>Sequence file</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/bitcarmanlee/article/details/78111289">https://blog.csdn.net/bitcarmanlee/article/details/78111289</a></p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>CombineFileInputFormat是一种新的inputformat，用于将多个文件合并成一个单独的split，另外，它会考虑数据的存储位置。</p>
<h3 id="NameNode-（非HA）"><a href="#NameNode-（非HA）" class="headerlink" title="NameNode （非HA）"></a>NameNode （非HA）</h3><ol>
<li>namenode节点每隔一定时间或者edits.log达到指定大小，请求secondaryNamenode合并操作</li>
<li>secondaryNamenode请求namenode进行edits.log的滚动，这样新的编辑操作就能够进入新的文件edits.new中</li>
<li>secondaryNamenode从namenode中下载fsImage和edits.log</li>
<li>secondaryNamenode进行fsImage和edits.log的合并,成为fsImage.checkpoint文件</li>
<li>namenode下载合并后的fsImage.checkpoin文件</li>
<li>将fsImage.checkpoint和edits.new命名为原来的文件名(之后fsImage和日志文件edits.log重新恢复初始状态)</li>
</ol>
<h3 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h3><blockquote>
<p> hdfs federation即hdfs的联邦，可以简单理解为多个hdfs集群聚合到一起，更准确的理解是有多个namenode节点的hdfs集群</p>
</blockquote>
<h4 id="hadoop1-x的hdfs架构"><a href="#hadoop1-x的hdfs架构" class="headerlink" title="hadoop1.x的hdfs架构"></a>hadoop1.x的hdfs架构</h4><p><img src="/images/20180530173450965" alt="img"></p>
<blockquote>
<p>主要由namespace（命名空间）和Block Storage（块的存储）两层组成</p>
</blockquote>
<ol>
<li><p>namespace：由目录、文件、块组成；支持创建、删除、修改、列举命名空间相关系统的操作</p>
</li>
<li><p>Block Storage：<strong>block management：</strong>块的管理，在namenode中完成，通过控制注册和阶段性的心跳来保证datanode正常运行；处理块的信息报告，维护块的位置信息创建，修改，删除，查询块管理副本和副本位置</p>
</li>
</ol>
<p><strong>单namenode架构的局限性</strong></p>
<ol>
<li><p>namespace命名空间限制：namenode把所有元数据存储在内存中，单个namenode所能存储的对象（文件+块）有限制</p>
</li>
<li><p>性能瓶颈（吞吐量）：整个hdfs文件系统的吞吐量受限于单个namenode的吞吐量</p>
</li>
<li><p>隔离问题：无法隔离应用程序，一个实验程序，可能影响整个集群</p>
</li>
<li><p>单点故障（热备下的高可用解决）</p>
</li>
<li><p>namespace和block management紧密耦合：紧密耦合导致使用另外一种namenode方案比较困难，也限制了其他想使用快存储的应用</p>
</li>
<li><p>纵向扩展namenode不可行：启动时间长，调试困难，集群易宕机。比如将Namenode的Heap空间扩大到512GB ——第一个问题就是启动问题，启动花费的时间太长。当前具有50GB的Heap Namenode的HDFS启动一次大概需要30分钟到2个小时；第二个潜在的问题就是Namenode在Full GC时，如果发生错误将会导致整个集群宕机；第三个问题是对大JVMHeap进行调试比较困难。优化Namenode的内存使用性价比比较低</p>
</li>
</ol>
<h4 id="Federation架构"><a href="#Federation架构" class="headerlink" title="Federation架构"></a>Federation架构</h4><p><img src="/images/20180530183049440" alt="img"></p>
<ol>
<li>这些namenode直接相互独立，各自分工管理自己的区域，且不需要互相协调通信，一个namenode挂掉了不会影响其他的namenode</li>
<li>datanode被用作通用的数据存储设备，每个datanode要向集群中所有的namenode注册，且周期性的向所有namenode发送心跳和报告，并执行来自所有namenode的命令</li>
<li>一个block pool由属于同一个namespace的数据块组成，每个datanode可能会存储集群中所有block pool 数据块，每个block pool内部自治，各自管理各自的block，不会与其他block pool交流</li>
<li>namenode和block pool一起被称作namespace volume，它是管理的基本单位，当一个namespace被删除后，所有datanode上与其对应的block pool也会被删除。当集群升级时，每个namespace volume作为一个基本单元进行升级</li>
</ol>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>解决了HDFS单节点如下问题</p>
<ol>
<li>namespace命名空间限制：namenode把所有元数据存储在内存中，单个namenode所能存储的对象（文件+块）有限制</li>
<li>性能瓶颈（吞吐量）：整个hdfs文件系统的吞吐量受限于单个namenode的吞吐量</li>
<li>隔离问题：无法隔离应用程序，一个实验程序，可能影响整个集群</li>
<li>单点故障（没有完全解决）</li>
</ol>
<p>简而言之就是</p>
<ul>
<li>NN的压力过大，内存受限</li>
<li>元数据进行分治，复用DN存储</li>
<li>元数据访问隔离性</li>
<li>DN目录隔离了block</li>
</ul>
<h4 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h4><blockquote>
<p>HDFS Federation并没有完全解决单点故障问题。虽然namenode/namespace存在多个，但对于单个namenode来说，仍然存在单点故障。如果某个namenode挂掉了，其管理的相应文件便不可以访问。<br>Federation中每个namenode仍然像之前一样，配有一个secondary namenode，以便主namenode挂掉后，用于还原元数据信息</p>
</blockquote>
<h2 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h2><h4 id="高容错-–-数据冗余备份"><a href="#高容错-–-数据冗余备份" class="headerlink" title="高容错 – 数据冗余备份"></a>高容错 – 数据冗余备份</h4><p>对于一个庞大的HDFS集群，在运行时总会有节点发生故障，但是HDFS仍旧可以正常提供服务，这得益于它的容错机制。</p>
<p>DataNode和NameNode之间会有一个类似通信的机制，称其为心跳机制。当网络问题或者节点故障导致DataNode发出的心跳信息没有被NameNode接收到时，NameNode会认为这个节点发生故障，存储的数据无效，于是DataNode就不会再发I/O操作给这个节点，同时从这个节点存储的文件块的其它冗余备份中获取未损坏的文件块进行操作。</p>
<p>因此NameNode会定期检测HDFS中所有正常冗余备份数目是否小于设定值，假如小于设定值，则从其它备份中复制一定数量的新备份放入DataNode中存储，使所有节点的冗余备份数目达到设定值。</p>
<h4 id="高可用-—-基于zookeeper-QJM"><a href="#高可用-—-基于zookeeper-QJM" class="headerlink" title="高可用 — 基于zookeeper+QJM"></a>高可用 — 基于zookeeper+QJM</h4><p>NameNode节点之间必须共享存储与编辑日志。当一个备用的NameNode节点启动完毕，它会读取标记日志文件，保持与活动NameNode节点状态的同步，然后继续读取由活动NameNode节点写入编辑日志文件中的新的状态。因为块的映射存储在DataNode节点的内存中，而不是磁盘上，所以两个NameNode必须实时获取这些元数据信息，这就要求DataNode节点必须同时向两个NameNode节点发送块报告，</p>
<p>StandByNameNode需要实时获取ActiveNameNode的editlogs（NameNode对所有客户端的操作都会写入editlog中），并合并FsImage和editlogs。对于高可用的共享存储有两个选择：一个是使用NFS文件服务器，另一个是仲裁日志管理器（QJM：quorum journal manager）。HDFS的实现使用的是QJM，主要是为了提供高可用的编辑日志。</p>
<p>QJM运行一组日志节点（journal nodes），每一个编辑操作都会被记录到多个日志节点中，<strong>类似zookeeper的ZAb协议</strong>，  系统可以容忍部分日志的丢失。如果NameNode节点故障，而StandByNameNode节点的内存存储着最新的状态，所以StandByNameNode节点可以很快接管。但是实际NameNode节点之间的切换时间会较长些（一分钟左右），因为系统需要确认NameNode节点是否已经失效（zkf会检查nameNode的状态，确保故障）。在活动的NameNode节点故障的时候，备用的NameNode节点也出现故障，对于这种极端情况，管理员仍然可以重新启动备用的NameNode节点，但是这种情况出现的概率较小。</p>
<h4 id="数据可靠性与安全性"><a href="#数据可靠性与安全性" class="headerlink" title="数据可靠性与安全性"></a>数据可靠性与安全性</h4><p>副本存放和数据读取是HDFS可靠性和高性能的关键，HDFS采用机架感知的策略来改进数据的可靠性，在读取数据时，HDFS会尽量读取距离客户端程序最近的节点副本（网络拓扑结构中最近的节点），减少读取距离和网络传输的IO。</p>
<p>HDFS采用两种方法确保文件安全，<strong>第一种是将NameNode中的元数据存储到远程NFS文件系统上，在多个文件系统中备份NameNode节点的元数据；第二种是系统中同步运行一个SecondaryNode/StandByNameNode，主要负责周期性合并日志中的命名空间镜像工作</strong>。</p>
<p>如上所述，HDFS采用在多个文件系统中备份NameNode节点元数据和使用SecondaryNode节点以检查点的方式来防止数据丢失。</p>
<p>但是由于NameNode节点是唯一存储元数据和文件到数据块映射的仓库，这并没有提供高可用的文件系统，NameNode节点仍旧存在故障的可能。因此，若NameNode节点故障，所有的客户端将不能读写文件，Hadoop将暂停服务直到有NameNode节点再次可用，此时管理员需要使用一个文件系统元数据的副本和DataNode节点的配置信息来启动一个新的NameNode，并让客户端使用这个新的NameNode。新的NameNode节点直到命名空间的镜像文件被加载到内存重做编辑日志并获得来自DataNode节点的报告后才能继续提供服务。</p>
<blockquote>
<p>Hdfs1.x提供的基于NameNode和SecondaryNameNode的冷备</p>
<p>Hdfs2.x提供的基于NameNode和StandByNameNode的热备</p>
</blockquote>
<p>因此，在一个含有大量文件和块的大集群中启动一个新的NameNode节点耗时巨大。为解决这种问题，从Hadoop 2.0版本开始，为用户提供了HDFS的高可用。该版本提供了一对NameNode节点，其中一个作为活动节点，另一个作为备用节点(StandByNameNode)，一旦活动节点出现故障，备用节点可以很快接管，继续为客户端提供服务，这期间不会出现明显的中断现象。</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><blockquote>
<p>NameNode在内存中维护所有元数据信息，对内存要求高</p>
<p>当FsImage和editlog文件过大，hdfs集群启动慢</p>
</blockquote>
<h2 id="主备数据交换-（1-x）"><a href="#主备数据交换-（1-x）" class="headerlink" title="主备数据交换 （1.x）"></a>主备数据交换 （1.x）</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/dabokele/article/details/51686257">https://blog.csdn.net/dabokele/article/details/51686257</a></p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><blockquote>
<p>NameNode用于存储HDFS的元数据（数据的数据，包括文件目录、文件名、文件属性等）、管理文件系统的命名空间以及保存整个文件系统的空间命名镜像（也称文件系统镜像，File System Image，FSImage）当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。</p>
<p>Namenode负责保存系统的目录树和文件信息并且保存有空间命名镜像的编辑日志，它只对元数据操作记录而不对数据块操作记录，对数据块的操作是DataNode具体执行的</p>
</blockquote>
<p><img src="/images/20160216153044620" alt="这里写图片描述"></p>
<ul>
<li>fsimage ：NameNode启动时对整个文件系统的快照</li>
<li>edit logs ：NameNode启动后，对文件系统的改动序列 – 存储在内存中</li>
</ul>
<blockquote>
<p>只有在NameNode重启时，edit logs才会合并到fsimage文件中，从而得到一个文件系统的最新快照</p>
</blockquote>
<p>在运行正常的集群中NameNode是很少重启的，这也意味着当NameNode运行了很长时间后，edit logs文件会变得很大。在这种情况下就会出现下面一些问题：</p>
<ul>
<li>edit logs文件会变的很大</li>
<li>NameNode的重启会花费很长时间，因为有很多改动（在edit logs中）要合并到fsimage文件上</li>
<li>如果NameNode挂掉了，就会丢失了很多改动，因为此时的fsimage文件非常旧，没有和edit logs文件合并</li>
</ul>
<blockquote>
<p>解决方式：定时合并edit logs和方式image</p>
</blockquote>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><blockquote>
<p>SecondaryNameNode就是来帮助解决上述问题的，它的职责是合并NameNode的edit logs到fsimage文件中。</p>
</blockquote>
<p><img src="/images/20160216153104112" alt="这里写图片描述"></p>
<h3 id="主备合作"><a href="#主备合作" class="headerlink" title="主备合作"></a>主备合作</h3><p><img src="/images/16d72c9e4a40abe7" alt="1"></p>
<blockquote>
<p>第一阶段：NameNode启动</p>
<ul>
<li>第一次启动NameNode，会创建Fsimage，Edit会在NameNode启动时生成；如果不是第一次启动，会加载Edit和FsImage到内存，然后进行合并操作，此时NameNode有最新的元数据信息</li>
<li>客户端对NameNode发送增删请求（查询操作不记录），NameNode会记录操作日志，并更新edit</li>
<li>NameNode会在内存中先对元数据进行增删操作</li>
</ul>
<p>第二阶段：SecondaryNameNode</p>
<ul>
<li>SecondaryNameNode定时询问NameNode是否需要checkpoint</li>
<li>checkpoint时间到了或者Edit数据满了，SecondaryNameNode执行checkpoint</li>
<li>NameNode滚动正在写的Edits，并生成新的空的edits.inprogress002，滚动的目的是给Edits打个标记，以后所有更新操作都写入edits.inprogress002中</li>
<li>原来的Fsimage和Edits文件会拷贝到SecondaryNameNode节点，SecondaryNameNode会将它们加载到内存合并，生成新的镜像文件fsimage.chkpoint</li>
<li>将新的镜像文件fsimage.chkpoint拷贝给NameNode，重命名为Fsimage，替换原来的镜像文件</li>
<li>最后当NameNode启动时，只需要加载之前未合并的Edits和Fsimage即可更新到最新的元数据信息</li>
</ul>
</blockquote>
<h2 id="主备数据交换-（2-x）"><a href="#主备数据交换-（2-x）" class="headerlink" title="主备数据交换 （2.x）"></a>主备数据交换 （2.x）</h2><blockquote>
<p>在一个HA（热备）集群中，会配置两个独立的Namenode。在任意时刻，只有一个节点作为活动的节点，另一个节点则处于备份状态。<strong>活动的Namenode负责执行所有修改命名空间以及删除备份数据块的操作，而备份的Namenode则执行同步操作，以保持与活动节点命名空间的一致性</strong>。</p>
</blockquote>
<h3 id="NameNode-1"><a href="#NameNode-1" class="headerlink" title="NameNode"></a>NameNode</h3><blockquote>
<p>NameNode用于存储HDFS的元数据（数据的数据，包括文件目录、文件名、文件属性等）、管理文件系统的命名空间以及保存整个文件系统的空间命名镜像（也称文件系统镜像，File System Image，FSImage）当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。</p>
<p>Namenode负责保存系统的目录树和文件信息并且保存有空间命名镜像的编辑日志，它只对元数据操作记录而不对数据块操作记录，对数据块的操作是DataNode具体执行的</p>
</blockquote>
<p><img src="/images/20160216153044620" alt="这里写图片描述"></p>
<h3 id="StandByNameNode"><a href="#StandByNameNode" class="headerlink" title="StandByNameNode"></a>StandByNameNode</h3><p>和Active NameNode一样，StandByNameNode作为备份的NameNode，当active NameNode故障时，StandByNameNode会立刻切换为active，</p>
<p>为了使StandByNameNode与Active NameNode的状态能够同步一致，两个节点都需要同一组独立运行的节点（JournalNodes，JNS）通信。</p>
<p><strong>当Active Namenode执行了修改命名空间的操作时，它会定期将执行的操作记录在editlog中，并写入JNS的多数节点中，Standby Namenode会一直监听JNS上editlog的变化，如果发现editlog有改动，Standby Namenode就会读取editlog并与当前自己的命名空间合并</strong></p>
<p>当发生了错误切换时，Standby节点会保证已经从JNS上读取了所有editlog并与命名空间合并，然后才会从Standby状态切换为Active状态。通过这种机制，保证了Active Namenode与Standby Namenode之间命名空间状态的一致性。</p>
<p>为了使错误节点切换能够很快的执行完，就要保证Standby节点也保存了实时的数据快的存储信息，发生切换时，Standby节点就不需要等待所有的数据节点进行全量数据块汇报，而直接可以切换到Active状态。为了实现这个机制，Datanode会同时向这两个Namenode发送心跳以及块汇报信息。这样就实现了Active Namenode 和standby Namenode 的元数据就完全一致，一旦发生故障，就可以马上切换，也就是热备。</p>
<p><img src="/images/20180312205533188" alt="这里写图片描述"></p>
<blockquote>
<p>Standby Namenode只会更新数据块的存储信息，并不会向namenode 发送复制或者删除数据块的指令，这些指令只能由Active namenode发送。</p>
</blockquote>
<h3 id="Quorum-Journal"><a href="#Quorum-Journal" class="headerlink" title="Quorum Journal"></a><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">Quorum Journal</a></h3><blockquote>
<p>在Hadoop2.6中，提供了QJM（Quorum Journal Manager）方案来解决HA共享存储问题。解决了一下存储问题</p>
<p>Active Namenode会将日志文件写到共享存储上。</p>
<p>StandbyNamenode会实时的从共享存储读取edetlog文件，然后合并到Standby Namenode的命名空间中。一旦Active Namenode发生错误，StandbyNamenode可以立即切换到Active状态。</p>
</blockquote>
<ul>
<li>JournalNoe（JN）：运行在N台独立的物理机器上，它将editlog文件保存在JournalNode的本地磁盘上，同时JournalNode还对外提供RPC接口QJournalProtocol以执行远程读写editlog文件的功能</li>
<li>QuorumJournalManager(QJM)：运行在NameNode上（目前HA集群只有两个Namenode），通过调用RPC接口QJournalProtocol中的方法向JournalNode发送写入、排斥、同步editlog</li>
</ul>
<blockquote>
<p>Quorum Journal方案依赖于这样一个概念：HDFS集群中有2N+1个JN存储editlog文件，这些editlog 文件是保存在JN的本地磁盘上的。每个JN对QJM暴露QJM接口QJournalProtocol，允许Namenode读写editlog文件。</p>
<p>当Namenode向共享存储写入editlog文件时，它会通过QJM向集群中所有的ＪＮ发送写editlog文件请求，当有一半以上的JＮ返回写操作成功时，即认为写成功。这个原理是基于Paxos算法的</p>
</blockquote>
<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ol>
<li>JN进程可以运行在普通的PC上，而无需配置专业的共享存储硬件。</li>
<li>不需要单独实现fencing机制，Quorum Journal模式中内置了fencing功能。</li>
<li>Quorum Journa不存在单点故障，集群中有2N+1个Journal，可以允许有Ｎ个Journal Node死亡。</li>
<li>JN不会因为其中一个机器的延迟而影响整体的延迟，而且也不会因为JN数量的增多而影响性能（因为Namenode向JournalNode发送日志是并行的）</li>
</ol>
<h4 id="互斥机制"><a href="#互斥机制" class="headerlink" title="互斥机制"></a>互斥机制</h4><blockquote>
<p>类似zookeeper选举机制里面的选举周期</p>
</blockquote>
<p>当HA集群中发生NameNode异常切换时，需要在共享存储上fencing上一个活动的节点以保证该节点不能再向共享存储写入editlog。基于Quorum Journal模式的HA提供了epoch number来解决互斥问题，epoch number具有以下几个性质</p>
<ol>
<li>当一个Namenode变为活动状态时，会分配给他一个epoch number。</li>
<li>每个epoch number都是唯一的，没有任意两个NameNode有相同的epoch number。</li>
<li>epoch number 定义了NameNode写editlog文件的顺序。对于任意两个namenode ，拥有更大epoch number的Namenode被认为是活动节点。</li>
</ol>
<p>当一个NameNode切换为活动状态时，它的QJM会向所有的JN发送命令，以获取该JN的最后一个promise epoch变量值。当QJM接受到了集群中多于一半的JN回复后，它会将所接收到的最大值加一，并保存到myepoch 中，之后QJM会将该值发送给所有的JN并提出更新请求。每个JN会将该值与自身的epoch值相互比较，如果新的myepoch比较大，则JN更新，并返回更新成功；如果小，则返回更新失败。如果QJM接收到超过一半的JN返回成功，则设置它的epoch number为myepoch；否则它终止尝试为一个活动的Namenode，并抛出异常</p>
<p>当活动的NameNode成功获取并更新了epoch number后，调用任何修改editlog的RPC请求都必须携带epoch number。当RPC请求到达JN后，JN会将请求者的epoch与自身保存的epoch相互对比，若请求者的epoch更大，JN就会更新自己的epoch，并执行相应的操作，如果请求者的epoch小，就会拒绝相应的请求。当集群中大多数的JN拒绝了请求时，这次操作就失败了。</p>
<p>当HDFS集群发生Namenode错误切换后，原来的standby Namenode将集群的epoch number加一后更新。这样原来的Active namenode的epoch number肯定小于这个值，当这个节点执行写editlog操作时，由于JN节点不接收epoch number小于自身的promise epoch的写请求，所以这次写请求会失败，也就达到了fencing的目的</p>
<h4 id="共享editlogs"><a href="#共享editlogs" class="headerlink" title="共享editlogs"></a>共享editlogs</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/nucdy/p/5892179.html">https://www.cnblogs.com/nucdy/p/5892179.html</a></p>
<p>在HA实现中还有一个非常重要的部分就是Active Namenode和Standby Namenode之间如何共享editlog日志文件</p>
<blockquote>
<p>所有的HA实现方案都依赖于一个保存editlog的共享存储，这个存储必须是高可用的，并且能够被集群中所有的Namenode同时访问（但是只能由Active NameNode进行写入）</p>
</blockquote>
<p><strong>基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉</strong>。</p>
<p>基于 QJM 的共享存储系统的内部实现架构图如图所示，主要包含下面几个主要的组件：</p>
<p><img src="/images/img004.png" alt="img"></p>
<blockquote>
<p>FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。</p>
<p>JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作；一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。</p>
<p>FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。</p>
<p>QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。</p>
<p>AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。</p>
<p>AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。</p>
<p>JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。</p>
<p>JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。</p>
</blockquote>
<h4 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h4><p><img src="/images/img005.png" alt="img"></p>
<blockquote>
<p>Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog</p>
</blockquote>
<h4 id="数据恢复"><a href="#数据恢复" class="headerlink" title="数据恢复"></a>数据恢复</h4><p>处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。</p>
<p>另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。</p>
<p>补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：</p>
<h2 id="Hdfs安全模式"><a href="#Hdfs安全模式" class="headerlink" title="Hdfs安全模式"></a>Hdfs安全模式</h2><p>集群启动的时候将FsImage加载到内存，执行editlog日志的操作（FsImage和editLog合并），此时会进入安全模式，datanode向namenode发送最新的块列表信息，NameNode检查集群内数据块的完整性和副本的数量，当集群的某个数据块存在副本数/设定的副本数的比值小于配置文件中的最小副本率，这个时候集群会自动复制副本，对副本数进行补充，如果多余设置的副本数目，那么集群就会删除多余的副本</p>
<p>hdfs第一次初始化启动的时候，没有任何的块信息，所以不会进入安全模式</p>
<p>进入安全模式以后，客户端不允许进行任何文件修改操作，包括删除、重命名、创建文件夹，但是可以进行目录浏览，查看文件内容的操作</p>
<blockquote>
<p>正常情况下，安全模式会运行一段时间自动退出的，只需要我们稍等一会就行了，我们可以通过50070端口查看安全模式退出的剩余时间</p>
</blockquote>
<p>通过命令行可以控制安全模式的进入和离开</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment">#查看安全模式状态</span>
hadoop fs -safemode get 
<span class="token comment">#进入安全模式状态</span>
hadoop fs -safemode enter  
<span class="token comment">#离开安全模式</span>
hadoop fs -safemode leave <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="基于zookeeper的高可用"><a href="#基于zookeeper的高可用" class="headerlink" title="基于zookeeper的高可用"></a>基于zookeeper的高可用</h2><blockquote>
<p>ZooKeeper Failover Controller：监控NameNode健康状态，并向Zookeeper注册NameNode；NameNode挂掉后，ZKFC为NameNode竞争锁，获得ZKFC 锁的NameNode变为active</p>
<p>watcher机制+建立临时节点</p>
</blockquote>
<p><img src="/images/20180312205533188" alt="这里写图片描述"></p>
<p><img src="/images/20180312203823704" alt="这里写图片描述"></p>
<ol>
<li>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务；</li>
<li>ZKFailoverController（主备切换控制器，FC）：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换（当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换）；</li>
<li>Zookeeper 集群：为主备切换控制器提供主备选举支持；</li>
<li>共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在<strong>确认元数据完全同步之后才能继续对外提供服务</strong>。</li>
<li>DataNode 节点：因为主 NameNode 和备 NameNode 需要共享 HDFS 的数据块和 DataNode 之间的映射关系，为了使故障切换能够快速进行，DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</li>
</ol>
<h3 id="ZKFC"><a href="#ZKFC" class="headerlink" title="ZKFC"></a>ZKFC</h3><p>为了支持故障转移，Hadoop引入两个新的组件：Zookeeper Quorum和ZKFailoverController process（简称ZKFC）</p>
<p>在每个Namenode守护进程的机器上，同时会运行一个ZKFC，用于完成以下任务：</p>
<ul>
<li>Namenode健康监控</li>
<li>ZK Session管理（会话机制，用于监控NameNode是否在线）</li>
<li>基于ZK的NameNode选举</li>
</ul>
<p>如果ZKFC所在机器的Namenode健康状态良好，并且用于选举的znode锁未被其他节点持有，则ZKFC会尝试获取锁,成功获取这个排它锁就代表获得选举，获得选举之后负责故障转移，如果有必要，会fencing掉之前的namenode使其不可用，然后将自己的namenode切换为Active状态</p>
<p>ZKFC 作为 NameNode 机器上一个独立的进程启动 ，它启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，其中：</p>
<ol>
<li>HealthMonitor：主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举；</li>
<li>ActiveStandbyElector：主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</li>
</ol>
<h3 id="自动触发主备选举"><a href="#自动触发主备选举" class="headerlink" title="自动触发主备选举"></a>自动触发主备选举</h3><p>NameNode 在选举成功后，会在 zk 上创建了一个 <code>/hadoop-ha/$&#123;dfs.nameservices&#125;/ActiveStandbyElectorLock</code> 节点，没有选举成功的NameNode 会监控这个节点，通过 Watcher 来监听这个节点的状态变化，ZKFC 的 ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件（这部分实现跟 Kafka 中 Controller 的选举一样）。</p>
<p>如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点 /hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock，这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建 /hadoop-ha/​${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。</p>
<p>当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。</p>
<p>Zookeeper的任务包括：</p>
<ul>
<li>失败检测：每个Namnode都在ZK中维护一个持久性session，如果Namnode故障，session过期，使用zk的事件机制通知（watcher机制）其他Namenode需要故障转移。</li>
<li>Namenode选举：如果当前Activenamenode挂了，另一个namenode会尝试获取ZK中的一个排它锁，获取这个锁就表名它将成为下一个Active NN</li>
</ul>
<h2 id="HDFS-脑裂问题"><a href="#HDFS-脑裂问题" class="headerlink" title="HDFS 脑裂问题"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/lushilin/p/11239908.html">HDFS 脑裂问题</a></h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/dadadechengzi/p/6715906.html">https://www.cnblogs.com/dadadechengzi/p/6715906.html</a></p>
<blockquote>
<p>在实际中，NameNode 可能会出现这种情况，NameNode 在垃圾回收（GC）时，可能会在长时间内整个系统无响应，因此，也就无法向 zk 写入心跳信息，这样的话可能会导致临时节点掉线，备 NameNode 会切换到 Active 状态，这种情况，可能会导致整个集群会有同时有两个 NameNode，这就是脑裂问题。</p>
</blockquote>
<p>脑裂问题的解决方案是隔离（Fencing），主要是在以下三处采用隔离措施：</p>
<ol>
<li>第三方共享存储：任一时刻，只有一个 NN 可以写入；</li>
<li>DataNode：需要保证只有一个 NN 发出与管理数据副本有关的删除命令；</li>
<li>Client：需要保证同一时刻只有一个 NN 能够对 Client 的请求发出正确的响应。</li>
<li><strong>生成一个新的 Epoch</strong>：Epoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制；产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：<ol>
<li>Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。</li>
<li>NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。</li>
<li>每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。</li>
<li>NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。</li>
</ol>
</li>
</ol>
<blockquote>
<p>在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。</p>
</blockquote>
<h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yeyazhishang/article/details/80758354">https://blog.csdn.net/yeyazhishang/article/details/80758354</a></p>
<p>CAP原则又称CAP定理，指的是在一个<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336">分布式系统</a>中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三个不能同时满足</p>
<p>一致性（C）：在<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336">分布式系统</a>中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</p>
<p>可用性（A）：保证每个请求不管成功或者失败都有响应。</p>
<p>分区容忍性（P）：系统中任意信息的丢失或失败不会影响系统的继续运作</p>
<blockquote>
<p>CAP的三选二是个伪命题，其实就是分布式系统二选一，在可用性和强一致性之间做抉择</p>
</blockquote>
<h3 id="CAP三个特性只能满足其中两个，那么取舍的策略就共有三种"><a href="#CAP三个特性只能满足其中两个，那么取舍的策略就共有三种" class="headerlink" title="CAP三个特性只能满足其中两个，那么取舍的策略就共有三种"></a>CAP三个特性只能满足其中两个，那么取舍的策略就共有三种</h3><p><strong>CA without P</strong>：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。</p>
<p><strong>CP without A</strong>：如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。</p>
<p><strong>AP wihtout C</strong>：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 <strong>A</strong>（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。</p>
<h3 id="Hdfs"><a href="#Hdfs" class="headerlink" title="Hdfs"></a>Hdfs</h3><p>从HDFS写数据的角度来说, 对于A和P和C都有取舍.</p>
<p>HDFS写数据是通过pipeline的方式来进行的, 我想目前市面上的很多文档对这个都有描述, 我就不细说了, 粗略说, 就是设HDFS的数据都有N=3个副本, 开始写数据时, NameNode会制定3个data node, 分别作为这3个副本的存储机器, 然后这3个机器通过socket串接在一起.<br>这里还有个”最小写副本数”的概念, 设这个值为MinN, 意思就是说, 当写成功MinN个副本, 就认为写成功了, 然后HDFS内部再会在后台异步将这个副本同步到其他的N - MinN个机器上, 最终形成N个副本.</p>
<p>那么回到开头, 为什么说HDFS其实对于A和P和C都会有取舍呢?</p>
<ol>
<li>如果MinN设为1, 那么其实就是牺牲了P; 因为这种情况下如果有写操作, pipeline管道只有1个data node, 写成功后, hdfs如果在同步这个副本到其他data node的过程中, 有这个block的data node坏掉了, 那么这个单副本的block数据就等于永久丢失了. 相当于无法保证P.</li>
<li>如果1 &lt; MinN &lt;= N, 比如MinN == N == 3, 那么这种情况下, pipeline管道中有3个data node都建立连接, 必须要同时写成功3个data node才会算作写成功, 在3个副本任一个副本没有确认写成功前, 写入的流数据(注意, 也是按照流数据, 将数据分做一个一个packet, 依次写入3个data node), 是无法被外部其他Client看到的, 这相当于牺牲了A.</li>
<li>最后说说, 为什么说也会牺牲C呢? 每个连入piepine的data node, 其正在被写入的block, 会记录一个当前已确认写入的数据的offset, 我们叫它ackOffset. 这个ackOffset, 决定了当有Client来本dataNode读取数据时, 可以返回给读Client能够读取的数据边界. ackOffset是如何确定的呢? 处于pipeline的最后一个data node, 将数据写入后(我记得不一定会flush磁盘到磁盘, 需要分场景), 更新当前自己的ackOffset, 然后会发送一个ack给它上游的data node; 上游data node收到这个ack后, 才会也更新自己的ackOffset, 然后同样发个ack给自己的上游data node.这个过程虽然很快, 但是理论上也会出现, 当ack在多个data node的pipeline中传递的过程中, 不同的Client读取不同的datanode, 导致读取的数据不一致的问题, 虽然概率会很小, 因为ack的传递会比较快.</li>
</ol>
<p>另外, hdfs设计为, 同一个block,同时只能有一个写Client, 相当于将这个block租给某一个client,这个就是lease租约机制; 这种情况下, 相当于牺牲了A(因为其他写Client不能进行), 得到了C(只有一个Client写, 所以对于写来说强一致性, 读仍是上面那一大段), 也得到了P.</p>
<p>当前的分布式系统, C主要指的是多个读如何做到一致性, 所以如果想做到强一致性, 那么只有写操作完全完成后, 才能让读操作看到，这样就相当于牺牲了A, 而保证了C强一致性，paxos等算法应该就是这个原理.</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">fuliangyu</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://fuliangyuzqm.github.io/2021/12/06/Hdfs/">https://fuliangyuzqm.github.io/2021/12/06/Hdfs/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">fuliangyu</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Hdfs/">
                                    <span class="chip bg-color">Hdfs</span>
                                </a>
                            
                                <a href="/tags/Hadoop/">
                                    <span class="chip bg-color">Hadoop</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: '9UNGkr3Dp4FiRz1sqecibL8f-gzGzoHsz',
        appKey: 'JxXPzxVqzEw4tHLe891YxU8o',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go'
    });
</script>

<!--酷Q推送-->


    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/12/06/Hbase/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/9.jpg" class="responsive-img" alt="Hbase">
                        
                        <span class="card-title">Hbase</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Hbase基础知识总结
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-12-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Hadoop/" class="post-category">
                                    Hadoop
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Hadoop/">
                        <span class="chip bg-color">Hadoop</span>
                    </a>
                    
                    <a href="/tags/Hbase/">
                        <span class="chip bg-color">Hbase</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/12/06/%E9%9D%A2%E7%BB%8Fother/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="面经other">
                        
                        <span class="card-title">面经other</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            面经-大数据开发工程师
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-12-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E9%9D%A2%E7%BB%8F/" class="post-category">
                                    面经
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E9%9D%A2%E7%BB%8F/">
                        <span class="chip bg-color">面经</span>
                    </a>
                    
                    <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">
                        <span class="chip bg-color">大数据开发</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: fuliangyu<br />'
            + '文章作者: fuliangyu<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1,h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1,h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2021-2022</span>
            
            <a href="/about" target="_blank">fuliangyu</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">134.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2021";
                        var startMonth = "12";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://fuliangyuzqm.github.io/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1719398791@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1719398791" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1719398791" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<!-- hexo injector body_end start --><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax  src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":300,"height":500,"hOffset":30,"vOffset":-10},"mobile":{"show":false},"react":{"opacity":1},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>
