<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="fuliangyu">
    <meta name="description" content="blog">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>fuliangyu</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">fuliangyu</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/gallery" class="waves-effect waves-light">
      
      <i class="fas fa-image" style="zoom: 0.6;"></i>
      
      <span>相册</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">fuliangyu</div>
        <div class="logo-desc">
            
            blog
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/gallery" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-image"></i>
			
			相册
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/fuliangyuZqm/fuliangyuZqm.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/fuliangyuZqm/fuliangyuZqm.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title"></h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-02-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-02-23
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    33.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    135 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><blockquote>
<p>pom</p>
</blockquote>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-core --></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>


       <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-scala --></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-streaming-scala_2.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
           <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="./pic/1684af007d1602ee" alt="img"></p>
<h2 id="流计算"><a href="#流计算" class="headerlink" title="流计算"></a>流计算</h2><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">//创建环境</span>
  <span class="token keyword">val</span> env<span class="token operator">=</span>ExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
  <span class="token keyword">val</span> wordCount<span class="token operator">=</span>env<span class="token punctuation">.</span>readTextFile<span class="token punctuation">(</span><span class="token string">"E:\\Drive\\MyOwn\\SynologyDrive\\BDCode\\flink\\src\\main\\resources\\data.txt"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
  wordCount<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">nc</span> -lp <span class="token number">9000</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h1 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h1><p><img src="./pic/image-20200930164106781.png" alt="image-20200930164106781"></p>
<blockquote>
<p>以上为 FlinkFlinkFlinkFlinkFlink的运行模型， Flink的程序主要由三部分构成，别为 Source、 Transformation、Sink。DataSource主要负责数据的读取，Transformation主要负责对 属于的转换操作，Sink负责最终数据的输出。 </p>
</blockquote>
<h2 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h2><blockquote>
<p>三种创建方式</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment StreamExecutionEnvironment<span class="token punctuation">.</span>createLocalEnvironment StreamExecutionEnvironment<span class="token punctuation">.</span>createRemoteEnvironment <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>本地环境</strong></p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">  <span class="token keyword">def</span> createLocalEnvironment<span class="token punctuation">(</span>parallelism<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> JavaEnv<span class="token punctuation">.</span>getDefaultLocalParallelism<span class="token punctuation">)</span><span class="token operator">:</span>
      StreamExecutionEnvironment <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">new</span> StreamExecutionEnvironment<span class="token punctuation">(</span>JavaEnv<span class="token punctuation">.</span>createLocalEnvironment<span class="token punctuation">(</span>parallelism<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>

<span class="token keyword">def</span> createLocalEnvironment<span class="token punctuation">(</span>parallelism<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> configuration<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span>
  StreamExecutionEnvironment <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">new</span> StreamExecutionEnvironment<span class="token punctuation">(</span>JavaEnv<span class="token punctuation">.</span>createLocalEnvironment<span class="token punctuation">(</span>parallelism<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>远程环境</strong></p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">//端口默认6123 </span>
<span class="token keyword">def</span> createRemoteEnvironment<span class="token punctuation">(</span>host<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> port<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> jarFiles<span class="token operator">:</span> <span class="token builtin">String</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">:</span>
  StreamExecutionEnvironment <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">new</span> StreamExecutionEnvironment<span class="token punctuation">(</span>JavaEnv<span class="token punctuation">.</span>createRemoteEnvironment<span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">,</span> jarFiles<span class="token operator">:</span> _<span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> env<span class="token operator">=</span>StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
<span class="token keyword">val</span> env<span class="token operator">=</span>ExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h2 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h2><h3 id="自定义集合取数据"><a href="#自定义集合取数据" class="headerlink" title="自定义集合取数据"></a>自定义集合取数据</h3><blockquote>
<p>从集合中创建一个数据流，集合中所有元素的类型是一致的</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment <span class="token keyword">val</span> list <span class="token operator">=</span> List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> 
<span class="token keyword">val</span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>list<span class="token punctuation">)</span> 
stream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span> 
env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"FirstJob"</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>从迭代(Iterator)中创建一个数据流，指定元素数据类型的类由 iterator 返回。</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment <span class="token keyword">val</span> iterator <span class="token operator">=</span> Iterator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> 
<span class="token keyword">val</span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>iterator<span class="token punctuation">)</span> 
stream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span> 
env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"FirstJob"</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>从给定的间隔中并行地产生一个数字序列。</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment <span class="token keyword">val</span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span>generateSequence<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> 
stream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span> 
env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"FirstJob"</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>从一个给定的对象序列中创建一个数据流，所有的对象必须是相同类型的。</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">case</span> <span class="token keyword">class</span> SensorReading<span class="token punctuation">(</span> id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> timestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> temperature<span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token punctuation">)</span>
   <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
   <span class="token keyword">val</span> stream1 <span class="token operator">=</span> env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
     SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">,</span> <span class="token number">1547718199</span><span class="token punctuation">,</span> <span class="token number">35.80018327300259</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_6"</span><span class="token punctuation">,</span> <span class="token number">1547718201</span><span class="token punctuation">,</span> <span class="token number">15.402984393403084</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_7"</span><span class="token punctuation">,</span> <span class="token number">1547718202</span><span class="token punctuation">,</span> <span class="token number">6.720945201171228</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_10"</span><span class="token punctuation">,</span> <span class="token number">1547718205</span><span class="token punctuation">,</span> <span class="token number">38.101067604893444</span><span class="token punctuation">)</span>
   <span class="token punctuation">)</span><span class="token punctuation">)</span>
   stream1<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"stream1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
   env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"SourceTest"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment <span class="token keyword">val</span> list <span class="token operator">=</span> List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> 
<span class="token keyword">val</span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span>fromElement<span class="token punctuation">(</span>list<span class="token punctuation">)</span> 
stream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span> 
env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"FirstJob"</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>从kafka读取数据</p>
</blockquote>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka-0.11_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"192.168.64.0:9092"</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"consumer-group"</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> stream3 <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaConsumer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="自定义source"><a href="#自定义source" class="headerlink" title="自定义source"></a>自定义source</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> stream4 <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">(</span><span class="token keyword">new</span> SensorSource<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> SensorSource<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> SourceFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">//定义一个flag，表示数据源是否正常运行</span>
  <span class="token keyword">var</span> running<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span>

  <span class="token comment">//生成数据</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> run<span class="token punctuation">(</span>ctx<span class="token operator">:</span> SourceFunction<span class="token punctuation">.</span>SourceContext<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//初始化随机数</span>
    <span class="token keyword">val</span> rand <span class="token operator">=</span> <span class="token keyword">new</span> Random<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//一组数据</span>
    <span class="token keyword">var</span> currentTemp <span class="token operator">=</span> <span class="token number">1.</span>to<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>
      i <span class="token keyword">=></span> <span class="token punctuation">(</span><span class="token string">"sensor_"</span> <span class="token operator">+</span> i<span class="token punctuation">,</span> <span class="token number">60</span> <span class="token operator">+</span> rand<span class="token punctuation">.</span>nextGaussian<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token comment">//无限生成一组数据</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span>running<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
      <span class="token comment">//在上一组数据基础上更新</span>
      currentTemp<span class="token operator">=</span>currentTemp<span class="token punctuation">.</span>map<span class="token punctuation">(</span>
        t<span class="token keyword">=></span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>t<span class="token punctuation">.</span>_2<span class="token operator">+</span>rand<span class="token punctuation">.</span>nextGaussian<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      <span class="token keyword">val</span> curTime<span class="token operator">=</span>System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span>
      currentTemp<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>
          <span class="token comment">//sourcefunction的上下文，将数据一条条发出去</span>
        t<span class="token keyword">=></span>ctx<span class="token punctuation">.</span>collect<span class="token punctuation">(</span>SensorReading<span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>curTime<span class="token punctuation">,</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      Thread<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">//停止数据生成</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> cancel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    running <span class="token operator">=</span> <span class="token boolean">false</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="TransForm"><a href="#TransForm" class="headerlink" title="TransForm"></a>TransForm</h2><h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><p><img src="./pic/image-20201006133828716.png" alt="image-20201006133828716"></p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> streamMap<span class="token operator">=</span> stream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=></span> x<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> flatMap<span class="token punctuation">[</span>A<span class="token punctuation">,</span>B<span class="token punctuation">]</span><span class="token punctuation">(</span>as<span class="token operator">:</span> List<span class="token punctuation">[</span>A<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>f<span class="token operator">:</span> A ⇒ List<span class="token punctuation">[</span>B<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> List<span class="token punctuation">[</span>B<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<blockquote>
<p> flatMap(List(1,2,3))(i ⇒ List(i,i)) ,结果是 List(1,1,2,2,3,3),</p>
<p> List(“a b”, “c d”).flatMap(line ⇒ line.split(“ “))  结果是 List(a, b, c, d)</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> STreamFlatMap<span class="token operator">=</span>stream<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>line<span class="token keyword">=></span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><p><img src="./pic/image-20201006143858905.png" alt="image-20201006143858905"></p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> streamFilter <span class="token operator">=</span> stream<span class="token punctuation">.</span>filter<span class="token punctuation">&#123;</span>
    <span class="token comment">//过滤为false的元素</span>
    x<span class="token keyword">=></span> x<span class="token operator">==</span><span class="token number">1</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="keyBy"><a href="#keyBy" class="headerlink" title="keyBy"></a>keyBy</h3><p><img src="./pic/image-20201006144746695.png" alt="image-20201006144746695"></p>
<blockquote>
<p><strong>DataStream → KeyedStream</strong>：逻辑地将一个流拆分成不相交的分区，每个分区包含具有相同 key 的元素，在内部以 hash 的形式实现的。</p>
<p>逻辑上将流分区为不相交的分区。具有相同Keys的所有记录都分配给同一分区。在内部，<em>keyBy（）</em>是使用散列分区实现的。<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https://flink.xskoo.com/dev/api_concepts.html%23specifying-keys">指定键</a>有不同的方法。</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">dataStream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token string">"someKey"</span><span class="token punctuation">)</span> <span class="token comment">// Key by field "someKey"</span>
dataStream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">// Key by the first element of a Tuple（数组）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="滚动聚合算子"><a href="#滚动聚合算子" class="headerlink" title="滚动聚合算子"></a>滚动聚合算子</h3><ol>
<li>sum()</li>
<li>min()</li>
<li>max()</li>
<li>minBy()</li>
<li>maxBy()</li>
</ol>
<p><strong>针对KeyedStream的每一个支流做聚合</strong></p>
<h3 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h3><blockquote>
<p><strong>KeyedStream → DataStream</strong>：一个分组数据流的聚合操作，合并当前的元素和上次聚合的结果，产生一个新的值，返回的流中包含每一次聚合的结果，而不是只返回最后一次聚合的最终结果。 </p>
<p><strong>合并每个支流的结果</strong></p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> dataStream<span class="token operator">=</span>streanFile
  <span class="token punctuation">.</span>map<span class="token punctuation">(</span>m <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> data <span class="token operator">=</span> m<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    SensorReading<span class="token punctuation">(</span>data<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> data<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> data<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">&#123;</span>
  <span class="token comment">//x是上一个元素，y是当前最新元素</span>
  SensorReading<span class="token punctuation">(</span>x<span class="token punctuation">.</span>id<span class="token punctuation">,</span>x<span class="token punctuation">.</span>timestamp<span class="token operator">+</span><span class="token number">100</span><span class="token punctuation">,</span>y<span class="token punctuation">.</span>temperature<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="split"><a href="#split" class="headerlink" title="split"></a>split</h3><p><img src="./pic/image-20201008123016852.png" alt="image-20201008123016852"></p>
<blockquote>
<p><strong>DataStream → SplitStream</strong>：根据某些特征把一个 DataStream 拆分成两个或者多个 DataStream。</p>
</blockquote>
<h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><blockquote>
<p><strong>SplitStream→DataStream</strong>：从一个 SplitStream 中获取一个或者多个 DataStream</p>
</blockquote>
<p><img src="./pic/image-20201008123234697.png" alt="image-20201008123234697"></p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><blockquote>
<p>传感器数据按照温度高低（以 50 度为界），拆分成两个流。</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> splitStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>split<span class="token punctuation">(</span>data <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>data<span class="token punctuation">.</span>temperature <span class="token operator">></span> <span class="token number">50</span><span class="token punctuation">)</span> Seq<span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">)</span>
  <span class="token keyword">else</span> Seq<span class="token punctuation">(</span><span class="token string">"low"</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> high <span class="token operator">=</span> splitStream<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> low <span class="token operator">=</span> splitStream<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"low"</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> all <span class="token operator">=</span> splitStream<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">,</span> <span class="token string">"low"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Connect"><a href="#Connect" class="headerlink" title="Connect"></a>Connect</h3><p><img src="./pic/image-20201008124307961.png" alt="image-20201008124307961"></p>
<blockquote>
<p><strong>DataStream,DataStream → ConnectedStreams</strong>：连接两个保持他们类型的数据流，两个数据流被 Connect 之后，只是被放在了一个同一个流中，<strong>内部依然保持各自的数据和形式不发生任何变化，两个流相互独立</strong></p>
</blockquote>
<h3 id="CoMap-CoFlatMap"><a href="#CoMap-CoFlatMap" class="headerlink" title="CoMap,CoFlatMap"></a>CoMap,CoFlatMap</h3><p><img src="./pic/image-20201008124453793.png" alt="image-20201008124453793"></p>
<blockquote>
<p>ConnectedStreams → DataStream：作用于 ConnectedStreams 上，功能与 map和 flatMap 一样，对 ConnectedStreams 中的每一个 Stream 分别进行 map 和 flatMap进行处理</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">   <span class="token keyword">val</span> high <span class="token operator">=</span> splitStream<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> low <span class="token operator">=</span> splitStream<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"low"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> all <span class="token operator">=</span> splitStream<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"high"</span><span class="token punctuation">,</span> <span class="token string">"low"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> warning<span class="token operator">=</span>high<span class="token punctuation">.</span>map<span class="token punctuation">(</span>m<span class="token keyword">=></span><span class="token punctuation">&#123;</span>
      <span class="token punctuation">(</span>m<span class="token punctuation">.</span>id<span class="token punctuation">,</span>m<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> connectStream<span class="token operator">=</span>warning<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>low<span class="token punctuation">)</span>
    <span class="token keyword">val</span> comMapDataStream<span class="token operator">=</span>connectStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>warningData<span class="token keyword">=></span>
      <span class="token punctuation">(</span>warningData<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>warningData<span class="token punctuation">.</span>_2<span class="token punctuation">,</span><span class="token string">"warning"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      lowData<span class="token keyword">=></span><span class="token punctuation">(</span>lowData<span class="token punctuation">.</span>id<span class="token punctuation">,</span><span class="token string">"healthy"</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
comMapDataStream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"comMapDataStream"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(sensor_1,38.56854465487693,warning)
(sensor_4,42.356323871177565,warning)
(sensor_4,43.61364062901137,warning)
(sensor_5,63.97493547610013,warning)
(sensor_3,healthy)
(sensor_3,healthy)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h3><p><img src="./pic/image-20201008130351170.png" alt="image-20201008130351170"></p>
<blockquote>
<p>connect只能合并两条流(格式不一样的)，union可以合并多个流(数据结构一样)</p>
<p>DataStream → DataStream：对两个或者两个以上的 DataStream 进行 union 操作，产生一个包含所有 DataStream 元素的新 DataStream。 </p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">high<span class="token punctuation">.</span>union<span class="token punctuation">(</span>low<span class="token punctuation">)</span><span class="token punctuation">.</span>union<span class="token punctuation">(</span>other<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<ol>
<li><p> Union 之前两个流的类型必须是一样，Connect 可以不一样，在之后的 coMap中再去调整成为一样的。</p>
</li>
<li><p> Connect 只能操作两个流，Union 可以操作多个。</p>
</li>
</ol>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p><strong>Flink 支持 Java 和 Scala 中所有常见数据类型</strong>。使用最广泛的类型有以下几种。</p>
<p>**Flink 对 Java 和 Scala 中的一些特殊目的的类型也都是支持的，比如 Java 的ArrayList，HashMap，Enum 等等。 **</p>
<h3 id="样例类"><a href="#样例类" class="headerlink" title="样例类"></a>样例类</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h2><h3 id="函数类（Function-Classes）"><a href="#函数类（Function-Classes）" class="headerlink" title="函数类（Function Classes）"></a>函数类（Function Classes）</h3><blockquote>
<p>**Flink 暴露了所有 udf 函数的接口(实现方式为接口或者抽象类)**，例如MapFunction, FilterFunction, ProcessFunction 等等</p>
</blockquote>
<h4 id="FilterFunction接口"><a href="#FilterFunction接口" class="headerlink" title="FilterFunction接口"></a>FilterFunction接口</h4><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> FilterFilter <span class="token keyword">extends</span> FilterFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> filter<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    value<span class="token punctuation">.</span>id<span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span class="token keyword">val</span> flinkTweets <span class="token operator">=</span> tweets<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token keyword">new</span> FlinkFilter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>匿名类</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">high<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token keyword">new</span> RichFilterFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">&#123;</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> filter<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    value<span class="token punctuation">.</span>id<span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>外部传参</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> FilterFilter<span class="token punctuation">(</span>key<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> FilterFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> filter<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    value<span class="token punctuation">.</span>id<span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span>key<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
high<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token keyword">new</span> FilterFilter<span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="富函数"><a href="#富函数" class="headerlink" title="富函数"></a>富函数</h3><p>**富函数”是 DataStream API 提供的一个函数类的接口，所有 Flink 函数类都有其 Rich 版本。它与常规函数的不同在于，可以获取运行环境的上下文，并拥有一些生命周期方法，包括状态编程，所以可以实现更复杂的功能。 **</p>
<blockquote>
<p><code>几乎所有算子都有对应的富函数</code></p>
</blockquote>
<ol>
<li><strong>open()方法是 rich function 的初始化方法，当一个算子例如 map 或者 filte被调用之前 open()会被调用。</strong></li>
<li><strong>close()方法是生命周期中的最后一个调用的方法，做一些清理工作。</strong></li>
<li><strong>getRuntimeContext()方法提供了函数的 RuntimeContext 的一些信息，例如函数执行的并行度，任务的名字，以及 state 状态</strong></li>
</ol>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">/**
 * Rich variant of the &#123;@link MapFunction&#125;. As a &#123;@link RichFunction&#125;, it gives access to the
 * &#123;@link org.apache.flink.api.common.functions.RuntimeContext&#125; and provides setup and teardown methods:
 * &#123;@link RichFunction#open(org.apache.flink.configuration.Configuration)&#125; and
 * &#123;@link RichFunction#close()&#125;.
 *
 * @param &lt;IN> Type of the input elements.
 * @param &lt;OUT> Type of the returned elements.
 */</span>
<span class="token annotation punctuation">@Public</span>
public <span class="token keyword">abstract</span> <span class="token keyword">class</span> RichMapFunction<span class="token generics"><span class="token punctuation">&lt;</span>IN<span class="token punctuation">,</span> OUT<span class="token punctuation">></span></span> <span class="token keyword">extends</span> AbstractRichFunction implements MapFunction<span class="token generics"><span class="token punctuation">&lt;</span>IN<span class="token punctuation">,</span> OUT<span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>

	<span class="token keyword">private</span> static <span class="token keyword">final</span> long serialVersionUID <span class="token operator">=</span> <span class="token number">1L</span><span class="token punctuation">;</span>

	<span class="token annotation punctuation">@Override</span>
	public <span class="token keyword">abstract</span> OUT map<span class="token punctuation">(</span>IN value<span class="token punctuation">)</span> throws Exception<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="./pic/image-20201008132937574.png" alt="image-20201008132937574"></p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">var</span> subTaskIndex<span class="token operator">=</span><span class="token number">0</span>
 <span class="token keyword">override</span> <span class="token keyword">def</span> open<span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
   subTaskIndex <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getIndexOfThisSubtask
   <span class="token comment">// 以下可以做一些初始化工作，例如建立一个和 HDFS的连接 </span>
 <span class="token punctuation">&#125;</span>
 <span class="token keyword">override</span> <span class="token keyword">def</span> close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
   <span class="token comment">// 以下做一些清理工作，例如断开和 HDFS的连接。 </span>
 <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><blockquote>
<p>Flink 没有类似于 spark 中 foreach 方法，让用户进行迭代的操作。虽有对外的输出操作都要利用 Sink 完成。最后通过类似如下方式完成整个任务最终输出操作。</p>
<p>除了官方定义的方法，其余都需要我们自己实现</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">stream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span><span class="token keyword">new</span> MySink<span class="token punctuation">(</span>xxxx<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="./pic/image-20201008133636977.png" alt="image-20201008133636977"></p>
<p><img src="./pic/image-20201008133650579.png" alt="image-20201008133650579"></p>
<h3 id="kdfka"><a href="#kdfka" class="headerlink" title="kdfka"></a>kdfka</h3><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka-0.11_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> union <span class="token operator">=</span> high<span class="token punctuation">.</span>union<span class="token punctuation">(</span>low<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>temperature<span class="token punctuation">.</span>toString<span class="token punctuation">)</span> 

union<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"localhost:9092"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.bahir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-redis_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>定义一个 redis 的 mapper 类，用于定义保存到 redis 时调用的命令：</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> MyRedissMap<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> RedisMapper<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">&#123;</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> getCommandDescription<span class="token operator">:</span> RedisCommandDescription <span class="token operator">=</span><span class="token punctuation">&#123;</span>
    <span class="token keyword">new</span> RedisCommandDescription<span class="token punctuation">(</span>RedisCommand<span class="token punctuation">.</span>HSET<span class="token punctuation">,</span><span class="token string">"seneor_temp"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> getKeyFromData<span class="token punctuation">(</span>data<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    data<span class="token punctuation">.</span>id
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> getValueFromData<span class="token punctuation">(</span>data<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    data<span class="token punctuation">.</span>temperature<span class="token punctuation">.</span>toString
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>主函数</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> FlinkJedisPoolConfig<span class="token punctuation">.</span>Builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setHost<span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setPort<span class="token punctuation">(</span><span class="token number">6379</span><span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span><span class="token punctuation">)</span> 
dataStream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span> <span class="token keyword">new</span> RedisSink<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> <span class="token keyword">new</span> MyRedissMap<span class="token punctuation">)</span> <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-elasticsearch6_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.7.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    
  <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
  env<span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> streanFile <span class="token operator">=</span> env<span class="token punctuation">.</span>readTextFile<span class="token punctuation">(</span><span class="token string">"F:\\SynologyDrive\\BDCode\\flink\\src\\main\\resources\\data.txt"</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> dataStream <span class="token operator">=</span> streanFile
    <span class="token punctuation">.</span>map<span class="token punctuation">(</span>m <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">val</span> data <span class="token operator">=</span> m<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
      SensorReading<span class="token punctuation">(</span>data<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> data<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> data<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
  
  <span class="token keyword">val</span> httpHosts <span class="token operator">=</span> <span class="token keyword">new</span> util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">[</span>HttpHost<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  httpHosts<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token keyword">new</span> HttpHost<span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">9200</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token comment">// 创建一个esSink 的builder</span>
  <span class="token keyword">val</span> esSinkBuilder <span class="token operator">=</span> <span class="token keyword">new</span> ElasticsearchSink<span class="token punctuation">.</span>Builder<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">(</span>
    httpHosts<span class="token punctuation">,</span>
    <span class="token keyword">new</span> ElasticsearchSinkFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">override</span> <span class="token keyword">def</span> process<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> ctx<span class="token operator">:</span> RuntimeContext<span class="token punctuation">,</span> indexer<span class="token operator">:</span> RequestIndexer<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        println<span class="token punctuation">(</span><span class="token string">"saving data: "</span> <span class="token operator">+</span> element<span class="token punctuation">)</span>
        <span class="token comment">// 包装成一个Map或者JsonObject</span>
        <span class="token keyword">val</span> json <span class="token operator">=</span> <span class="token keyword">new</span> util<span class="token punctuation">.</span>HashMap<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        json<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"sensor_id"</span><span class="token punctuation">,</span> element<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
        json<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"temperature"</span><span class="token punctuation">,</span> element<span class="token punctuation">.</span>temperature<span class="token punctuation">.</span>toString<span class="token punctuation">)</span>
        json<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"ts"</span><span class="token punctuation">,</span> element<span class="token punctuation">.</span>timestamp<span class="token punctuation">.</span>toString<span class="token punctuation">)</span>

        <span class="token comment">// 创建index request，准备发送数据</span>
        <span class="token keyword">val</span> indexRequest <span class="token operator">=</span> Requests<span class="token punctuation">.</span>indexRequest<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token string">"sensor"</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>`<span class="token keyword">type</span>`<span class="token punctuation">(</span><span class="token string">"readingdata"</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>source<span class="token punctuation">(</span>json<span class="token punctuation">)</span>

        <span class="token comment">// 利用index发送请求，写入数据</span>
        indexer<span class="token punctuation">.</span>add<span class="token punctuation">(</span>indexRequest<span class="token punctuation">)</span>
        println<span class="token punctuation">(</span><span class="token string">"data saved."</span><span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">)</span>

  <span class="token comment">// sink</span>
  dataStream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span> esSinkBuilder<span class="token punctuation">.</span>build<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>

  env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"es sink test"</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">></span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">></span></span>mysql<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">></span></span>mysql<span class="token operator">-</span>connector<span class="token operator">-</span>java<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">></span></span><span class="token number">5.1</span><span class="token number">.44</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> MyJdbcSink<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> RichSinkFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">&#123;</span>
  <span class="token comment">// 定义sql连接、预编译器</span>
  <span class="token keyword">var</span> conn<span class="token operator">:</span> Connection <span class="token operator">=</span> _
  <span class="token keyword">var</span> insertStmt<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> _
  <span class="token keyword">var</span> updateStmt<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> _

  <span class="token comment">// 初始化，创建连接和预编译语句</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> open<span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">super</span><span class="token punctuation">.</span>open<span class="token punctuation">(</span>parameters<span class="token punctuation">)</span>
    conn <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">"jdbc:mysql://localhost:3306/test"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span>
      <span class="token comment">//预编译语句</span>
    insertStmt <span class="token operator">=</span> conn<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span><span class="token string">"INSERT INTO temperatures (sensor, temp) VALUES (?,?)"</span><span class="token punctuation">)</span>
    updateStmt <span class="token operator">=</span> conn<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span><span class="token string">"UPDATE temperatures SET temp = ? WHERE sensor = ?"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">// 调用连接，执行sql</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> invoke<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> context<span class="token operator">:</span> SinkFunction<span class="token punctuation">.</span>Context<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// 执行更新语句</span>
    updateStmt<span class="token punctuation">.</span>setDouble<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span>
    updateStmt<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
    updateStmt<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 如果update没有查到数据，那么执行插入语句</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span> updateStmt<span class="token punctuation">.</span>getUpdateCount <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
      insertStmt<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
      insertStmt<span class="token punctuation">.</span>setDouble<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span>
      insertStmt<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">// 关闭时做清理工作</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    insertStmt<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    updateStmt<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
  env<span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

  <span class="token comment">// source</span>
  <span class="token keyword">val</span> inputStream <span class="token operator">=</span> env<span class="token punctuation">.</span>readTextFile<span class="token punctuation">(</span><span class="token string">"D:\\Projects\\BigData\\FlinkTutorial\\src\\main\\resources\\sensor.txt"</span><span class="token punctuation">)</span>

  <span class="token comment">// transform</span>
  <span class="token keyword">val</span> dataStream <span class="token operator">=</span> inputStream
    <span class="token punctuation">.</span>map<span class="token punctuation">(</span>
      data <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">val</span> dataArray <span class="token operator">=</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        SensorReading<span class="token punctuation">(</span>dataArray<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> dataArray<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> dataArray<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span>
    <span class="token punctuation">)</span>

  <span class="token comment">// sink</span>
  dataStream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span> <span class="token keyword">new</span> MyJdbcSink<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>

  env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"jdbc sink test"</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Flink运行组件"><a href="#Flink运行组件" class="headerlink" title="Flink运行组件"></a>Flink运行组件</h1><blockquote>
<p>Flink 运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作：作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager），以及分发器（Dispatcher）, Flink 是用 Java 和 Scala 实现的，所以所有组件都会运行在Java 虚拟机上。</p>
</blockquote>
<h2 id="JobManager-作业管理器"><a href="#JobManager-作业管理器" class="headerlink" title="JobManager(作业管理器)"></a>JobManager(作业管理器)</h2><blockquote>
<p>控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager 所控制执行。JobManager 会先接收到要执行的应用程序，<strong>这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR 包</strong>。</p>
<p>JobManager 会把JobGraph 转换成一个物理层面的数据流图，这个图被叫做 “执行图”（ExecutionGraph），包含了所有可以并发执行的任务。JobManager 会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager 上。而在运行过程中，JobManager 会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。 </p>
</blockquote>
<ul>
<li>接收要执行的应用程序——作业图、逻辑数据流图、Jar包、类</li>
<li>把JobGraph转成ExecutionGraph</li>
<li>向ResourceManager请求资源——TaskManager的slot</li>
<li>分发执行图，开始执行</li>
<li>运行中的中央协调</li>
</ul>
<h2 id="资源管理器（ResourceManager）"><a href="#资源管理器（ResourceManager）" class="headerlink" title="资源管理器（ResourceManager）"></a>资源管理器（ResourceManager）</h2><blockquote>
<p>主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger 插槽是 Flink 中定义的处理资源单元。Flink 为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s，以及 standalone 部署。</p>
<p>当JobManager 申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager 分配给JobManager。<strong>如果 ResourceManager 没有足够的插槽来满足 JobManager 的请求，它还可以向资源提供平台发起会话，以提供启动 TaskManager进程的容器</strong>。另外，ResourceManager 还负责终止空闲的 TaskManager，释放计算资源。 </p>
</blockquote>
<ul>
<li>给JobManager分配有空闲slot的TaskManager</li>
<li>终止空闲的TaskManager，释放计算资源</li>
</ul>
<h2 id="任务管理器（TaskManager）"><a href="#任务管理器（TaskManager）" class="headerlink" title="任务管理器（TaskManager）"></a>任务管理器（TaskManager）</h2><blockquote>
<p>Flink 中的工作进程。通常在 Flink 中会有多个 TaskManager 运行，每一个 TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了 TaskManager 能够执行的任务数量。启动之后，TaskManager 会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager 就会将一个或者多个插槽提供给 JobManager 调用。JobManager 就可以向插槽分配任务（tasks）来执行了。在执行过程中，一个TaskManager 可以跟其它运行同一应用程序的TaskManager 交换数据。 </p>
</blockquote>
<ul>
<li>一个TaskManager包含了多个slot</li>
<li>TaskManager向资源管理器注册slot</li>
<li>TaskManager将slot提供给JobManager</li>
<li>一个TaskManager 可以跟其它运行同一应用程序的TaskManager 交换数据</li>
<li> <strong>同一 slot中的线程共享相同的JVM。 同一JVM中的任务共享 TCP 连接和心跳消息。Task Manager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。默认情况下，Flink 允许子任务共享 Slot，即使它们是不同 task 的 subtask，只要它们来自相同的 job。这种共享可以有更好的资源利用率</strong></li>
</ul>
<p><img src=".%5Cpic%5CECv5y2.jpg" alt="img"></p>
<blockquote>
<p>上面图片中有两个 Task Manager，每个 Task Manager 有三个 slot，这样我们的算子最大并行度那么就可以达到 6 个，在同一个 slot 里面可以执行 1 至多个子任务。</p>
<p>那么再看上面的图片，source/map/keyby/window/apply 最大可以有 6 个并行度，sink 只用了 1 个并行。</p>
<p>每个 Flink TaskManager 在集群中提供 slot。 slot 的数量通常与每个 TaskManager 的可用 CPU 内核数成比例。<code>一般情况下你的 slot 数是你每个 TaskManager 的 cpu 的核数。</code></p>
<p>但是 flink 配置文件中设置的 task manager 默认的 slot 是 1。</p>
</blockquote>
<h2 id="分发器（Dispatcher）"><a href="#分发器（Dispatcher）" class="headerlink" title="分发器（Dispatcher）"></a>分发器（Dispatcher）</h2><blockquote>
<p>可以跨作业运行，它为应用提交提供了 REST 接口。当一个应用被提交执行时，分发器就会启动并将应用移交给一个 JobManager。由于是REST 接口，所以Dispatcher 可以作为集群的一个HTTP 接入点，这样就能够不受防火墙阻挡。Dispatcher 也会启动一个 Web UI，用来方便地展示和监控作业执行的信息。Dispatcher 在架构中可能并不是必需的，这取决于应用提交运行的方式。 </p>
</blockquote>
<ul>
<li>跨作业运行</li>
<li>当一个应用被提交执行时，分发器就会启动将应用移交给JobManager</li>
<li>Dispatch会启动一个UI，监控和展示作业的执行</li>
</ul>
<h1 id="Flink任务调度与执行"><a href="#Flink任务调度与执行" class="headerlink" title="Flink任务调度与执行"></a>Flink任务调度与执行</h1><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><blockquote>
<p>flink-conf.yaml</p>
</blockquote>
<h3 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#jobManager的IP地址</span>
<span class="token key atrule">jobmanager.rpc.address</span><span class="token punctuation">:</span> 47.88.89.63
<span class="token comment">#JobManager的端口号</span>
<span class="token key atrule">jobmanager.rpc.port</span><span class="token punctuation">:</span> <span class="token number">6123</span>

<span class="token comment">#JobManager JVM堆内存大小</span>
<span class="token key atrule">jobmanager.heap.size</span><span class="token punctuation">:</span> 1024m

<span class="token comment">#TaskManager JVM堆内存大小</span>
<span class="token key atrule">taskmanager.heap.size</span><span class="token punctuation">:</span> 1024m

<span class="token comment">#每个TaskManager提供的任务插槽数量大小</span>

<span class="token key atrule">taskmanager.numberOfTaskSlots</span><span class="token punctuation">:</span> <span class="token number">1</span>

<span class="token comment">#程序并行计算的个数</span>
<span class="token key atrule">parallelism.default</span><span class="token punctuation">:</span> <span class="token number">1</span>

<span class="token comment">#文件系统来源</span>
<span class="token comment">#fs.default-scheme</span>



<span class="token comment">#可以选择'NONE'或'zookeeper'。</span>
<span class="token comment">#高可用性：Zookeeper</span>

<span class="token comment">#文件系统路径，让Flink在高可用性设置中永久保存元数据</span>
<span class="token comment">#high-availability.storageDir：hdfs：/// flink / ha /</span>

<span class="token comment">#ip和端口扩展号</span>
<span class="token comment">#high-availability.zookeeper.quorum：本地主机：2181</span>

<span class="token comment">#默认是open，如果zookeeper security启用了该值会更改成creator </span>
<span class="token comment">#high-availability.zookeeper.client.acl：open</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>zoo.cfg</p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">＃每个tick的毫米数
tickTime &#x3D; 2000

＃初始同步阶段可以采用的tick数
initLimit &#x3D; 10

＃在发送请求和获取确认之间可以传递的tick数
syncLimit &#x3D; 5

＃存储快照的目录
＃dataDir &#x3D; &#x2F; tmp &#x2F; zookeeper

＃客户端将连接的端口
clientPort &#x3D; 2181

＃ZooKeeper仲裁对等端
server.1 &#x3D; localhost：2888：3888 
＃server.2 &#x3D; host：peer-port：leader-port
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="任务提交"><a href="#任务提交" class="headerlink" title="任务提交"></a>任务提交</h2><blockquote>
<p>任务提交和组件交互流程</p>
</blockquote>
<p><img src="./pic/image-20201015205852992.png" alt="image-20201015205852992"></p>
<blockquote>
<p>Yarn 模式任务提交流程</p>
</blockquote>
<p><img src="./pic/image-20201015210009774.png" alt="image-20201015210009774"></p>
<p><img src=".%5Cpic%5C11509359-1193ea0663aa9a60.png" alt="img"></p>
<blockquote>
<ol>
<li>Flink任务提交后，Client 向 HDFS 上传 Flink 的 Jar 包和配置到JobManager，</li>
<li>JobManager会将JobGraph转换为一个物理层面的数据流图（执行图：ExecutionGragh），包含了所有可以并发执行的任务，然后向 Yarn ResourceManager 申请资源</li>
<li>ResourceManager分配 Container资源并通知对应的NodeManager启动ApplicationMaster，ApplicationMaster 启动后加载 Flink 的 Jar 包和配置构建环境</li>
<li>ApplicationMaster向ResourceManager申请资源启动 TaskManager  </li>
<li>ResourceManager分配Container资源后，由ApplicationMaster通知资源所在节点的NodeManager启动 TaskManager </li>
<li>NodeManager 加载 Flink 的 Jar 包和配置构建环境并启动 TaskManager，TaskManager启动后向 JobManager 发送心跳包，并等待 JobManager 向其分配任务 </li>
<li>在运行过程中，JobManager会负责所有需要中央协调的操作，比如检查点（checkpoints)的协调</li>
</ol>
</blockquote>
<h2 id="架构和拓扑概览"><a href="#架构和拓扑概览" class="headerlink" title="架构和拓扑概览"></a>架构和拓扑概览</h2><p><img src=".%5Cpic%5CTB1ObBnJFXXXXXtXVXXXXXXXXXX" alt="img"></p>
<p>当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的 TaskManager。由 Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。<strong>上述三者均为独立的 JVM 进程</strong>。</p>
<ul>
<li><strong>Client</strong> 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager 环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming的任务），也可以不结束并等待结果返回。</li>
<li><strong>JobManager</strong> 主要负责调度 Job 并协调 Task 做 checkpoint，职责上很像 Storm 的 Nimbus。从 Client 处接收到 Job 和 JAR 包等资源后，会生成优化后的执行计划，并以 Task 的单元调度到各个 TaskManager 去执行。</li>
<li><strong>TaskManager</strong> 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动一个 Task，Task 为线程。从 JobManager 处接收需要部署的 Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理。</li>
</ul>
<p>可以看到 Flink 的任务调度是多线程模型，并且不同Job/Task混合在一个 TaskManager 进程中。虽然这种方式可以有效提高 CPU 利用率，但是个人不太喜欢这种设计，因为不仅缺乏资源隔离机制，同时也不方便调试。类似 Storm 的进程模型，一个JVM 中只跑该 Job 的 Tasks 实际应用中更为合理。</p>
<h2 id="job提交示例"><a href="#job提交示例" class="headerlink" title="job提交示例"></a>job提交示例</h2><p>我们使用 Flink 自带的 examples 包中的 <code>SocketTextStreamWordCount</code>，这是一个从 socket 流中统计单词出现次数的例子。</p>
<ul>
<li><p>首先，使用 <strong>netcat</strong> 启动本地服务器：</p>
<pre class="line-numbers language-none"><code class="language-none">$ nc -l 9000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>然后提交 Flink 程序</p>
<pre class="line-numbers language-none"><code class="language-none">$ bin&#x2F;flink run examples&#x2F;streaming&#x2F;SocketTextStreamWordCount.jar \
  --hostname 10.218.130.9 \
  --port 9000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
</ul>
<p>在netcat端输入单词并监控 taskmanager 的输出可以看到单词统计的结果。</p>
<p><code>SocketTextStreamWordCount</code> 的具体代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// 检查输入</span>
  <span class="token keyword">final</span> <span class="token class-name">ParameterTool</span> params <span class="token operator">=</span> <span class="token class-name">ParameterTool</span><span class="token punctuation">.</span><span class="token function">fromArgs</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

  <span class="token comment">// set up the execution environment</span>
  <span class="token keyword">final</span> <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// get input data</span>
  <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> text <span class="token operator">=</span>
      env<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"hostname"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> params<span class="token punctuation">.</span><span class="token function">getInt</span><span class="token punctuation">(</span><span class="token string">"port"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> counts <span class="token operator">=</span>
      <span class="token comment">// split up the lines in pairs (2-tuples) containing: (word,1)</span>
      text<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tokenizer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token comment">// group by the tuple field "0" and sum up tuple field "1"</span>
          <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  counts<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  
  <span class="token comment">// execute program</span>
  env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"WordCount from SocketTextStream Example"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>将最后一行代码 <code>env.execute</code> 替换成 <code>System.out.println(env.getExecutionPlan());</code> 并在本地运行该代码（并发度设为2），可以得到该拓扑的逻辑执行计划图的 JSON 串，将该 JSON 串粘贴到 <a target="_blank" rel="noopener" href="http://flink.apache.org/visualizer/">http://flink.apache.org/visualizer/</a> 中，能可视化该执行图。</p>
<img src=".\pic\TB1vB1uJFXXXXbaXpXXXXXXXXXX" alt="img" style="zoom:200%;" />

<p>但这并不是最终在 Flink 中运行的执行图，只是一个表示拓扑节点关系的计划图，在 Flink 中对应了 SteramGraph。另外，提交拓扑后（并发度设为2）还能在 UI 中看到另一张执行计划图，如下所示，该图对应了 Flink 中的 JobGraph。</p>
<p><img src=".%5Cpic%5CTB1QKR2JFXXXXbyaXXXXXXXXXXX" alt="img"></p>
<h3 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h3><p>Flink 中的执行图可以分成四层：StreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; 物理执行图。</p>
<ul>
<li><strong>StreamGraph：</strong>是用户通过 Stream API 编写的代码生成的最初的图，用来表示程序的拓扑结构。</li>
<li><strong>JobGraph：</strong>StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。</li>
<li><strong>ExecutionGraph：</strong>JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。</li>
<li><strong>物理执行图：</strong>JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。</li>
</ul>
<p>例如上文中的2个并发度（Source为1个并发度）的 <code>SocketTextStreamWordCount</code> 四层执行图的演变过程如下图所示：</p>
<img src=".\pic\TB1tA_GJFXXXXapXFXXXXXXXXXX" alt="img" style="zoom:200%;" />

<ul>
<li><p>StreamGraph：</p>
<p>根据用户通过 Stream API 编写的代码生成的最初的图。</p>
<ul>
<li>StreamNode：用来代表 operator 的类，并具有所有相关的属性，如并发度、入边和出边等。</li>
<li>StreamEdge：表示连接两个StreamNode的边。</li>
</ul>
</li>
<li><p>JobGraph：</p>
<p>StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。</p>
<ul>
<li>JobVertex：<strong>经过优化后符合条件的多个StreamNode可能会chain在一起生成一个JobVertex，即一个JobVertex包含一个或多个operator，JobVertex的输入是JobEdge，输出是IntermediateDataSet</strong>。</li>
<li>IntermediateDataSet：表示JobVertex的输出，即经过operator处理产生的数据集。producer是JobVertex，consumer是JobEdge。</li>
<li>JobEdge：代表了job graph中的一条数据传输通道。source 是 IntermediateDataSet，target 是 JobVertex。即数据通过JobEdge由IntermediateDataSet传递给目标JobVertex。</li>
<li>  JobEdge =&gt; JobVertex  =&gt; IntermediateDataSet =&gt; JobEdge 1</li>
</ul>
</li>
<li><p>ExecutionGraph：</p>
<p>JobManager 根据 JobGraph 生成ExecutionGraph。<strong>ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构</strong>。</p>
<ul>
<li>ExecutionJobVertex：和JobGraph中的JobVertex一一对应。每一个ExecutionJobVertex都有和并发度一样多的 ExecutionVertex。</li>
<li>ExecutionVertex：表示ExecutionJobVertex的其中一个并发子任务，输入是ExecutionEdge，输出是IntermediateResultPartition。</li>
<li>IntermediateResult：和JobGraph中的IntermediateDataSet一一对应。一个IntermediateResult包含多个IntermediateResultPartition，其个数等于该operator的并发度。</li>
<li>IntermediateResultPartition：表示ExecutionVertex的一个输出分区，producer是ExecutionVertex，consumer是若干个ExecutionEdge。</li>
<li>ExecutionEdge：表示ExecutionVertex的输入，source是IntermediateResultPartition，target是ExecutionVertex。source和target都只能是一个。</li>
<li>Execution：是执行一个 ExecutionVertex 的一次尝试。当发生故障或者数据需要重算的情况下 ExecutionVertex 可能会有多个 ExecutionAttemptID。一个 Execution 通过 ExecutionAttemptID 来唯一标识。JM和TM之间关于 task 的部署和 task status 的更新都是通过 ExecutionAttemptID 来确定消息接受者。</li>
</ul>
</li>
<li><p>物理执行图：</p>
<p>JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。</p>
<ul>
<li>Task：Execution被调度后在分配的 TaskManager 中启动对应的 Task。Task 包裹了具有用户执行逻辑的 operator。</li>
<li>ResultPartition：代表由一个Task的生成的数据，和ExecutionGraph中的IntermediateResultPartition一一对应。</li>
<li>ResultSubpartition：是ResultPartition的一个子分区。每个ResultPartition包含多个ResultSubpartition，其数目要由下游消费 Task 数和 DistributionPattern 来决定。</li>
<li>InputGate：代表Task的输入封装，和JobGraph中JobEdge一一对应。每个InputGate消费了一个或多个的ResultPartition。</li>
<li>InputChannel：每个InputGate会包含一个以上的InputChannel，和ExecutionGraph中的ExecutionEdge一一对应，也和ResultSubpartition一对一地相连，即一个InputChannel接收一个ResultSubpartition的输出。</li>
</ul>
</li>
</ul>
<blockquote>
<p> Spark 中也有多张图，数据依赖图以及物理执行的DAG。其目的都是一样的，就是解耦，每张图各司其职，每张图对应了 Job 不同的阶段，更方便做该阶段的事情。我们给出更完整的 Flink Graph 的层次图。</p>
<p><img src=".%5Cpic%5CTB1qmtpJVXXXXagXXXXXXXXXXXX" alt="img"></p>
<p>首先我们看到，JobGraph 之上除了 StreamGraph 还有 OptimizedPlan。OptimizedPlan 是由 Batch API 转换而来的。StreamGraph 是由 Stream API 转换而来的。为什么 API 不直接转换成 JobGraph？因为，Batch 和 Stream 的图结构和优化方法有很大的区别，比如 Batch 有很多执行前的预分析用来优化图的执行，而这种优化并不普适于 Stream，所以通过 OptimizedPlan 来做 Batch 的优化会更方便和清晰，也不会影响 Stream。JobGraph 的责任就是统一 Batch 和 Stream 的图，用来描述清楚一个拓扑图的结构，并且做了 chaining 的优化，chaining 是普适于 Batch 和 Stream 的，所以在这一层做掉。ExecutionGraph 的责任是方便调度和各个 tasks 状态的监控和跟踪，所以 <strong>ExecutionGraph 是并行化的 JobGraph</strong>。而“<strong>物理执行图”就是最终分布式在各个机器上运行着的tasks了</strong>。所以可以看到，这种解耦方式极大地方便了我们在各个层所做的工作，各个层之间是相互隔离的。</p>
</blockquote>
<h2 id="Graph-1"><a href="#Graph-1" class="headerlink" title="Graph"></a>Graph</h2><blockquote>
<p><strong>SrtreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; 物理执行图</strong> </p>
</blockquote>
<h3 id="StreamGraph"><a href="#StreamGraph" class="headerlink" title="StreamGraph"></a>StreamGraph</h3><blockquote>
<p>StreamGraph 相关的代码主要在 <code>org.apache.flink.streaming.api.graph</code> 包中。构造StreamGraph的入口函数是 <code>StreamGraphGenerator.generate(env, transformations)</code>。该函数会由触发程序执行的方法<code>StreamExecutionEnvironment.execute()</code>调用到。也就是说 StreamGraph 是在 Client 端构造的，这也意味着我们可以在本地通过调试观察 StreamGraph 的构造过程。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Internal</span>
<span class="token keyword">public</span> <span class="token class-name">StreamGraph</span> <span class="token function">getStreamGraph</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>transformations<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
		<span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalStateException</span><span class="token punctuation">(</span><span class="token string">"No operators defined in streaming topology. Cannot execute."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span>
	<span class="token keyword">return</span> <span class="token class-name">StreamGraphGenerator</span><span class="token punctuation">.</span><span class="token function">generate</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> transformations<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><code>StreamGraphGenerator.generate</code> 的一个关键的参数是 <code>List&lt;StreamTransformation&lt;?&gt;&gt;</code>。<code>StreamTransformation</code>代表了从一个或多个<code>DataStream</code>生成新<code>DataStream</code>的操作。<code>DataStream</code>的底层其实就是一个 <code>StreamTransformation</code>，描述了这个<code>DataStream</code>是怎么来的。</p>
</blockquote>
<p>StreamTransformation的类图如下图所示：</p>
<p><img src=".%5Cpic%5CTB1yQmNJFXXXXXnXpXXXXXXXXXX" alt="img"></p>
<p>transformation集成关系如下图所示：</p>
<p><img src=".%5Cpic%5C4999130-2f842b7548739c8f.png" alt="img"></p>
<p><strong>DataStream 上的每一个 Transformation 都对应了一个 StreamOperator</strong></p>
<p>DataStream 上常见的 transfor mation 有 map、flatmap、filter等（见<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/index.html#datastream-transformations">DataStream Transformation</a>了解更多）。这些transformation会构造出一棵 StreamTransformation 树，通过这棵树转换成 StreamGraph。比如 <code>DataStream.map</code>源码如下，其中<code>SingleOutputStreamOperator</code>为DataStream的子类</p>
<p>从上方代码可以了解到，map转换将用户自定义的函数<code>MapFunction</code>包装到<code>StreamMap</code>这个Operator中，再将<code>StreamMap</code>包装到<code>OneInputTransformation</code>，最后该transformation存到env中，当调用<code>env.execute</code>时，遍历其中的transformation集合构造出StreamGraph。其分层实现如下图所示：</p>
<blockquote>
<p>transform内会调用函数doTransform，在doTransform内，会将用户自定义的函数、输出类型、transformation，生成OneInputTransformation对象，同时将该Transformation对象，保存到StreamExecutionEnvironment类中的transformations列表内；</p>
</blockquote>
<p><img src=".%5Cpic%5CTB12u5yJFXXXXXhaXXXXXXXXXXX" alt="img"></p>
<p>另外，并不是每一个 StreamTransformation 都会转换成 runtime 层中物理操作。有一些只是逻辑概念，比如 union、split/select、partition等。如下图所示的转换树，在运行时会优化成下方的操作图。</p>
<p><img src=".%5Cpic%5CTB1XgmOJFXXXXaYXpXXXXXXXXXX" alt="img"></p>
<p>union、split/select、partition中的信息会被写入到 Source –&gt; Map 的边中。通过源码也可以发现，<code>UnionTransformation</code>,<code>SplitTransformation</code>,<code>SelectTransformation</code>,<code>PartitionTransformation</code>由于不包含具体的操作所以都没有StreamOperator成员变量，而其他StreamTransformation的子类基本上都有。</p>
<blockquote>
<p><strong>带有StreamOperator的算子同其它（select/union/relance）等算子相比，还有一个显著的不同；从上面tansformaion继承关系图中可以看到，在runtime时，会生成对应物理task的算子，都继承了PhysicalTransformation类，而实现了这个类的算子在运行中（默认情况下），flink会针对算子进行优化，通过将一些operator，按照一定的策略链接在一起，并放入到一个slot（task）上去运行，依次来避免在算子运行过程中带来的网络IO(数据从上一个operator到下一个operator)/线程切换带来的影响</strong></p>
</blockquote>
<p>我们通过在DataStream上做了一系列的转换（map、filter等）得到了StreamTransformation集合，然后通过<code>StreamGraphGenerator.generate</code>获得StreamGraph，该方法的源码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 构造 StreamGraph 入口函数</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">StreamGraph</span> <span class="token function">generate</span><span class="token punctuation">(</span><span class="token class-name">StreamExecutionEnvironment</span> env<span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StreamTransformation</span><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span><span class="token punctuation">></span></span> transformations<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">StreamGraphGenerator</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">generateInternal</span><span class="token punctuation">(</span>transformations<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token comment">// 自底向上（sink->source）对转换树的每个transformation进行转换。</span>
<span class="token keyword">private</span> <span class="token class-name">StreamGraph</span> <span class="token function">generateInternal</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StreamTransformation</span><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span><span class="token punctuation">></span></span> transformations<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">StreamTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span> transformation<span class="token operator">:</span> transformations<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token function">transform</span><span class="token punctuation">(</span>transformation<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
  <span class="token keyword">return</span> streamGraph<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token comment">// 对具体的一个transformation进行转换，转换成 StreamGraph 中的 StreamNode 和 StreamEdge</span>
<span class="token comment">// 返回值为该transform的id集合，通常大小为1个（除FeedbackTransformation）</span>
<span class="token keyword">private</span> <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> <span class="token function">transform</span><span class="token punctuation">(</span><span class="token class-name">StreamTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span> transform<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  
  <span class="token comment">// 跳过已经转换过的transformation</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>alreadyTransformed<span class="token punctuation">.</span><span class="token function">containsKey</span><span class="token punctuation">(</span>transform<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> alreadyTransformed<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  LOG<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span><span class="token string">"Transforming "</span> <span class="token operator">+</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// 为了触发 MissingTypeInfo 的异常</span>
  transform<span class="token punctuation">.</span><span class="token function">getOutputType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> transformedIds<span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">OneInputTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformOnInputTransform</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">OneInputTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">TwoInputTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformTwoInputTransform</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">TwoInputTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">SourceTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformSource</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">SourceTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">SinkTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformSink</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">SinkTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">UnionTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformUnion</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">UnionTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">SplitTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformSplit</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">SplitTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">SelectTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformSelect</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">SelectTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">FeedbackTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformFeedback</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">FeedbackTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">CoFeedbackTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformCoFeedback</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">CoFeedbackTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>transform <span class="token keyword">instanceof</span> <span class="token class-name">PartitionTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    transformedIds <span class="token operator">=</span> <span class="token function">transformPartition</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">PartitionTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalStateException</span><span class="token punctuation">(</span><span class="token string">"Unknown transformation: "</span> <span class="token operator">+</span> transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">// need this check because the iterate transformation adds itself before</span>
  <span class="token comment">// transforming the feedback edges</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>alreadyTransformed<span class="token punctuation">.</span><span class="token function">containsKey</span><span class="token punctuation">(</span>transform<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    alreadyTransformed<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>transform<span class="token punctuation">,</span> transformedIds<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getBufferTimeout</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    streamGraph<span class="token punctuation">.</span><span class="token function">setBufferTimeout</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transform<span class="token punctuation">.</span><span class="token function">getBufferTimeout</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getUid</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    streamGraph<span class="token punctuation">.</span><span class="token function">setTransformationId</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transform<span class="token punctuation">.</span><span class="token function">getUid</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">return</span> transformedIds<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>最终都会调用 <code>transformXXX</code> 来对具体的StreamTransformation进行转换。我们可以看下<code>transformOnInputTransform(transform)</code>的实现：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token generics"><span class="token punctuation">&lt;</span>IN<span class="token punctuation">,</span> OUT<span class="token punctuation">></span></span> <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> <span class="token function">transformOnInputTransform</span><span class="token punctuation">(</span><span class="token class-name">OneInputTransformation</span><span class="token generics"><span class="token punctuation">&lt;</span>IN<span class="token punctuation">,</span> OUT<span class="token punctuation">></span></span> transform<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// 递归对该transform的直接上游transform进行转换，获得直接上游id集合</span>
  <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> inputIds <span class="token operator">=</span> <span class="token function">transform</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getInput</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// 递归调用可能已经处理过该transform了</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>alreadyTransformed<span class="token punctuation">.</span><span class="token function">containsKey</span><span class="token punctuation">(</span>transform<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> alreadyTransformed<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>transform<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token class-name">String</span> slotSharingGroup <span class="token operator">=</span> <span class="token function">determineSlotSharingGroup</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getSlotSharingGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> inputIds<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// 添加 StreamNode</span>
  streamGraph<span class="token punctuation">.</span><span class="token function">addOperator</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      slotSharingGroup<span class="token punctuation">,</span>
      transform<span class="token punctuation">.</span><span class="token function">getOperator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      transform<span class="token punctuation">.</span><span class="token function">getInputType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      transform<span class="token punctuation">.</span><span class="token function">getOutputType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      transform<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getStateKeySelector</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token class-name">TypeSerializer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span> keySerializer <span class="token operator">=</span> transform<span class="token punctuation">.</span><span class="token function">getStateKeyType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">createSerializer</span><span class="token punctuation">(</span>env<span class="token punctuation">.</span><span class="token function">getConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    streamGraph<span class="token punctuation">.</span><span class="token function">setOneInputStateKey</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transform<span class="token punctuation">.</span><span class="token function">getStateKeySelector</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keySerializer<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  streamGraph<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transform<span class="token punctuation">.</span><span class="token function">getParallelism</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// 添加 StreamEdge</span>
  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Integer</span> inputId<span class="token operator">:</span> inputIds<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    streamGraph<span class="token punctuation">.</span><span class="token function">addEdge</span><span class="token punctuation">(</span>inputId<span class="token punctuation">,</span> transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">return</span> <span class="token class-name">Collections</span><span class="token punctuation">.</span><span class="token function">singleton</span><span class="token punctuation">(</span>transform<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>如下程序，是一个从 Source 中按行切分成单词并过滤输出的简单流程序，其中包含了逻辑转换：随机分区shuffle。我们会分析该程序是如何生成StreamGraph的。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> text <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span>hostName<span class="token punctuation">,</span> port<span class="token punctuation">)</span><span class="token punctuation">;</span>
text<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">LineSplitter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">shuffle</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HelloFilter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>首先会在env中生成一棵transformation树，用<code>List&lt;StreamTransformation&lt;?&gt;&gt;</code>保存。其结构图如下：<img src=".%5Cpic%5CTB1w3SQJFXXXXalXVXXXXXXXXXX" alt="img"></p>
<blockquote>
<p>其中符号<code>*</code>为input指针，指向上游的transformation，从而形成了一棵transformation树。然后，通过调用<code>StreamGraphGenerator.generate(env, transformations)</code>来生成StreamGraph。自底向上递归调用每一个transformation，也就是说处理顺序是Source-&gt;FlatMap-&gt;Shuffle-&gt;Filter-&gt;Sink。</p>
</blockquote>
<img src=".\pic\TB1s7SpJFXXXXXjaXXXXXXXXXXX" alt="img" style="zoom:150%;" />

<ol>
<li>首先处理的Source，生成了Source的StreamNode。</li>
<li>然后处理的FlatMap，生成了FlatMap的StreamNode，并生成StreamEdge连接上游Source和FlatMap。<strong>由于上下游的并发度不一样（1:4），所以此处是Rebalance分区</strong>。</li>
<li>然后处理的Shuffle，<strong>由于是逻辑转换，并不会生成实际的节点</strong>。将partitioner信息暂存在<code>virtuaPartitionNodes</code>中。</li>
<li>在处理Filter时，生成了Filter的StreamNode。发现上游是shuffle，找到shuffle的上游FlatMap，创建StreamEdge与Filter相连。并把ShufflePartitioner的信息写到StreamEdge中。</li>
<li>最后处理Sink，创建Sink的StreamNode，并生成StreamEdge与上游Filter相连。由于上下游并发度一样（4:4），所以此处选择 Forward 分区。</li>
</ol>
<p><img src=".%5Cpic%5CTB1y_1FJFXXXXapaXXXXXXXXXXX" alt="img"></p>
<h3 id="JobGraph"><a href="#JobGraph" class="headerlink" title="JobGraph"></a>JobGraph</h3><p>根据用户用Stream API编写的程序，构造出一个代表拓扑结构的StreamGraph的。以 WordCount 为例，转换图如下图所示：</p>
<img src=".\pic\TB1DzYXJFXXXXXJXVXXXXXXXXXX" alt="img" style="zoom: 150%;" />

<blockquote>
<p>StreamGraph 和 JobGraph 都是在 Client 端生成的，也就是说我们可以在 IDE 中通过断点调试观察 StreamGraph 和 JobGraph 的生成过程。</p>
</blockquote>
<blockquote>
<p>JobGraph 的相关数据结构主要在 <code>org.apache.flink.runtime.jobgraph</code> 包中。构造 JobGraph 的代码主要集中在 <code>StreamingJobGraphGenerator</code> 类中，入口函数是 <code>StreamingJobGraphGenerator.createJobGraph()</code>。</p>
</blockquote>
<h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><ol>
<li>先给每个 StreamNode 生成一个唯一确定的 hash id；</li>
<li><code>setChaining()</code> 方法将可以 Chain 到一起的 StreamNode Chain 在一起，这里会生成相应的 JobVertex 、JobEdge 、 IntermediateDataSet 对象，JobGraph 的 Graph 在这一步就已经完全构建出来了；(<strong>StreamGraph 转换为 JobGraph 的处理过程主要是在 <code>setChaining()</code> 中完成</strong>)<ol>
<li>这段代码处理完成后，整个 JobGraph 就构建完成了，它首先从会遍历这个 StreamGraph 的 source 节点，然后选择从 source 节点开始执行 <code>createChain()</code> 方法，在具体的实现里，主要逻辑如下（需要配合前面的代码去看，这里会把多个 StreamNode Chain 在一起的 Node 叫做 ChainNode，方便讲述）：</li>
<li><code>createChain()</code> 当前要处理的节点是 <code>currentNodeId</code>，先从 StreamGraph 中拿到这个 StreamNode 的 outEdge（<code>currentNode.getOutEdges()</code>），然后判断这个 outEdge 连接的两个 StreamNode 是否可以 Chain 在一起，判断方法是 <code>isChainable()</code>；</li>
<li>紧接着会有一个递归调用：<ul>
<li>对于可以 Chain 在一起的 StreamEdge（这个 Edge 连接两个 StreamNode 是可以 Chain 在一起），会再次调用 <code>createChain()</code> 方法，并且 <code>createChain()</code> 中的 <code>startNodeId</code> 还是最开始的 <code>startNodeId</code>（这个标识了这个 ChainNode 的开始 NodeId），而 <code>chainIndex</code> 会自增加 1；</li>
<li>而对于不能 Chain 在一起的 StreamEdge，<code>createChain()</code> 中的 <code>startNodeId</code> 变成了这个 StreamEdge 的 target StreamNode（相当于如果 Chain 在一起，ChainNode 中的 startNodeId 会赋值为下一个节点的 NodeId，然后再依次类推），<code>chainIndex</code> 又从 0 开始计；</li>
<li>也就是说：<code>createChain()</code> 中的 <code>startNodeId</code> 表示了当前可以 Chain 之后 Node 的 startId，这里，会一直递归调用，直到达到 Sink 节点。</li>
</ul>
</li>
<li>然后在生成 <code>StreamConfig</code> 对象时，判断当前的 <code>currentNodeId</code> 与 <code>startNodeId</code> 是否相等，如果相等的话，证明当前 Node 就是这个 ChainNode 的 StartNode，这里会调用 <code>createJobVertex()</code> 方法给这个 ChainNode 创建一个 JobVertex 对象，最后会返回一个 StreamConfig 对象，如果前面的 id 不相等的话，这里会直接返回一个 StreamConfig 对象（这个对象主要是记录当前 StreamNode 的一些配置，它会同步 StreamGraph 中相关的配置）；</li>
<li>最后还会分两种情况判断：<ul>
<li>如果 id 相等，相当于这个 ChainNode 已经完成，先做一些相关的配置（比如：标识当前 StreamNode 为这个 JobVertex 的起始 node），最后再通过 <code>connect()</code> 方法创建 JobEdge 和 IntermediateDataSet 对象，把这个 Graph 连接起来；</li>
<li>如果 id 不相等，那么证明当前 StreamNode 只是这个 ChainNode 的一部分，这里只是同步一下信息，并记录到缓存。</li>
</ul>
</li>
<li>真正创建 JobEdge 和 IntermediateDataSet 对象是在 JobVertex 中的 <code>connectNewDataSetAsInput()</code> 方法中，在这里也会把 JobVertex、JobEdge、IntermediateDataSet 三者连接起来（JobGraph 的 graph 就是这样构建的）</li>
</ol>
</li>
<li><code>setPhysicalEdges()</code> 方法会将每个 JobVertex 的入边集合也序列化到该 JobVertex 的 StreamConfig 中 (出边集合已经在 setChaining 的时候写入了)；</li>
<li><code>setSlotSharingAndCoLocation()</code> 方法主要是 JobVertex 的 SlotSharingGroup 和 CoLocationGroup 设置；</li>
<li><code>configureCheckpointing()</code> 方法主要是 checkpoint 相关的设置。</li>
</ol>
<blockquote>
<p><code>StreamingJobGraphGenerator</code>的成员变量都是为了辅助生成最终的JobGraph。</p>
<p><code>createJobGraph()</code>函数的逻辑也很清晰，首先为所有节点生成一个唯一的hash id，如果节点在多次提交中没有改变（包括并发度、上下游等），那么这个id就不会改变，这主要用于故障恢复。这里我们不能用 <code>StreamNode.id</code>来代替，因为这是一个从1开始的静态计数变量，同样的Job可能会得到不一样的id，如下代码示例的两个job是完全一样的，但是source的id却不一样了。然后就是最关键的chaining处理，和生成JobVetex、JobEdge等。之后就是写入各种配置相关的信息。</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 范例1：A.id&#x3D;1  B.id&#x3D;2
DataStream&lt;String&gt; A &#x3D; ...
DataStream&lt;String&gt; B &#x3D; ...
A.union(B).print();
&#x2F;&#x2F; 范例2：A.id&#x3D;2  B.id&#x3D;1
DataStream&lt;String&gt; B &#x3D; ...
DataStream&lt;String&gt; A &#x3D; ...
A.union(B).print();<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</blockquote>
<p>在 StreamGraph 中，每一个算子（Operator） 对应了图中的一个节点（StreamNode）。StreamGraph 会被进一步优化，将多个符合条件的节点串联（Chain） 在一起形成一个节点，从而减少数据在不同节点之间流动所产生的序列化、反序列化、网络传输的开销。多个算子被 chain 在一起的形成的节点在 <code>JobGraph</code> 中对应的就是 <code>JobVertex</code></p>
<p>每个 <code>JobVertex</code> 中包含一个或多个 Operators。 <code>JobVertex</code> 的主要成员变量包括：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/** The ID of the vertex. */</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">JobVertexID</span> id<span class="token punctuation">;</span>
 
<span class="token comment">/** The alternative IDs of the vertex. */</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JobVertexID</span><span class="token punctuation">></span></span> idAlternatives <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">/** The IDs of all operators contained in this vertex. */</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">OperatorID</span><span class="token punctuation">></span></span> operatorIDs <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">/** The alternative IDs of all operators contained in this vertex. */</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">OperatorID</span><span class="token punctuation">></span></span> operatorIdsAlternatives <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">/** List of produced data sets, one per writer */</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">IntermediateDataSet</span><span class="token punctuation">></span></span> results <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">IntermediateDataSet</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">/** List of edges with incoming data. One per Reader. */</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JobEdge</span><span class="token punctuation">></span></span> inputs <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JobEdge</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">/** Number of subtasks to split this task into at runtime.*/</span>
<span class="token keyword">private</span> <span class="token keyword">int</span> parallelism <span class="token operator">=</span> <span class="token class-name">ExecutionConfig</span><span class="token punctuation">.</span>PARALLELISM_DEFAULT<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>两个 operator chain 在一起的的条件：</p>
<ol>
<li>上下游的并行度一致</li>
<li>下游节点的入度为 1 （也就是说下游节点没有来自其他节点的输入）</li>
<li>上下游节点都在同一个 slot group 中(Slot槽位共享)</li>
<li>下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter 等默认 是 ALWAYS）</li>
<li>上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接， Source 默认是 HEAD）</li>
<li>两个节点间数据分区方式是 forward</li>
<li>用户没有禁用chain</li>
</ol>
<p><code>JobVertex</code> 产生的数据被抽象为 <code>IntermediateDataSet</code>, 字面意思为<strong>中间数据集</strong>，这个很容易理解。前面提到，<code>JobEdge</code> 是和节点的输出结果相关联的，其实就是指可以把 <code>JobEdge</code> 看作是 <code>IntermediateDataSet</code> 的消费者，那么 <code>JobVertex</code> 自然就是生产者了。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">IntermediateDataSetID</span> id<span class="token punctuation">;</span> <span class="token comment">// the identifier</span>
 
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">JobVertex</span> producer<span class="token punctuation">;</span>	<span class="token comment">// the operation that produced this data set</span>
 
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JobEdge</span><span class="token punctuation">></span></span> consumers <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JobEdge</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">// The type of partition to use at runtime</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ResultPartitionType</span> resultType<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>每个 JobVertex 都会对应一个可序列化的 StreamConfig, 用来发送给 JobManager 和 TaskManager。最后在 TaskManager 中起 Task 时,需要从这里面反序列化出所需要的配置信息, 其中就包括了含有用户代码的StreamOperator。</p>
<p><code>setChaining</code>会对source调用<code>createChain</code>方法，该方法会递归调用下游节点，从而构建出node chains。<code>createChain</code>会分析当前节点的出边，根据<a target="_blank" rel="noopener" href="http://wuchong.me/blog/2016/05/09/flink-internals-understanding-execution-resources/#Operator-Chains">Operator Chains</a>中的chainable条件，将出边分成chainalbe和noChainable两类，并分别递归调用自身方法。之后会将StreamNode中的配置信息序列化到StreamConfig中。如果当前不是chain中的子节点，则会构建 JobVertex 和 JobEdge相连。如果是chain中的子节点，则会将StreamConfig添加到该chain的config集合中。一个node chains，除了 headOfChain node会生成对应的 JobVertex，其余的nodes都是以序列化的形式写入到StreamConfig中，并保存到headOfChain的 <code>CHAINED_TASK_CONFIG</code> 配置项中。直到部署时，才会取出并生成对应的ChainOperators，具体过程请见<a target="_blank" rel="noopener" href="http://wuchong.me/blog/2016/05/09/flink-internals-understanding-execution-resources/#Operator-Chains">理解 Operator Chains</a>。</p>
</blockquote>
<p>对于每一个 <code>StreamOperator</code>, 也就是 <code>StreamGraph</code> 中的每一个 <code>StreamNode</code>, 在生成 <code>JobGraph</code> 的过程中 <code>StreamingJobGraphGenerator</code> 都会创建一个对应的 <code>StreamConfig</code>。</p>
<p><code>StreamConfig</code> 中保存了这个算子（operator） 在运行是需要的所有配置信息，这些信息都是通过 key/value 的形式存储在 <code>Configuration</code> 中的。例如： </p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token comment">//保存StreamOperator信息</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setStreamOperator</span><span class="token punctuation">(</span><span class="token class-name">StreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">></span></span> operator<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>operator <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        config<span class="token punctuation">.</span><span class="token function">setClass</span><span class="token punctuation">(</span>USER_FUNCTION<span class="token punctuation">,</span> operator<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
        <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">InstantiationUtil</span><span class="token punctuation">.</span><span class="token function">writeObjectToConfig</span><span class="token punctuation">(</span>operator<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">.</span>config<span class="token punctuation">,</span> SERIALIZEDUDF<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">StreamTaskException</span><span class="token punctuation">(</span><span class="token string">"Cannot serialize operator object "</span>
                                        <span class="token operator">+</span> operator<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"."</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
 
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setChainedOutputs</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StreamEdge</span><span class="token punctuation">></span></span> chainedOutputs<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">InstantiationUtil</span><span class="token punctuation">.</span><span class="token function">writeObjectToConfig</span><span class="token punctuation">(</span>chainedOutputs<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">.</span>config<span class="token punctuation">,</span> CHAINED_OUTPUTS<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">StreamTaskException</span><span class="token punctuation">(</span><span class="token string">"Cannot serialize chained outputs."</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
 
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setNonChainedOutputs</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StreamEdge</span><span class="token punctuation">></span></span> outputvertexIDs<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">InstantiationUtil</span><span class="token punctuation">.</span><span class="token function">writeObjectToConfig</span><span class="token punctuation">(</span>outputvertexIDs<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">.</span>config<span class="token punctuation">,</span> NONCHAINED_OUTPUTS<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">StreamTaskException</span><span class="token punctuation">(</span><span class="token string">"Cannot serialize non chained outputs."</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
 
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setInPhysicalEdges</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StreamEdge</span><span class="token punctuation">></span></span> inEdges<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">InstantiationUtil</span><span class="token punctuation">.</span><span class="token function">writeObjectToConfig</span><span class="token punctuation">(</span>inEdges<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">.</span>config<span class="token punctuation">,</span> IN_STREAM_EDGES<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">StreamTaskException</span><span class="token punctuation">(</span><span class="token string">"Cannot serialize inward edges."</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
 
<span class="token comment">//......</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><a target="_blank" rel="noopener" href="https://www.freesion.com/article/65801055874/">作业转换</a></li>
<li><a target="_blank" rel="noopener" href="https://matt33.com/2019/12/09/flink-job-graph-3/">Flink转换JobGraph</a></li>
</ul>
<img src=".\pic\image-20201027142956344.png" alt="image-20201027142956344" style="zoom:200%;" />



<h3 id="ExecutionGraph"><a href="#ExecutionGraph" class="headerlink" title="ExecutionGraph"></a>ExecutionGraph</h3><blockquote>
<p>和 <code>StreamGraph</code> 以及 <code>JobGraph</code> 不同的是，<code>ExecutionGraph</code> 是在 JobManager 中生成的。 Client 向 JobManager 提交 <code>JobGraph</code> 后， JobManager 就会根据 <code>JobGraph</code> 来创建对应的 <code>ExecutionGraph</code>,并以此来调度任务</p>
</blockquote>
<h4 id="ExecutionJobVertex"><a href="#ExecutionJobVertex" class="headerlink" title="ExecutionJobVertex"></a>ExecutionJobVertex</h4><p>在 <code>ExecutionGraph</code> 中，节点对应的类是 <code>ExecutionJobVertex</code>，与之对应的就是 <code>JobGraph</code> 中的 <code>JobVertex</code>。每一个 <code>ExexutionJobVertex</code> 都是由一个 <code>JobVertex</code> 生成的。</p>
<h4 id="ExecutionVertex"><a href="#ExecutionVertex" class="headerlink" title="ExecutionVertex"></a>ExecutionVertex</h4><p><code>ExexutionJobVertex</code> 的成员变量中包含一个 <code>ExecutionVertex</code> 数组。我们知道，Flink Job 是可以指定任务的并行度的，在实际运行时，会有多个并行的任务同时在执行，对应到这里就是 <code>ExecutionVertex</code>。<code>ExecutionVertex</code> 是并行任务的一个子任务，算子的并行度是多少，那么就会有多少个 <code>ExecutionVertex</code>。</p>
<h4 id="Execution"><a href="#Execution" class="headerlink" title="Execution"></a>Execution</h4><p><code>Execution</code> 是对 <code>ExecutionVertex</code> 的一次执行，通过 <code>ExecutionAttemptId</code> 来唯一标识。</p>
<h4 id="IntermediateResult"><a href="#IntermediateResult" class="headerlink" title="IntermediateResult"></a>IntermediateResult</h4><p>在 <code>JobGraph</code> 中用 <code>IntermediateDataSet</code> 表示 <code>JobVertex</code> 的对外输出，一个 <code>JobGraph</code> 可能有 n(n &gt;=0) 个输出。在 <code>ExecutionGraph</code> 中，与此对应的就是 <code>IntermediateResult</code>。</p>
<blockquote>
<p>由于 <code>ExecutionJobVertex</code> 有 numParallelProducers 个并行的子任务，自然对应的每一个 <code>IntermediateResult</code> 就有 numParallelProducers 个生产者，每个生产者的在相应的 <code>IntermediateResult</code> 上的输出对应一个 <code>IntermediateResultPartition</code>。<code>IntermediateResultPartition</code> 表示的是 <code>ExecutionVertex</code> 的一个输出分区，即：</p>
<pre class="line-numbers language-none"><code class="language-none">ExecutionJobVertex --&gt;  IntermediateResult

ExecutionVertex --&gt;  IntermediateResultPartition<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>一个 <code>ExecutionJobVertex</code> 可能包含多个（n） 个 <code>IntermediateResult</code>， 那实际上每一个并行的子任务 <code>ExecutionVertex</code> 可能会包含（n） 个 <code>IntermediateResultPartition</code>。</p>
<p><code>IntermediateResultPartition</code> 的生产者是 <code>ExecutionVertex</code>，消费者是一个或若干个 <code>ExecutionEdge</code>。</p>
</blockquote>
<h4 id="ExecutionEdge"><a href="#ExecutionEdge" class="headerlink" title="ExecutionEdge"></a>ExecutionEdge</h4><p><code>ExecutionEdge</code> 表示 <code>ExecutionVertex</code> 的输入，通过 <code>ExecutionEdge</code> 将 <code>ExecutionVertex</code> 和 <code>IntermediateResultPartition</code> 连接起来，进而在不同的 <code>ExecutionVertex</code> 之间建立联系。</p>
<h4 id="构建-ExecutionGraph-的流程"><a href="#构建-ExecutionGraph-的流程" class="headerlink" title="构建 ExecutionGraph 的流程"></a>构建 ExecutionGraph 的流程</h4><p><img src=".%5Cpic%5C1681a29125a407bd" alt="img"></p>
<ol>
<li>创建 ExecutionGraph 对象并设置基本属性<ul>
<li>设置 JobInformation, SlotProvider 等信息，下面罗列了一些比较重要的属性：</li>
</ul>
</li>
<li>JobVertex 初始化<ul>
<li>JobVertex 在 Master 上进行初始化，主要关注<code>OutputFormatVertex</code> 和 <code>InputFormatVertex</code>，其他类型的 vertex 在这里没有什么特殊操作。File output format 在这一步准备好输出目录, Input splits 在这一步创建对应的 splits。</li>
</ul>
</li>
<li>生成 ExecutionGraph 内部的节点和连接<ul>
<li>对所有的 Jobvertext 进行拓扑排序，并生成 <code>ExecutionGraph</code> 内部的节点和连接</li>
<li>对 JobVertex 进行拓扑排序，所谓拓扑排序，即保证如果存在 A -&gt; B 的有向边，那么在排序后的列表中 A 节点一定在 B 节点之前。</li>
<li>创建 ExecutionJobVertex，按照拓扑排序的结果依次为每个 <code>JobVertex</code> 创建对应的 <code>ExecutionJobVertex</code>，在创建 <code>ExecutionJobVertex</code> 的时候会创建对应的 <code>ExecutionVertex</code>， <code>IntermediateResult</code>，<code>ExecutionEdge</code> ， <code>IntermediateResultPartition</code> 等对象，这里涉及到的对象相对较多，概括起来大致是这样的：<ul>
<li>每一个 <code>JobVertex</code> 对应一个 ExecutionJobVertex,</li>
<li>每一个 <code>ExecutionJobVertex</code> 有 parallelism 个 <code>ExecutionVertex</code></li>
<li>每一个 <code>JobVertex</code> 可能有 n(n&gt;=0) 个 <code>IntermediateDataSet</code>，在 <code>ExecutionJobVertex</code> 中，一个 <code>IntermediateDataSet</code> 对应一个 <code>IntermediateResult</code>, 每一个 <code>IntermediateResult</code> 都有 parallelism 个生产者, 对应 parallelism 个<code>IntermediateResultPartition</code></li>
<li>每一个 <code>ExecutionJobVertex</code> 都会和前向的 <code>IntermediateResult</code> 连接，实际上是 <code>ExecutionVertex</code> 和 <code>IntermediateResult</code> 建立连接，生成 <code>ExecutionEdge</code></li>
</ul>
</li>
</ul>
</li>
<li> 配置 state checkpointing</li>
</ol>
<blockquote>
<p><code>ExecutionGraph</code> 是在创建 <code>JobMaster</code> 时就构建完成的，之后就可以被调度执行了。下面简单概括下调度执行的流程</p>
<p>ExecutionGraph.scheduleForExecution</p>
<p>按照拓扑顺序为所有的 <code>ExecutionJobVertex</code> 分配资源，其中每一个 <code>ExecutionVertex</code> 都需要分配一个 slot，<code>ExecutionVertex</code> 的一次执行对应一个 <code>Execution</code>，在分配资源的时候会依照 <code>SlotSharingGroup</code> 和 <code>CoLocationConstraint</code> 确定，分配的时候会考虑 slot 重用的情况。</p>
<p>在所有的节点资源都获取成功后，会逐一调用 <code>Execution.deploy()</code> 来部署 <code>Execution</code>, 使用 <code>TaskDeploymentDescriptor</code> 来描述 <code>Execution</code>，并提交到分配给该 Execution 的 slot 对应的 TaskManager, 最终被分配给对应的 <code>TaskExecutor</code> 执行。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.jrwang.me/2019/flink-source-code-executiongraph/">ExecutionGraph生成</a></li>
</ul>
<h3 id="物理执行图"><a href="#物理执行图" class="headerlink" title="物理执行图"></a>物理执行图</h3><p>JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。</p>
<ul>
<li>Task：Execution被调度后在分配的 TaskManager 中启动对应的 Task。Task 包裹了具有用户执行逻辑的 operator。</li>
<li><strong>ResultPartition</strong>：代表由一个Task的生成的数据，和ExecutionGraph中的IntermediateResultPartition一一对应。</li>
<li><strong>ResultSubpartition</strong>：是ResultPartition的一个子分区。每个ResultPartition包含多个ResultSubpartition，其数目要由下游消费 Task 数和 DistributionPattern 来决定。</li>
<li>InputGate：代表Task的输入封装，和JobGraph中JobEdge一一对应。每个InputGate消费了一个或多个的ResultPartition。</li>
<li>InputChannel：每个InputGate会包含一个以上的InputChannel，和ExecutionGraph中的ExecutionEdge一一对应，也和ResultSubpartition一对一地相连，即一个InputChannel接收一个ResultSubpartition的输出。</li>
</ul>
<h2 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h2><blockquote>
<p>Flink集群启动后，集群会根据配置文件，在相应机子上启动一个JobManager至少一个TaskManager</p>
</blockquote>
<blockquote>
<p>配置文件：</p>
<p><strong>flink-conf.yaml</strong></p>
<pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#设置为服务器IP，这个是JobManager的服务器地址</span>
<span class="token key atrule">jobmanager.rpc.address</span><span class="token punctuation">:</span> 47.88.89.63


<span class="token comment">#————————————————————————</span>
<span class="token comment"># jobManager 的IP地址</span>
<span class="token key atrule">jobmanager.rpc.address</span><span class="token punctuation">:</span> master
 
<span class="token comment"># JobManager 的端口号</span>
<span class="token key atrule">jobmanager.rpc.port</span><span class="token punctuation">:</span> <span class="token number">6123</span>
 
<span class="token comment"># JobManager JVM heap 内存大小</span>
<span class="token key atrule">jobmanager.heap.size</span><span class="token punctuation">:</span> 1024m
 
<span class="token comment"># TaskManager JVM heap 内存大小</span>
<span class="token key atrule">taskmanager.heap.size</span><span class="token punctuation">:</span> 1024m
 
<span class="token comment"># 每个 TaskManager 提供的任务 slots 数量大小，默认为1</span>
 
<span class="token key atrule">taskmanager.numberOfTaskSlots</span><span class="token punctuation">:</span> <span class="token number">2</span>
 
<span class="token comment"># 程序默认并行计算的个数，默认为1</span>
<span class="token key atrule">parallelism.default</span><span class="token punctuation">:</span> <span class="token number">4</span>
<span class="token comment">#——————————————————————————————</span>



<span class="token comment">#高可用配置</span>
<span class="token comment"># 首先将jobmanager.rpc.address项注释掉</span>
<span class="token comment"># 然后设置高可用相关的配置项</span>
<span class="token key atrule">high-availability</span><span class="token punctuation">:</span> zookeeper
<span class="token key atrule">high-availability.storageDir</span><span class="token punctuation">:</span> /nfs/flink/ha/ <span class="token comment"># 存储目录 这里直接使用了百度云的CFS文件系统，三台均挂载到了/nfs下</span>
<span class="token key atrule">high-availability.zookeeper.quorum</span><span class="token punctuation">:</span> 192.168.32.36<span class="token punctuation">:</span><span class="token number">2181</span><span class="token punctuation">,</span>192.168.32.37<span class="token punctuation">:</span><span class="token number">2181</span><span class="token punctuation">,</span>192.168.32.38<span class="token punctuation">:</span><span class="token number">2181</span> <span class="token comment"># ZooKeeper quorum是ZooKeeper服务器的复制组，它提供分布式协调服务</span>
<span class="token key atrule">high-availability.zookeeper.path.root</span><span class="token punctuation">:</span> /flink <span class="token comment"># 根ZooKeeper节点，在该节点下放置所有集群节点</span>
<span class="token key atrule">high-availability.cluster-id</span><span class="token punctuation">:</span> /ccreate<span class="token punctuation">-</span>flink<span class="token punctuation">-</span>cluster <span class="token comment"># cluster-id ZooKeeper节点，在该节点下放置集群的所有必需协调数据# 另外以下几个参数看情况调整jobmanager.memory.process.size: 10240mtaskmanager.memory.process.size: 10240mtaskmanager.numberOfTaskSlots: 8 # flink槽数量 建议设置为当前服务器的CPU核数parallelism.default: 1 # 这个可以在JOB中指定，这里设不设置影响不大, 优先级最低</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>slaves</strong></p>
<p>配置slaves文件，该文件用于指定从节点，表示集群的taskManager。添加以下内容</p>
<pre class="line-numbers language-none"><code class="language-none">localhost<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

</blockquote>
<p><img src=".%5Cpic%5Cimage-20201016171440432.png" alt="image-20201016171440432"></p>
<ul>
<li>client提交任务给JobManager</li>
<li>JobManager调度任务，给TaskManager分配任务执行</li>
<li>TaskManager将心跳和统计信息汇报给JobManager</li>
</ul>
<h2 id="Task数据传输"><a href="#Task数据传输" class="headerlink" title="Task数据传输"></a>Task数据传输</h2><p>Flink 的数据交换机制在设计时遵循两个基本原则： <strong>1. 数据交换的控制流</strong>（例如，为初始化数据交换而发出的消息）是由接收端发起的；2. 数据交换的数据流（例如，在网络中实际传输的数据被抽象为 IntermediateResult 的概念）是可插拔的。这意味着系统基于相同的实现逻辑既可以支持 Streaming 模式也可以支持 Batch 模式下数据的传输</p>
<blockquote>
<p><strong>在一个 TaskManager 中可能会同时并行运行多个 Task，每个 Task 都在单独的线程中运行。在不同的 TaskManager 中运行的 Task 之间进行数据传输要基于网络进行通信。实际上，是 TaskManager 和另一个 TaskManager 之间通过网络进行通信，通信是基于 Netty 创建的标准的 TCP 连接，同一个 TaskManager 内运行的不同 Task 会复用网络连接</strong></p>
</blockquote>
<h3 id="数据交换的控制流"><a href="#数据交换的控制流" class="headerlink" title="数据交换的控制流"></a>数据交换的控制流</h3><ul>
<li><a target="_blank" rel="noopener" href="https://blog.jrwang.me/2019/flink-source-code-data-exchange/">task数据交换</a></li>
</ul>
<p><img src=".%5Cpic%5Ccontrolflow.png" alt="controlflow"></p>
<blockquote>
<p>上图代表了一个简单的 map-reduce 类型的作业，有两个并行的任务。有两个 TaskManager，每个 TaskManager 都分别运行一个 map Task 和一个 reduce Task。我们重点观察 M1 和 R2 这两个 Task 之间的数据传输的发起过程。数据传输用粗箭头表示，消息用细箭头表示。</p>
<ol>
<li>首先，M1 产出了一个 ResultPartition(RP1)（箭头1）。当这个 RP 可以被消费时，会告知 JobManager（箭头2）。</li>
<li>JobManager 会通知想要接收这个 RP 分区数据的接收者（tasks R1 and R2）当前分区数据已经准备好。</li>
<li>如果接受方还没有被调度，这将会触发对应任务的部署（箭头 3a，3b）。</li>
<li>接受方会从 RP 中请求数据（箭头 4a，4b）。这将会初始化 Task 之间的数据传输（5a,5b）,数据传输可能是本地的(5a)，也可能是通过 TaskManager 的网络栈进行（5b）。</li>
<li>对于一个 RP 什么时候告知 JobManager 当前已经出于可用状态，在这个过程中是有充分的自由度的：例如，如果在 RP1 在告知 JobManager 之前已经完整地产出了所有的数据（甚至可能写入了本地文件），那么相应的数据传输更类似于 Batch 的批交换；如果 RP1 在第一条记录产出时就告知 JM，那么就是 Streaming 流交换。</li>
</ol>
</blockquote>
<h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><blockquote>
<p>基于 JVM 的大数据处理分析引擎面临的一个问题是，为了高效地处理数据，有大量的数据需要保存在内存中。直接使用 JVM 堆内存来管理这些数据对象是最简单的实现，但是这样会导致一系列问题：首先，在有大量的数据对象不停地创建和失效的情况下，要正常地管理和控制堆内存并非易事，很容易引发 OOM 问题；其次，GC 会严重影响性能，尤其是为了处理海量数据而分配了较大的内存空间，GC 开销很容易就能达到 50% 以上；最后，Java 对象存储本身存在开销，对于那种本身是小对象的数据集而言，对象头、对齐填充这些存储开销非常浪费。</p>
</blockquote>
<blockquote>
<p>类似Spark的内存管理，不再使用JVM进行内存管理，使用自身的内存管理器，对内存占用了解更彻底</p>
</blockquote>
<h3 id="TaskManager-的内存布局"><a href="#TaskManager-的内存布局" class="headerlink" title="TaskManager 的内存布局"></a>TaskManager 的内存布局</h3><p><strong>Flink 内部并非直接将对象存储在堆上</strong>，而是将对象序列化到一个个预先分配的 <code>MemorySegment</code> 中。<code>MemorySegment</code> 是一段固定长度的内存（默认32KB），也是 Flink 中最小的内存分配单元。<code>MemorySegment</code> 提供了高效的读写方法，它的底层可以是堆上的 byte[], 也可以是堆外（off-heap）ByteBuffer。</p>
<p>可以把 <code>MemorySegment</code> 看作 Java NIO 中的 ByteBuffer，Flink 还实现了 Java 的 <code>java.io.DataOutput</code> 和 <code>java.io.DataInput</code> 接口，分别是 <code>AbstractPagedInputView</code> 和 <code>AbstractPagedOutputView</code>, 可以通过一种逻辑视图的方式来操作连续的多块 <code>MemorySegment</code>。</p>
<p>在 Flink 中，TaskManager 负责任务的实际运行，通常一个 TaskManager 对应一个 JVM 进程（非 MiniCluster 模式）。抛开 JVM 内存模型，单从 TaskManager内存的主要使用方式来看，TaskManager 的内存主要分为三个部分：</p>
<ul>
<li>Network Buffers：一定数量的 <code>MemorySegment</code>, 主要用于网络传输。在 TaskManager 启动时分配， 通过 <code>NetworkEnvironment</code> 和 <code>NetworkBufferPool</code> 进行管理</li>
<li>Managed Memory：由 <code>MemoryManager</code> 管理的一组 <code>MemorySegment</code> 集合， 主要用于 Batch 模式下的 sorting, hashing, 和 cache 等。</li>
<li>Remaining JVM heap：余下的堆内存留给 TaskManager的数据结构以及用户代码处理数据时使用。TaskManager 自身的数据结构并不会占用太多内存，因而主要都是供用户代码使用，用户代码创建的对象通常生命周期都较短</li>
</ul>
<p>需要注意的是，上面所说的三部分的内存并非都是 JVM 堆上的内存，因为 <code>MemorySegment</code> 底层的内存可以在堆上，也可以在堆外（不由 JVM 管理）。对于 Network Buffers，这一部分内存就是在堆外（off-heap）进行分配的；对于 Managed Memory，这一部分内存可以配置在堆上，也可以配置在堆外。另外还需要注意的一点是，<strong>Managed Memory 主要是在 Batch 模式下使用，在 Streaming 模式下这一部分内存并不会预分配，因而空闲出来的内存其实都是可以给用户自定义函数使用的</strong>。</p>
<h3 id="通过二进制数据管理对象"><a href="#通过二进制数据管理对象" class="headerlink" title="通过二进制数据管理对象"></a>通过二进制数据管理对象</h3><p>我们已经知道，Flink 是通过 <code>MemorySegment</code> 来管理数据对象的，因而对象首先需要被序列化保存到 <code>MemorySegment</code> 中。在 Java 的生态系统中，已经存在很多现有的序列化框架了，如 Java 自带的序列化机制、Kryo、Avro、Thrift、Protobuf 等，但 Flink 也实现了一套自己的序列化框架。这主要是出于以下考虑：<strong>首先，比较和操作二进制数据需要准确了解序列化的布局，针对二进制数据的操作来配置序列化的布局可以显著提升性能；其次，对于 Flink 应用而言，它所处理的数据对象类型通常是完全已知的，由于数据集对象的类型固定，对于数据集可以只保存一份对象 Schema 信息，可以进一步节省存储空间</strong>。</p>
<blockquote>
<p>对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。</p>
<p>在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常</p>
</blockquote>
<p>Flink 可以处理任意的 Java 或 Scala 对象，而不必实现特定的接口。对于 Java 实现的 Flink 程序，Flink 会通过反射框架获取用户自定义函数返回的类型；而对于 Scala 实现的 Flink 程序，则通过 Scala Compiler 分析用户自定义函数返回的类型。每一种数据类型都对应一个 <code>TypeInfomation</code>。</p>
<ul>
<li><code>BasicTypeInfo</code>: 基本类型（装箱的）或 String 类型</li>
<li><code>BasicArrayTypeInfo</code>: 基本类型数组（装箱的）或 String 数组</li>
<li><code>WritableTypeInfo</code>: 任意 Hadoop Writable 接口的实现类</li>
<li><code>TupleTypeInfo</code>: 任意的 Flink Tuple 类型 (支持Tuple1 to Tuple25)</li>
<li><code>CaseClassTypeInfo</code>: 任意的 Scala CaseClass (包括 Scala tuples)</li>
<li><code>PojoTypeInfo</code>: 任意的 POJO (Java or Scala)，Java对象的所有成员变量，要么是 public 修饰符定义，要么有 getter/setter 方法</li>
<li><code>GenericTypeInfo</code>: 任意无法匹配之前几种类型的类</li>
</ul>
<p>通过 <code>TypeInfomation</code> 可以获取到对应数据类型的序列化器 <code>TypeSerializer</code>。对于 <code>BasicTypeInfo</code>，Flink 提供了对应的序列化器；对于 <code>WritableTypeInfo</code>, Flink 会将序列化和反序列化操作委托给 Hadoop Writable 接口的 <code>write()</code> and <code>readFields()</code>；对于 <code>GenericTypeInfo</code>， Flink 默认使用 Kyro 进行序列化；而 <code>TupleTypeInfo</code>、<code>CaseClassTypeInfo</code> 和 <code>PojoTypeInfo</code> 是一种组合类型，序列化时分别委托给成员的序列化器进行序列化即可。</p>
<p>对于可以用作 key 的数据类型，<code>TypeInfomation</code> 还可以生成 <code>TypeComparator</code>，用来直接在序列化后的二进制数据上进行 compare、hash 等操作。</p>
<p>Flink 的类型和序列化系统也可以方便地进行扩展，用户可以提供自定义的序列化器和比较器，具体可以参考 Flink 官方提供的文档 <a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-master/dev/types_serialization.html">Data Types &amp; Serialization</a>。</p>
<p>在批处理的场景下，诸如 group, sort, 和 join 等操作都需要访问大量的数据。借助于MemorySegment并直接操作二进制数据，Flink 可以高效地完成这些操作，避免了频繁地序列化/反序列化，并且这些操作是缓存友好的。具体可以参考 Flink 团队的文章<a target="_blank" rel="noopener" href="https://flink.apache.org/news/2015/05/11/Juggling-with-Bits-and-Bytes.html">Juggling with Bits and Bytes</a>。</p>
<p>这种基于 <code>MemorySegment</code> 和二进制数据直接管理数据对象的方式可以带来如下好处：</p>
<ul>
<li>保证内存安全<strong>：由于分配的 MemorySegment 的数量是固定的，因而可以准确地追踪 MemorySegment 的使用情况。在 Batch 模式下，如果 MemorySegment 资源不足，会将一批 MemorySegment 写入磁盘，需要时再重新读取。这样有效地减少了 OOM 的情况</strong>。</li>
<li>减少了 GC 的压力：因为分<strong>配的 MemorySegment 是长生命周期的对象，数据都以二进制形式存放，且 MemorySegment 可以回收重用，所以 MemorySegment 会一直保留在老年代不会被 GC</strong>；<strong>而由用户代码生成的对象基本都是短生命周期的，Minor GC 可以快速回收这部分对象，尽可能减少 Major GC 的频率。</strong>此外，MemorySegment 还可以配置为使用堆外内存，进而避免 GC。</li>
<li>节省内存空间：数据对象序列化后以二进制形式保存在 MemorySegment 中，减少了对象存储的开销。</li>
<li>高效的二进制操作和缓存友好的计算：可以直接基于二进制数据进行比较等操作，避免了反复进行序列化于反序列；<strong>另外，二进制形式可以把相关的值，以及 hash 值，键值和指针等相邻地放进内存中，这使得数据结构可以对高速缓存更友好</strong>。</li>
</ul>
<h3 id="MemorySegment"><a href="#MemorySegment" class="headerlink" title="MemorySegment"></a>MemorySegment</h3><p>前面已经介绍了，<code>MemorySegment</code> 是一段固定长度的内存，也是 Flink 中最小的内存分配单元。在早期版本的实现中，<code>MemorySegment</code> 使用的都是堆上的内存。尽管 Flink 的内存管理机制已经做了很多优化，但是 Flink 团队仍然加入了对堆外内存的支持。主要是考虑到以下几个方面：</p>
<ul>
<li>启动很大堆内存（100s of GBytes heap memory）的 JVM 需要很长时间，GC 停留时间也会很长（分钟级）。使用堆外内存的话，JVM 只需要分配较少的堆内存（只需要分配 Remaining Heap 那一块）。</li>
<li>堆外内存在写磁盘或网络传输时是可以利用 zero-copy 特性，I/O 和网络传输的效率更高。</li>
<li>堆外内存是进程间共享的，也就是说，即使 JVM 进程崩溃也不会丢失数据。这可以用来做故障恢复。Flink暂时没有利用起这个，不过未来有可能会利用这个特性。</li>
</ul>
<p>但是使用堆外内存同样存在一些潜在的问题：</p>
<ul>
<li>堆内存可以很方便地进行监控和分析，相较而言堆外内存则更加难以控制；</li>
<li>Flink 有时可能需要短生命周期的 MemorySegment，在堆上申请开销会更小；</li>
<li>一些操作在堆内存上会更快一些</li>
</ul>
<p>Flink 将原来的 <code>MemorySegment</code> 变成了抽象类，并提供了两个具体的子类：<code>HeapMemorySegment</code> 和 <code>HybridMemorySegment</code>。前者是用于分配堆内存，后者用来分配堆外内存和堆内存的。</p>
<p>在早期版本中，由于 <code>MemorySegment</code> 是只基于堆内存的，因而只需要提供一种类型的 <code>MemorySegment</code> 实现即可；而在引入对堆外内存的支持后，按一般的思路是应该在新增一个基于堆外内存的实现即可。但是，这里涉及到一个 JIT 优化的性能问题。在只有一种类型的 <code>MemorySegment</code> 的情况下，通过 Class Hierarchy Analysis (CHA)，JIT 编译器能够确定方法调用的具体实现，因而方法调用可以通过去虚化（de-virtualized）和内联（inlined）来提升性能。而一旦有了两种类型的实现，在同时使用两种类型的 <code>MemorySegment</code> 的情况下，JIT 编译器就无法进行优化，这大概会导致 2.7 倍的性能差异。因而 Flink 做了这两种优化：1）确保只有一种 <code>MemorySegment</code> 的实现被加载；2）提供一种能同时处理管理堆内存和堆外内存的 <code>MemorySegment</code> 实现，从而保证频繁调用的 <code>MemorySegment</code> 能够被 JIT 优化。详细的解释和性能的评测可以参考 Flink 团队的文章<a target="_blank" rel="noopener" href="https://flink.apache.org/news/2015/09/16/off-heap-memory.html">Off-heap Memory in Apache Flink and the curious JIT compiler</a>。</p>
<h1 id="Flink-Window概述"><a href="#Flink-Window概述" class="headerlink" title="Flink Window概述"></a>Flink Window概述</h1><blockquote>
<p>streaming 流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，而 window 是一种切割无限数据为有限块进行处理的手段。 </p>
<p>Window 是无限数据流处理的核心，Window 将一个无限的 stream 拆分成有限大小的”buckets”桶，我们可以在这些桶上做计算操作。 </p>
</blockquote>
<p><img src="./pic/image-20201008144316428.png" alt="image-20201008144316428"></p>
<h1 id="Window类型"><a href="#Window类型" class="headerlink" title="Window类型"></a>Window类型</h1><ol>
<li>CountWindow：按照指定的数据条数生成一个 Window，与时间无关。</li>
<li>TimeWindow：按照时间生成 Window。</li>
</ol>
<blockquote>
<p>对于 TimeWindow，可以根据窗口实现原理的不同分成三类：滚动窗口（Tumbling Window）、滑动窗口（Sliding Window）和会话窗口（Session Window）。 </p>
</blockquote>
<h2 id="滚动窗口（Tumbling-Windows）"><a href="#滚动窗口（Tumbling-Windows）" class="headerlink" title="滚动窗口（Tumbling Windows）"></a>滚动窗口（Tumbling Windows）</h2><blockquote>
<p><strong>将数据依据固定的窗口长度对数据进行切片。</strong><br><strong>特点：时间对齐，窗口长度固定，没有重叠。</strong><br>滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，并且不会出现重叠。例如：如果你指定了一个 5 分钟大小的滚动窗口，窗口的创建如下图所示： </p>
</blockquote>
<p><img src="./pic/image-20201008145200332.png" alt="image-20201008145200332"></p>
<p><strong>适用场景：适合做 BI 统计等（做每个时间段的聚合计算）</strong></p>
<h2 id="滑动窗口（Sliding-Windows）"><a href="#滑动窗口（Sliding-Windows）" class="headerlink" title="滑动窗口（Sliding Windows）"></a>滑动窗口（Sliding Windows）</h2><p>滑动窗口是固定窗口的更广义的一种形式，<strong>滑动窗口由固定的窗口长度和滑动间隔组成</strong>。 </p>
<blockquote>
<p>滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，窗口是可以重叠的，在这种情况下元素会被分配到多个窗口中。 </p>
</blockquote>
<p>**特点：时间对齐，窗口长度固定，可以有重叠。 **</p>
<p>例如，你有 10 分钟的窗口和 5 分钟的滑动，那么每个窗口中 5 分钟的窗口里包含着上个 10 分钟产生的数据，如下图所示：</p>
<p><img src="./pic/image-20201008145130501.png" alt="image-20201008145130501"></p>
<p>**适用场景：对最近一个时间段内的统计（求某接口最近 5min 的失败率来决定是否要报警）。 **</p>
<h2 id="会话窗口Session-Windows）"><a href="#会话窗口Session-Windows）" class="headerlink" title="会话窗口Session Windows）"></a>会话窗口Session Windows）</h2><p>由一系列事件组合一个指定时间长度的 timeout 间隙组成，类似于 web 应用的session，也就是一段时间没有接收到新数据就会生成新的窗口。</p>
<p><strong>特点：时间无对齐</strong></p>
<blockquote>
<p>session 窗口分配器通过 session 活动来对元素进行分组，session 窗口跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况，相反，当它在一个固定的时间周期内不再收到元素，即非活动间隔产生，那个这个窗口就会关闭。一个 session 窗口通过一个 session 间隔来配置，这个 session 间隔定义了非活跃周期的长度，当这个非活跃周期产生，那么当前的 session 将关闭并且后续的元素将被分配到新的 session 窗口中去。 </p>
</blockquote>
<p><img src="./pic/image-20201008145110573.png" alt="image-20201008145110573"></p>
<ol>
<li>由一系列事件组合一个指定时间长度的timeout间隙组成，一段时间没有接受到新数据就会生成新的窗口</li>
<li>时间无对齐</li>
</ol>
<h1 id="Window-API"><a href="#Window-API" class="headerlink" title="Window API"></a>Window API</h1><h2 id="窗口分配器"><a href="#窗口分配器" class="headerlink" title="窗口分配器"></a>窗口分配器</h2><ol>
<li>用.window()方法定义窗口，基于这个window做一些聚合或者其他处理，<strong>window方法必须在KeyBy之后才能用</strong></li>
<li>Flink有.timeWindow和.countWindow方法，用于定义时间窗口和计数窗口</li>
<li><strong>window()方法接收的参数是一个WindowAssigner</strong></li>
<li>WindowAssigner负责将每条数据发送到正确的window中去</li>
<li>WindowAssigner包括<ol>
<li><strong>滚动窗口  tumbling window</strong></li>
<li><strong>滑动窗口 sliding window</strong></li>
<li><strong>会话窗口 session window</strong></li>
<li><strong>全局窗口 global window</strong></li>
</ol>
</li>
</ol>
<p><img src="./pic/image-20201008151129982.png" alt="image-20201008151129982"></p>
<p><img src="./pic/image-20201008151153027.png" alt="image-20201008151153027"></p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> minTemPreWindow<span class="token operator">=</span>dataStream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">(</span>r1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>r2<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>min<span class="token punctuation">(</span>r2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="./pic/1691e5382032abc5" alt="img"></p>
<h2 id="时间窗口"><a href="#时间窗口" class="headerlink" title="时间窗口"></a>时间窗口</h2><blockquote>
<p>TimeWindow 是将指定时间范围内的所有数据组成一个 window，一次对一个window 里面的所有数据进行计算。</p>
</blockquote>
<h3 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h3><blockquote>
<p>Flink 默认的时间窗口<strong>根据 Processing Time 进行窗口的划分</strong>，将 Flink 获取到的数据根据进入 Flink 的时间划分到不同的窗口中。 </p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> minTempPerWindow <span class="token operator">=</span> dataStream 
  <span class="token punctuation">.</span>map<span class="token punctuation">(</span>r <span class="token keyword">=></span> <span class="token punctuation">(</span>r<span class="token punctuation">.</span>id<span class="token punctuation">,</span> r<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span> r2<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>r1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> r1<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>min<span class="token punctuation">(</span>r2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>时间间隔可以通过 Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。 </p>
</blockquote>
<p>滚动窗口分派器（assigner）会将数据元素分派给指定大小的窗口，滚动窗口尺寸固定，相互不会重叠</p>
<h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><blockquote>
<p>滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是 window_size，一个是 sliding_size。 </p>
<p>面代码中的 sliding_size 设置为了 5s，也就是说，窗口每 5s 就计算一次，每一次计算的 window 范围是 15s 内的所有元素。 </p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> minTempPerWindow<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dataStream 
  <span class="token punctuation">.</span>map<span class="token punctuation">(</span>r <span class="token keyword">=></span> <span class="token punctuation">(</span>r<span class="token punctuation">.</span>id<span class="token punctuation">,</span> r<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span> r2<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>r1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> r1<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>min<span class="token punctuation">(</span>r2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token punctuation">.</span>window<span class="token punctuation">(</span>EventTimeSessionWindows<span class="token punctuation">.</span>withGap<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>minutes<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>时间间隔可以通过 Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。 </p>
</blockquote>
<h2 id="CountWindow"><a href="#CountWindow" class="headerlink" title="CountWindow"></a>CountWindow</h2><p>CountWindow 根据窗口中相同 key 元素的数量来触发执行，执行时只计算元素数量达到窗口大小的 key 对应的结果。 </p>
<p>**注意：CountWindow 的 window_size 指的是相同 Key 的元素的个数，不是输入的所有元素的总数。 **</p>
<h3 id="滚动窗口-1"><a href="#滚动窗口-1" class="headerlink" title="滚动窗口"></a>滚动窗口</h3><blockquote>
<p>默认的 CountWindow 是一个滚动窗口，只需要指定窗口大小即可，当<strong>元素数量达到窗口大小时，就会触发窗口的执行</strong>。 </p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> minTempPerWindow<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dataStream 
<span class="token punctuation">.</span>map<span class="token punctuation">(</span>r <span class="token keyword">=></span> <span class="token punctuation">(</span>r<span class="token punctuation">.</span>id<span class="token punctuation">,</span> r<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>countWindow<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> 
  <span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span> r2<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>r1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> r1<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>max<span class="token punctuation">(</span>r2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="滑动窗口-1"><a href="#滑动窗口-1" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><blockquote>
<p>滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是 window_size，一个是 sliding_size。 </p>
<p>下面代码中的 sliding_size 设置为了 2，也就是说，每收到两个相同 key 的数据就计算一次，每一次计算的 window 范围是 10 个元素。 </p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> keyedStream<span class="token operator">:</span> KeyedStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Tuple<span class="token punctuation">]</span> <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>r <span class="token keyword">=></span> <span class="token punctuation">(</span>r<span class="token punctuation">.</span>id<span class="token punctuation">,</span> r<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> 
<span class="token comment">//每当某一个 key的个数达到 2的时候,触发计算，计算最近该 key最近 10个元素的内容 val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10,2) </span>
<span class="token keyword">val</span> sumDstream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> windowedStream<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h2 id="window-function"><a href="#window-function" class="headerlink" title="window function"></a>window function</h2><p>window function 定义了要对窗口中收集的数据做的计算操作，主要可以分为两类：</p>
<ol>
<li>增量聚合函数（incremental aggregation functions）：<strong>每条数据到来就进行计算，保持一个简单的状态。典型的增量聚合函数有ReduceFunction, AggregateFunction。</strong></li>
<li>全窗口函数（full window functions）：<strong>先把窗口所有数据收集起来，等到计算的时候会遍历所有数据。 ProcessWindowFunction 就是一个全窗口函数。</strong></li>
<li>.tragger()触发器：定义window什么时候关闭，触发计算并输出结果</li>
<li>.evitor()移除器：定义移除某些数据的逻辑</li>
<li>.allowedLateness：允许处理迟到的数据</li>
<li>.sideOutputLateData()：将迟到的数据放在侧输出流</li>
<li>.getSideOutput()：获取侧输出流</li>
</ol>
<p><img src="./pic/image-20201008152918348.png" alt="image-20201008152918348"></p>
<h1 id="时间语义-amp-amp-Watermark"><a href="#时间语义-amp-amp-Watermark" class="headerlink" title="时间语义 &amp;&amp; Watermark"></a>时间语义 &amp;&amp; Watermark</h1><p><img src="./pic/image-20201008153529310.png" alt="image-20201008153529310"></p>
<p><img src="./pic/image-20201008160956151.png" alt="image-20201008160956151"></p>
<p><img src="./pic/image-20201008161227024.png" alt="image-20201008161227024"></p>
<h2 id="水位线Watermark"><a href="#水位线Watermark" class="headerlink" title="水位线Watermark"></a>水位线Watermark</h2><blockquote>
<p>Watermark是Apache Flink为了处理EventTime 窗口计算提出的一种机制,本质上也是一种时间戳，由Apache Flink Source或者自定义的Watermark生成器按照需求Punctuated或者Periodic两种方式生成的一种系统Event，与普通数据流Event一样流转到对应的下游算子，接收到Watermark Event的算子以此不断调整自己管理的EventTime clock。 Apache Flink 框架保证Watermark单调递增，算子接收到一个Watermark时候，框架知道不会再有任何小于该Watermark的时间戳的数据元素到来了，所以Watermark可以看做是告诉Apache Flink框架数据流已经处理到什么位置(时间维度)的方式。 Watermark的产生和Apache Flink内部处理逻辑如下图所示: </p>
<p><img src="./pic/1691e5381e90a583" alt="img"></p>
</blockquote>
<p>从上文中，我们可以得出两个触发watermark的必要条件</p>
<ol>
<li><strong>watermark时间 &gt;= 窗口的结束时间</strong></li>
<li><strong>在窗口的时间范围(左闭右开)内有数据</strong></li>
</ol>
<p><strong>防止数据乱序 / 指定时间内获取不到全部数据。</strong></p>
<p><img src="./pic/image-20201008162020291.png" alt="image-20201008162020291"></p>
<p><img src="./pic/image-20201008163218317.png" alt="image-20201008163218317"></p>
<ol>
<li>watermark是一条特殊的数据记录</li>
<li>watermark必须单调递增，确保任务时间时钟向前推进</li>
<li>watermark与数据的时间戳相关</li>
</ol>
<blockquote>
<p>watermark传递</p>
</blockquote>
<p><img src="./pic/image-20201008163705543.png" alt="image-20201008163705543"></p>
<ol>
<li>flink暴露TimestampAssigner接口供我们实现，我们可以自定义如何从数据（事件）中抽取时间戳和生成watermark</li>
<li>AssignerWithPeriodicWatermarks：周期性将waatermark插入流中，默认周期是200毫秒，使用ExecutionConfig.setAutoWatermarkInterval()进行设置</li>
<li>AssignerWithPunctuatedWatermarks，可以生成没有时间规律，可打断的watermark</li>
</ol>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"> <span class="token comment">//设置时间为事件时间</span>
env<span class="token punctuation">.</span>setStreamTimeCharacteristic<span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>EventTime<span class="token punctuation">)</span>
<span class="token comment">//设置周期watermark插入  100毫秒</span>
env<span class="token punctuation">.</span>getConfig<span class="token punctuation">.</span>setAutoWatermarkInterval<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="AssignerWithPeriodicWatermarks-–-周期性插入watermark"><a href="#AssignerWithPeriodicWatermarks-–-周期性插入watermark" class="headerlink" title="AssignerWithPeriodicWatermarks  –  周期性插入watermark"></a>AssignerWithPeriodicWatermarks  –  周期性插入watermark</h2><blockquote>
<p>Periodic：周期性的（一定时间间隔或者达到一定的记录条数）产生一个Watermark。在实际的生产中Periodic的方式必须结合时间和积累条数两个维度继续周期性产生Watermark，否则在极端情况下会有很大的延时。</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> PeriodicAssigner <span class="token keyword">extends</span> AssignerWithPeriodicWatermarks<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">//水位线延时1min</span>
  <span class="token keyword">val</span> bound<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">1000</span>
  <span class="token comment">//观察到的最大时间戳</span>
  <span class="token keyword">var</span> maxTx<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token builtin">Long</span><span class="token punctuation">.</span>MinValue
    
    <span class="token comment">//生成watermark，每200毫秒（默认）调用一次</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> getCurrentWatermark<span class="token operator">:</span> Watermark <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">new</span> Watermark<span class="token punctuation">(</span>maxTx <span class="token operator">-</span> bound<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
    
    <span class="token comment">//抽取时间戳</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> previousElementTimestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    maxTx <span class="token operator">=</span> maxTx<span class="token punctuation">.</span>max<span class="token punctuation">(</span>element<span class="token punctuation">.</span>timestamp<span class="token punctuation">)</span>
    element<span class="token punctuation">.</span>timestamp
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="assignAscendingTimestamps-—-时间严格递增"><a href="#assignAscendingTimestamps-—-时间严格递增" class="headerlink" title="assignAscendingTimestamps — 时间严格递增"></a>assignAscendingTimestamps — 时间严格递增</h2><p>如果数据时间是严格递增，则对datastream的数据流使用assignAscendingTimestamps，直接用数据中的时间生成watermark</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">dataStream<span class="token punctuation">.</span>assignAscendingTimestamps<span class="token punctuation">(</span>e<span class="token keyword">=></span>e<span class="token punctuation">.</span>timestamp<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="乱序数据"><a href="#乱序数据" class="headerlink" title="乱序数据"></a>乱序数据</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> SensorTimeAssigner <span class="token keyword">extends</span> BoundedOutOfOrdernessTimestampExtractor<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
  <span class="token comment">//抽取时间戳</span>
    <span class="token comment">//延时5秒</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    element<span class="token punctuation">.</span>timestamp<span class="token operator">*</span><span class="token number">1000</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="AssignerWithPunctuatedWatermarks-–-选择性插入"><a href="#AssignerWithPunctuatedWatermarks-–-选择性插入" class="headerlink" title="AssignerWithPunctuatedWatermarks  – 选择性插入"></a>AssignerWithPunctuatedWatermarks  – 选择性插入</h2><blockquote>
<p>Punctuated：数据流中每一个递增的EventTime都会产生一个Watermark。 在实际的生产中Punctuated方式在TPS很高的场景下会产生大量的Watermark在一定程度上对下游算子造成压力，所以只有在实时性要求非常高的场景才会选择Punctuated的方式进行Watermark的生成。</p>
</blockquote>
<p>间断生成watermark，和周期性不同，这种方式不是固定时间的，可以根据需要对每条数据进行筛选和处理，例如我们只对“sensor_1”的数据插入watermark</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> PunctuatedAssigner <span class="token keyword">extends</span> AssignerWithPunctuatedWatermarks<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">val</span> bonud<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">1000</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> checkAndGetNextWatermark<span class="token punctuation">(</span>lastElement<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> extractedTimestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> Watermark <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>lastElement<span class="token punctuation">.</span>id<span class="token punctuation">.</span>equals<span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">new</span> Watermark<span class="token punctuation">(</span>extractedTimestamp <span class="token operator">-</span> bonud<span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">null</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> previousElementTimestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    element<span class="token punctuation">.</span>timestamp
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">dataStream<span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> PeriodicAssigner<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="BoundedOutOfOrdernessTimestampExtractor"><a href="#BoundedOutOfOrdernessTimestampExtractor" class="headerlink" title="BoundedOutOfOrdernessTimestampExtractor"></a>BoundedOutOfOrdernessTimestampExtractor</h2><blockquote>
<p>滚动窗口</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">    <span class="token keyword">val</span> dataStream <span class="token operator">=</span> inputStream
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>data <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">val</span> dataArray <span class="token operator">=</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        SensorReading<span class="token punctuation">(</span>dataArray<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> dataArray<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> dataArray<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>     
<span class="token comment">//水位线延迟1秒</span>
<span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> BoundedOutOfOrdernessTimestampExtractor<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> element<span class="token punctuation">.</span>timestamp <span class="token operator">*</span> <span class="token number">1000</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">   <span class="token keyword">val</span> dataStream <span class="token operator">=</span> inputStream
     <span class="token punctuation">.</span>map<span class="token punctuation">(</span>data <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
       <span class="token keyword">val</span> dataArray <span class="token operator">=</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
       SensorReading<span class="token punctuation">(</span>dataArray<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">,</span> dataArray<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> dataArray<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
     <span class="token punctuation">&#125;</span><span class="token punctuation">)</span> 
<span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> BoundOutOfOrdeness<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   <span class="token keyword">val</span> minTem <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>m <span class="token keyword">=></span> <span class="token punctuation">(</span>m<span class="token punctuation">.</span>id<span class="token punctuation">,</span> m<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>data1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> data1<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>min<span class="token punctuation">(</span>data2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   minTem<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"min"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>源码</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">/**
  * Windows this [[KeyedStream]] into tumbling time windows.
  *
  * This is a shortcut for either `.window(TumblingEventTimeWindows.of(size))` or
  * `.window(TumblingProcessingTimeWindows.of(size))` depending on the time characteristic
  * set using
  * [[StreamExecutionEnvironment.setStreamTimeCharacteristic()]]
  *
  * @param size The size of the window.
  */</span>
 <span class="token keyword">def</span> timeWindow<span class="token punctuation">(</span>size<span class="token operator">:</span> Time<span class="token punctuation">)</span><span class="token operator">:</span> WindowedStream<span class="token punctuation">[</span>T<span class="token punctuation">,</span> K<span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
   <span class="token keyword">new</span> WindowedStream<span class="token punctuation">(</span>javaStream<span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/**
 * Windows this &#123;@code KeyedStream&#125; into tumbling time windows.
 *
 * &lt;p>This is a shortcut for either &#123;@code .window(TumblingEventTimeWindows.of(size))&#125; or
 * &#123;@code .window(TumblingProcessingTimeWindows.of(size))&#125; depending on the time characteristic
 * set using
 * &#123;@link org.apache.flink.streaming.api.environment.StreamExecutionEnvironment#setStreamTimeCharacteristic(org.apache.flink.streaming.api.TimeCharacteristic)&#125;
 *
 * @param size The size of the window.
 */</span>
<span class="token keyword">public</span> <span class="token class-name">WindowedStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> KEY<span class="token punctuation">,</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> <span class="token function">timeWindow</span><span class="token punctuation">(</span><span class="token class-name">Time</span> size<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>environment<span class="token punctuation">.</span><span class="token function">getStreamTimeCharacteristic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token class-name">TimeCharacteristic<span class="token punctuation">.</span>ProcessingTime</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
		<span class="token keyword">return</span> <span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingProcessingTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
		<span class="token keyword">return</span> <span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingEventTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Override</span>
<span class="token keyword">public</span> <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> <span class="token function">assignWindows</span><span class="token punctuation">(</span><span class="token class-name">Object</span> element<span class="token punctuation">,</span> <span class="token keyword">long</span> timestamp<span class="token punctuation">,</span> <span class="token class-name">WindowAssignerContext</span> context<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">final</span> <span class="token keyword">long</span> now <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">getCurrentProcessingTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token keyword">long</span> start <span class="token operator">=</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">.</span><span class="token function">getWindowStartWithOffset</span><span class="token punctuation">(</span>now<span class="token punctuation">,</span> offset<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token keyword">return</span> <span class="token class-name">Collections</span><span class="token punctuation">.</span><span class="token function">singletonList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> start <span class="token operator">+</span> size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>滑动窗口</p>
<p>窗口宽度15，滑动步长5</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> minTem <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>m <span class="token keyword">=></span> <span class="token punctuation">(</span>m<span class="token punctuation">.</span>id<span class="token punctuation">,</span> m<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>data1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> data1<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>min<span class="token punctuation">(</span>data2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
minTem<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"min"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">/**
 * Windows this [[KeyedStream]] into sliding time windows.
 *
 * This is a shortcut for either `.window(SlidingEventTimeWindows.of(size))` or
 * `.window(SlidingProcessingTimeWindows.of(size))` depending on the time characteristic
 * set using
 * [[StreamExecutionEnvironment.setStreamTimeCharacteristic()]]
 *
 * @param size The size of the window.
 */</span>
<span class="token keyword">def</span> timeWindow<span class="token punctuation">(</span>size<span class="token operator">:</span> Time<span class="token punctuation">,</span> slide<span class="token operator">:</span> Time<span class="token punctuation">)</span><span class="token operator">:</span> WindowedStream<span class="token punctuation">[</span>T<span class="token punctuation">,</span> K<span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">new</span> WindowedStream<span class="token punctuation">(</span>javaStream<span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>size<span class="token punctuation">,</span> slide<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/**
 * Windows this &#123;@code KeyedStream&#125; into sliding time windows.
 *
 * &lt;p>This is a shortcut for either &#123;@code .window(SlidingEventTimeWindows.of(size, slide))&#125; or
 * &#123;@code .window(SlidingProcessingTimeWindows.of(size, slide))&#125; depending on the time
 * characteristic set using
 * &#123;@link org.apache.flink.streaming.api.environment.StreamExecutionEnvironment#setStreamTimeCharacteristic(org.apache.flink.streaming.api.TimeCharacteristic)&#125;
 *
 * @param size The size of the window.
 */</span>
<span class="token keyword">public</span> <span class="token class-name">WindowedStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> KEY<span class="token punctuation">,</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> <span class="token function">timeWindow</span><span class="token punctuation">(</span><span class="token class-name">Time</span> size<span class="token punctuation">,</span> <span class="token class-name">Time</span> slide<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>environment<span class="token punctuation">.</span><span class="token function">getStreamTimeCharacteristic</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token class-name">TimeCharacteristic<span class="token punctuation">.</span>ProcessingTime</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
		<span class="token keyword">return</span> <span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">SlidingProcessingTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> slide<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
		<span class="token keyword">return</span> <span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">SlidingEventTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> slide<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Override</span>
<span class="token keyword">public</span> <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> <span class="token function">assignWindows</span><span class="token punctuation">(</span><span class="token class-name">Object</span> element<span class="token punctuation">,</span> <span class="token keyword">long</span> timestamp<span class="token punctuation">,</span> <span class="token class-name">WindowAssignerContext</span> context<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>timestamp <span class="token operator">></span> <span class="token class-name">Long</span><span class="token punctuation">.</span>MIN_VALUE<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
		<span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> windows <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>size <span class="token operator">/</span> slide<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token keyword">long</span> lastStart <span class="token operator">=</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">.</span><span class="token function">getWindowStartWithOffset</span><span class="token punctuation">(</span>timestamp<span class="token punctuation">,</span> offset<span class="token punctuation">,</span> slide<span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">long</span> start <span class="token operator">=</span> lastStart<span class="token punctuation">;</span>
			start <span class="token operator">></span> timestamp <span class="token operator">-</span> size<span class="token punctuation">;</span>
			start <span class="token operator">-=</span> slide<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
			windows<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> start <span class="token operator">+</span> size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
		<span class="token punctuation">&#125;</span>
		<span class="token keyword">return</span> windows<span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
		<span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span><span class="token string">"Record has Long.MIN_VALUE timestamp (= no timestamp marker). "</span> <span class="token operator">+</span>
				<span class="token string">"Is the time characteristic set to 'ProcessingTime', or did you forget to call "</span> <span class="token operator">+</span>
				<span class="token string">"'DataStream.assignTimestampsAndWatermarks(...)'?"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-java" data-language="java"><code class="language-java"> <span class="token operator">*</span> <span class="token class-name">Method</span> <span class="token keyword">to</span> <span class="token namespace">get</span> the window start <span class="token keyword">for</span> a timestamp<span class="token punctuation">.</span>
 <span class="token operator">*</span>
 <span class="token operator">*</span> <span class="token annotation punctuation">@param</span> timestamp epoch millisecond <span class="token keyword">to</span> <span class="token namespace">get</span> the window start<span class="token punctuation">.</span>
 <span class="token operator">*</span> <span class="token annotation punctuation">@param</span> offset <span class="token class-name">The</span> offset which window start would be shifted by<span class="token punctuation">.</span>
 <span class="token operator">*</span> <span class="token annotation punctuation">@param</span> windowSize <span class="token class-name">The</span> size of the generated windows<span class="token punctuation">.</span>
 <span class="token operator">*</span> <span class="token annotation punctuation">@return</span> window start
 <span class="token operator">*</span><span class="token operator">/</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">long</span> <span class="token function">getWindowStartWithOffset</span><span class="token punctuation">(</span><span class="token keyword">long</span> timestamp<span class="token punctuation">,</span> <span class="token keyword">long</span> offset<span class="token punctuation">,</span> <span class="token keyword">long</span> windowSize<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
	<span class="token keyword">return</span> timestamp <span class="token operator">-</span> <span class="token punctuation">(</span>timestamp <span class="token operator">-</span> offset <span class="token operator">+</span> windowSize<span class="token punctuation">)</span> <span class="token operator">%</span> windowSize<span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token punctuation">.</span>window<span class="token punctuation">(</span>SlidingEventTimeWindows<span class="token punctuation">.</span>of<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Time<span class="token punctuation">.</span>hours<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote>
<p>总结，如果数据的时间是严格递增，则采用<strong>assignAscendingTimestamps</strong>来指定处理时间</p>
<p>如果不是，使用<strong>assignTimestampsAndWatermarks</strong>来自定义抽取时间，在参数中可以传递<strong>AssignerWithPeriodicWatermarks</strong>和<strong>AssignerWithPunctuatedWatermarks</strong>自定义接口，另外<strong>BoundedOutOfOrdernessTimestampExtractor</strong>类也继承自<strong>AssignerWithPeriodicWatermarks</strong>类</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> BoundedOutOfOrdernessTimestampExtractor<span class="token punctuation">[</span>UserBehavior<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> UserBehavior<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token operator">?</span><span class="token operator">?</span><span class="token operator">?</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h1 id="底层API"><a href="#底层API" class="headerlink" title="底层API"></a>底层API</h1><blockquote>
<p>我们之前学习的转换算子是无法访问事件的时间戳信息和水位线信息的。而这在一些应用场景下，极为重要。例如 MapFunction 这样的 map 转换算子就无法访问时间戳或者当前事件的事件时间。 </p>
<p>基于此，DataStream API 提供了一系列的 Low-Level 转换算子。可以访问时间戳、watermark 以及注册定时事件。还可以输出特定的一些事件，例如超时事件等。 Process Function 用来构建事件驱动的应用以及实现自定义的业务逻辑(使用之前的window 函数和转换算子无法实现)。例如，<strong>Flink SQL 就是使用 Process Function 实现的。</strong> </p>
</blockquote>
<ul>
<li><strong>ProcessFunction</strong></li>
<li>**KeyedProcessFunction **</li>
<li><strong>CoProcessFunction</strong></li>
<li>BroadcastProcessFunction</li>
<li>KeyedBroadcastProcessFunction</li>
<li>ProcessWindowFunction</li>
<li>ProcessAllWindowFunction</li>
</ul>
<h2 id="KeyedProcessFunction"><a href="#KeyedProcessFunction" class="headerlink" title="KeyedProcessFunction"></a>KeyedProcessFunction</h2><ol>
<li><p>KeyedProcessFunction 用来操作 KeyedStream</p>
</li>
<li><p>KeyedProcessFunction 会处理流的每一个元素，输出为 0 个、1 个或者多个元素。</p>
</li>
<li><p>所有的 Process Function 都继承自RichFunction 接口，所以都有 open()、close()和 getRuntimeContext()等方法。而KeyedProcessFunction[KEY, IN, OUT]还额外提供了两个方法:</p>
<ol>
<li>processElement(v: IN, ctx: Context, out: Collector[OUT]), <strong>流中的每一个元素都会调用这个方法，调用结果将会放在 Collector 数据类型中输出</strong>。Context可以访问元素的时间戳、元素的 key以及 TimerService 时间服务。Context还可以将结果输出到别的流(side outputs)。</li>
<li>onTimer(timestamp: Long, ctx: OnTimerContext, out: Collector[OUT])是一个回调函数。当之前注册的定时器触发时调用。参数 timestamp 为定时器所设定的触发的时间戳。Collector 为输出结果的集合。OnTimerContext 和processElement 的 Context 参数一样，提供了上下文的一些信息，例如定时器触发的时间信息(事件时间或者处理时间)。</li>
</ol>
<h3 id="TimerService-和-定时器（Timers）"><a href="#TimerService-和-定时器（Timers）" class="headerlink" title="TimerService 和 定时器（Timers）"></a>TimerService 和 定时器（Timers）</h3><blockquote>
<p>Context 和 OnTimerContext 所持有的 TimerService 对象拥有以下方法: </p>
</blockquote>
<ol>
<li>currentProcessingTime(): Long 返回当前处理时间</li>
<li>currentWatermark(): Long 返回当前 watermark 的时间戳</li>
<li>registerProcessingTimeTimer(timestamp: Long): Unit 会注册当前 key 的processing time 的定时器。当 processing time 到达定时时间时，触发 timer。</li>
<li>registerEventTimeTimer(timestamp: Long): Unit 会注册当前 key 的 event time定时器。当水位线大于等于定时器注册的时间时，触发定时器执行回调函数。 </li>
<li>deleteProcessingTimeTimer(timestamp: Long): Unit 删除之前注册处理时间定时器。如果没有这个时间戳的定时器，则不执行。</li>
<li>deleteEventTimeTimer(timestamp: Long): Unit 删除之前注册的事件时间定时器，如果没有此时间戳的定时器，则不执行。</li>
</ol>
</li>
</ol>
<blockquote>
<p>温度连续上升</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
   <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
   env<span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
   <span class="token comment">//接收数据</span>
   <span class="token keyword">val</span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">9000</span><span class="token punctuation">)</span>
   <span class="token comment">//分隔接收的数据，并返回一个Sensor实例对象</span>
   <span class="token keyword">val</span> mapStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
     <span class="token keyword">val</span> line <span class="token operator">=</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
     <span class="token keyword">new</span> SensorReading<span class="token punctuation">(</span>line<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toString<span class="token punctuation">,</span> line<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> line<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
   <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
   <span class="token comment">//分配时间戳和水位线</span>
   <span class="token keyword">val</span> stream <span class="token operator">=</span> mapStream<span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> BoundedOutOfOrdernessTimestampExtractor<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
     <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
       element<span class="token punctuation">.</span>timestamp <span class="token operator">*</span> <span class="token number">1000</span>
     <span class="token punctuation">&#125;</span>
   <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
   <span class="token comment">//先对id进行分区，然后通过ProcessFunction(底层API)进行操作</span>
   <span class="token keyword">val</span> processStream <span class="token operator">=</span> stream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
     <span class="token punctuation">.</span>process<span class="token punctuation">(</span><span class="token keyword">new</span> TempIncrese<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

   <span class="token comment">//输出</span>
   mapStream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"sensor data:"</span><span class="token punctuation">)</span>
   processStream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"process function:"</span><span class="token punctuation">)</span>

   <span class="token comment">//执行操作</span>
   env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"process function test"</span><span class="token punctuation">)</span>
 <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> TempIncrese <span class="token keyword">extends</span> KeyedProcessFunction<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>

  <span class="token comment">//定义一个状态，用于保存上一个数据的温度值</span>
  <span class="token keyword">lazy</span> <span class="token keyword">val</span> lastTemp<span class="token operator">:</span> ValueState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>getRuntimeContext
    <span class="token punctuation">.</span>getState<span class="token punctuation">(</span><span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"lastTemp"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token comment">//定义一个状态，保存定时器的时间戳</span>
  <span class="token keyword">lazy</span> <span class="token keyword">val</span> currentTimer<span class="token operator">:</span> ValueState<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> getRuntimeContext
    <span class="token punctuation">.</span>getState<span class="token punctuation">(</span><span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"currentTimer"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token comment">//流中的每一个元素都会调用这个方法，调用结果将会放在 Collector 数据类型中输出</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> processElement<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span>
                              ctx<span class="token operator">:</span> KeyedProcessFunction<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span>#Context<span class="token punctuation">,</span>
                              out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//取出上一个温度值</span>
    <span class="token keyword">val</span> preTemp <span class="token operator">=</span> lastTemp<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//取出保存的定时器的时间戳</span>
    <span class="token keyword">val</span> curTimer <span class="token operator">=</span> currentTimer<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//更新温度值</span>
    lastTemp<span class="token punctuation">.</span>update<span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span>

    <span class="token comment">//如果当前元素的温度值大于上一次的温度值，并且没有设置定时器，那么就设置定时器</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature <span class="token operator">></span> preTemp <span class="token operator">&amp;&amp;</span> curTimer <span class="token operator">==</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token comment">//获取当前事件时间，并加上10s，即10000ms</span>
      <span class="token keyword">val</span> timeTs <span class="token operator">=</span> ctx<span class="token punctuation">.</span>timerService<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>currentProcessingTime<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">10000</span>
      <span class="token comment">//注册事件时间定时器,10秒钟之后触发</span>
      ctx<span class="token punctuation">.</span>timerService<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>registerProcessingTimeTimer<span class="token punctuation">(</span>timeTs<span class="token punctuation">)</span>
      <span class="token comment">//更新定时器时间戳</span>
      currentTimer<span class="token punctuation">.</span>update<span class="token punctuation">(</span>timeTs<span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature <span class="token operator">&lt;</span> preTemp <span class="token operator">||</span> preTemp <span class="token operator">==</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token comment">//如果当前元素的温度值小于上一次的温度值，或者当前是第一个温度值，就删除定时器</span>
      ctx<span class="token punctuation">.</span>timerService<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>deleteProcessingTimeTimer<span class="token punctuation">(</span>curTimer<span class="token punctuation">)</span>
      <span class="token comment">//清空状态变量</span>
      currentTimer<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">/**
    * onTimer(timestamp: Long, ctx: OnTimerContext, out: Collector[OUT])是一个回调函数。当之前注册的定时器触发时调用。
    *
    * @param timestamp 定时器所设定的触发的时间戳
    * @param ctx
    * @param out       输出结果的集合
    */</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> onTimer<span class="token punctuation">(</span>timestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span>
                       ctx<span class="token operator">:</span> KeyedProcessFunction<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span>#OnTimerContext<span class="token punctuation">,</span>
                       out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token string">"传感器id为："</span> <span class="token operator">+</span> ctx<span class="token punctuation">.</span>getCurrentKey <span class="token operator">+</span> <span class="token string">"传感器的温度值已连续上升。"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="侧输出流"><a href="#侧输出流" class="headerlink" title="侧输出流"></a>侧输出流</h2><p>​    大部分的 DataStream API 的算子的输出是单一输出，也就是某种数据类型的流。除了 split 算子，可以将一条流分成多条流，这些流的数据类型也都相同。</p>
<p>​    <strong>process function 的 side outputs 功能可以产生多条流，并且这些流的数据类型可以不一样。一个 side output 可以定义为 OutputTag[X]对象，X 是输出流的数据类型。process function 可以通过 Context 对象发射一个事件到一个或者多个 side outputs。</strong> </p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
   <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
   env<span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
   <span class="token comment">//接收数据</span>
   <span class="token keyword">val</span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">9000</span><span class="token punctuation">)</span>
   <span class="token comment">//分隔接收的数据，并返回一个Sensor实例对象</span>
   <span class="token keyword">val</span> mapStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span> <span class="token operator">=</span> dataStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
     <span class="token keyword">val</span> line <span class="token operator">=</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
     <span class="token keyword">new</span> SensorReading<span class="token punctuation">(</span>line<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toString<span class="token punctuation">,</span> line<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> line<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>trim<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span>
   <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
   <span class="token comment">//分配时间戳和水位线</span>
   <span class="token keyword">val</span> stream <span class="token operator">=</span> mapStream<span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> BoundedOutOfOrdernessTimestampExtractor<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
     <span class="token keyword">override</span> <span class="token keyword">def</span> extractTimestamp<span class="token punctuation">(</span>element<span class="token operator">:</span> SensorReading<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
       element<span class="token punctuation">.</span>timestamp <span class="token operator">*</span> <span class="token number">1000</span>
     <span class="token punctuation">&#125;</span>
   <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
   <span class="token comment">//先对id进行分区，然后通过ProcessFunction(底层API)进行操作</span>
   <span class="token keyword">val</span> processStream <span class="token operator">=</span> stream
     <span class="token punctuation">.</span>process<span class="token punctuation">(</span><span class="token keyword">new</span> MySideOutputTest<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//得到侧输出流</span>
   processStream<span class="token punctuation">.</span>getSideOutput<span class="token punctuation">(</span><span class="token keyword">new</span> OutputTag<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"low tem alert"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"side"</span><span class="token punctuation">)</span>
   processStream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"out"</span><span class="token punctuation">)</span>

   <span class="token comment">//执行操作</span>
   env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"process function test"</span><span class="token punctuation">)</span>
 <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">//温度报警,小于32输出报警信息到侧输出流</span>
<span class="token keyword">class</span> MySideOutputTest<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> ProcessFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">,</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">&#123;</span>
  <span class="token keyword">lazy</span> <span class="token keyword">val</span> outputTag<span class="token operator">=</span><span class="token keyword">new</span> OutputTag<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"low tem alert"</span><span class="token punctuation">)</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> processElement<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> ctx<span class="token operator">:</span> ProcessFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">,</span> SensorReading<span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature<span class="token operator">&lt;</span><span class="token number">32.0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
      ctx<span class="token punctuation">.</span>output<span class="token punctuation">(</span>outputTag<span class="token punctuation">,</span><span class="token string">"low tem alert"</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token punctuation">&#123;</span>
      out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="CoProcessFunction"><a href="#CoProcessFunction" class="headerlink" title="CoProcessFunction"></a>CoProcessFunction</h2><blockquote>
<p> 对于两条输入流，DataStream API 提供了 CoProcessFunction 这样的 low-level操作。CoProcessFunction 提供了操作每一个输入流的方法: processElement1()和processElement2()。 </p>
<p> 类似于 ProcessFunction，这两种方法都通过 Context 对象来调用。这个 Context对象可以访问事件数据，定时器时间戳，TimerService，以及 side outputs。 CoProcessFunction 也提供了 onTimer()回调函数。 </p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> MyCoMap<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> CoProcessFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">,</span>SensorReading<span class="token punctuation">,</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">&#123;</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> processElement1<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> ctx<span class="token operator">:</span> CoProcessFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> SensorReading<span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token operator">?</span><span class="token operator">?</span><span class="token operator">?</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> processElement2<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> ctx<span class="token operator">:</span> CoProcessFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> SensorReading<span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span>SensorReading<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token operator">?</span><span class="token operator">?</span><span class="token operator">?</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="状态编程"><a href="#状态编程" class="headerlink" title="状态编程"></a>状态编程</h1><h2 id="Flink的几种状态类型"><a href="#Flink的几种状态类型" class="headerlink" title="Flink的几种状态类型"></a>Flink的几种状态类型</h2><blockquote>
<h3 id="Managed-State和Raw-State"><a href="#Managed-State和Raw-State" class="headerlink" title="Managed State和Raw State"></a>Managed State和Raw State</h3><p>Flink有两种基本类型的状态：托管状态（Managed State）和原生状态（Raw State）。从名称中也能读出两者的区别：Managed State是由Flink管理的，Flink帮忙存储、恢复和优化，Raw State是开发者自己管理的，需要自己序列化。</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>Managed State</th>
<th>Raw State</th>
</tr>
</thead>
<tbody><tr>
<td>状态管理方式</td>
<td>Flink Runtime托管，自动存储、自动恢复、自动伸缩</td>
<td>用户自己管理</td>
</tr>
<tr>
<td>状态数据结构</td>
<td>Flink提供的常用数据结构，如ListState、MapState等</td>
<td>字节数组：byte[]</td>
</tr>
<tr>
<td>使用场景</td>
<td>绝大多数Flink算子</td>
<td>用户自定义算子</td>
</tr>
</tbody></table>
<p>两者的具体区别有：</p>
<ul>
<li>从状态管理的方式上来说，Managed State由Flink Runtime托管，状态是自动存储、自动恢复的，Flink在存储管理和持久化上做了一些优化。当我们横向伸缩，或者说我们修改Flink应用的并行度时，状态也能自动重新分布到多个并行实例上。Raw State是用户自定义的状态。</li>
<li>从状态的数据结构上来说，Managed State支持了一系列常见的数据结构，如ValueState、ListState、MapState等。Raw State只支持字节，任何上层数据结构需要序列化为字节数组。使用时，需要用户自己序列化，以非常底层的字节数组形式存储，Flink并不知道存储的是什么样的数据结构。</li>
<li>从具体使用场景来说，绝大多数的算子都可以通过继承Rich函数类或其他提供好的接口类，在里面使用Managed State。Raw State是在已有算子和Managed State不够用时，用户自定义算子时使用。</li>
</ul>
<p><strong>对Managed State继续细分，它又有两种类型：Keyed State和Operator State</strong></p>
<h2 id="Flink状态"><a href="#Flink状态" class="headerlink" title="Flink状态"></a>Flink状态</h2><p><img src="./pic/image-20201013160904114.png" alt="image-20201013160904114"></p>
<ul>
<li>由一个任务维护，并且用来计算某个结果的所有数据，都属于这个任务的状态</li>
<li>状态可以认为是一个本地变量，可以被业务逻辑访问</li>
<li>flink进行状态管理，包括状态一致性、故障处理及高效存储访问</li>
<li>状态与特定算子相关联</li>
<li>为了使运行时flink了解算子状态，算子需要预先注册其状态</li>
</ul>
<p><img src="./pic/16a532cb8fabec39" alt="img"></p>
<h2 id="算子状态-Operator-State"><a href="#算子状态-Operator-State" class="headerlink" title="算子状态(Operator State)"></a>算子状态(Operator State)</h2><p><img src="./pic/image-20201013182738520.png" alt="image-20201013182738520"></p>
<ul>
<li>算子状态的作用范围是算子任务，<strong>由同一并行任务所处理的所有数据都可以访问到相同状态</strong></li>
<li>状态对同一任务是共享的</li>
<li>算子状态不能由相同或者不同算子的另一个任务访问</li>
</ul>
<blockquote>
<p>Operator State可以用在所有算子上，每个算子子任务或者说每个算子实例共享一个状态，流入这个算子子任务的数据可以访问和更新这个状态。下图展示了Operator State，算子子任务1上的所有数据可以共享第一个Operator State，以此类推，每个算子子任务上的数据共享自己的状态。</p>
<p><img src="./pic/16fe9e3d1047b4fb" alt="Operator State示意图"></p>
</blockquote>
<h3 id="算子状态的数据结构"><a href="#算子状态的数据结构" class="headerlink" title="算子状态的数据结构"></a>算子状态的数据结构</h3><ul>
<li><p>列表结构（List State）</p>
<ul>
<li>将状态表示为一组数据结构</li>
</ul>
</li>
<li><p>联合列表状态(Union list state)</p>
<ul>
<li>将状态表示为数据列表，与常规列表区别在于，发生故障时，或者从保存点启动应用程序时如何恢复</li>
</ul>
</li>
<li><p>广播状态(Broadcast state)</p>
<ul>
<li>如果一个算子有多个任务，这些任务状态又相同，那么适用于广播状态</li>
</ul>
<p><img src="./pic/16a532ccad85c660" alt="img"></p>
</li>
</ul>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><blockquote>
<p>状态从本质上来说，是Flink算子子任务的一种本地数据，为了保证数据可恢复性，使用Checkpoint机制来将状态数据持久化输出到存储空间上<strong>。状态相关的主要逻辑有两项：一、将算子子任务本地内存数据在Checkpoint时snapshot写入存储；二、初始化或重启应用时，以一定的逻辑从存储中读出并变为算子子任务的本地内存数据。</strong>Keyed State对这两项内容做了更完善的封装，开发者可以开箱即用。<strong>对于Operator State来说，每个算子子任务管理自己的Operator State，或者说每个算子子任务上的数据流共享同一个状态，可以访问和修改该状态</strong>。Flink的算子子任务上的数据在程序重启、横向伸缩等场景下不能保证百分百的一致性。换句话说，重启Flink应用后，某个数据流元素不一定会和上次一样，还能流入该算子子任务上。因此，我们需要根据自己的业务场景来设计snapshot和restore的逻辑。为了实现这两个步骤，Flink提供了最为基础的<code>CheckpointedFunction</code>接口类。</p>
</blockquote>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">CheckpointedFunction</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// Checkpoint时会调用这个方法，我们要实现具体的snapshot逻辑，比如将哪些本地状态持久化</span>
	<span class="token keyword">void</span> <span class="token function">snapshotState</span><span class="token punctuation">(</span><span class="token class-name">FunctionSnapshotContext</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span><span class="token punctuation">;</span>
  <span class="token comment">// 初始化时会调用这个方法，向本地状态中填充数据</span>
	<span class="token keyword">void</span> <span class="token function">initializeState</span><span class="token punctuation">(</span><span class="token class-name">FunctionInitializationContext</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li>在Flink的Checkpoint机制下，当一次snapshot触发后，<code>snapshotState</code>会被调用，将本地状态持久化到存储空间上。这里我们可以先不用关心snapshot是如何被触发的，暂时理解成snapshot是自动触发的.</li>
<li><code>initializeState</code>在算子子任务初始化时被调用，初始化包括两种场景：一、整个Flink作业第一次执行，状态数据被初始化为一个默认值；二、Flink作业重启，之前的作业已经将状态输出到存储，通过这个方法将存储上的状态读出并填充到这个本地状态中。</li>
<li>目前Operator State主要有三种，其中ListState和UnionListState在数据结构上都是一种<code>ListState</code>，还有一种BroadcastState。</li>
<li>这里我们主要介绍<code>ListState</code>这种列表形式的状态。这种状态以一个列表的形式序列化并存储，以适应横向扩展时状态重分布的问题。每个算子子任务有零到多个状态S，组成一个列表<code>ListState[S]</code>。各个算子子任务将自己状态列表的snapshot到存储，整个状态逻辑上可以理解成是将这些列表连接到一起，组成了一个包含所有状态的大列表。当作业重启或横向扩展时，我们需要将这个包含所有状态的列表重新分布到各个算子子任务上。ListState和UnionListState的区别在于：ListState是将整个状态列表按照round-ribon的模式均匀分布到各个算子子任务上，每个算子子任务得到的是整个列表的子集；UnionListState按照广播的模式，将整个列表发送给每个算子子任务。</li>
<li><strong>Operator State的实际应用场景不如Keyed State多，它经常被用在Source或Sink等算子上，用来保存流入数据的偏移量或对输出数据做缓存，以保证Flink应用的Exactly-Once语义</strong>。这里我们来看一个Flink官方提供的Sink案例以了解<code>CheckpointedFunction</code>的工作原理。</li>
</ul>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">// BufferingSink需要继承SinkFunction以实现其Sink功能，同时也要继承CheckpointedFunction接口类</span>
<span class="token keyword">class</span> BufferingSink<span class="token punctuation">(</span>threshold<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token keyword">extends</span> SinkFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">with</span> CheckpointedFunction <span class="token punctuation">&#123;</span>

  <span class="token comment">// Operator List State句柄</span>
  <span class="token annotation punctuation">@transient</span>
  <span class="token keyword">private</span> <span class="token keyword">var</span> checkpointedState<span class="token operator">:</span> ListState<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

  <span class="token comment">// 本地缓存</span>
  <span class="token keyword">private</span> <span class="token keyword">val</span> bufferedElements <span class="token operator">=</span> ListBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token comment">// Sink的核心处理逻辑，将上游数据value输出到外部系统</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> invoke<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token operator">:</span> Context<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// 先将上游数据缓存到本地的缓存</span>
    bufferedElements <span class="token operator">+=</span> value
    <span class="token comment">// 当本地缓存大小到达阈值时，将本地缓存输出到外部系统</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>bufferedElements<span class="token punctuation">.</span>size <span class="token operator">==</span> threshold<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">for</span> <span class="token punctuation">(</span>element <span class="token keyword">&lt;-</span> bufferedElements<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// send it to the sink</span>
      <span class="token punctuation">&#125;</span>
      <span class="token comment">// 清空本地缓存</span>
      bufferedElements<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">// 重写CheckpointedFunction中的snapshotState</span>
  <span class="token comment">// 将本地缓存snapshot保存到存储上</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> snapshotState<span class="token punctuation">(</span>context<span class="token operator">:</span> FunctionSnapshotContext<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// 将之前的Checkpoint清理</span>
    checkpointedState<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 将最新的数据写到状态中</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>element <span class="token keyword">&lt;-</span> bufferedElements<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      checkpointedState<span class="token punctuation">.</span>add<span class="token punctuation">(</span>element<span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token comment">// 重写CheckpointedFunction中的initializeState</span>
  <span class="token comment">// 初始化状态</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> initializeState<span class="token punctuation">(</span>context<span class="token operator">:</span> FunctionInitializationContext<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// 注册ListStateDescriptor</span>
    <span class="token keyword">val</span> descriptor <span class="token operator">=</span> <span class="token keyword">new</span> ListStateDescriptor<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
      <span class="token string">"buffered-elements"</span><span class="token punctuation">,</span>
      TypeInformation<span class="token punctuation">.</span>of<span class="token punctuation">(</span><span class="token keyword">new</span> TypeHint<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// 从FunctionInitializationContext中获取OperatorStateStore，进而获取ListState</span>
    checkpointedState <span class="token operator">=</span> context<span class="token punctuation">.</span>getOperatorStateStore<span class="token punctuation">.</span>getListState<span class="token punctuation">(</span>descriptor<span class="token punctuation">)</span>

    <span class="token comment">// 如果是作业重启，读取存储中的状态数据并填充到本地缓存中</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span>isRestored<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">for</span><span class="token punctuation">(</span>element <span class="token keyword">&lt;-</span> checkpointedState<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        bufferedElements <span class="token operator">+=</span> element
      <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>

<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="键控状态-Keyed-State"><a href="#键控状态-Keyed-State" class="headerlink" title="键控状态(Keyed State)"></a>键控状态(Keyed State)</h2><p><img src="./pic/image-20201013185700801.png" alt="image-20201013185700801"></p>
<ul>
<li>键控状态时根据输入数据流中定义的键（key）来维护和访问的</li>
<li>Flink为每个key维护一个实例状态，将具有相同键的所有数据，都分到同一个算子任务中，这个任务会维护和处理这个key对应的状态</li>
<li>当任务处理一条数据的时候，他会自动将状态访问限定为当前key</li>
</ul>
<p><img src="./pic/16fe9e3d11bd7006" alt="Keyed State继承关系"></p>
<p><img src="./pic/16a532cb8f05c33d" alt="img"></p>
<blockquote>
<p>Keyed State是<code>KeyedStream</code>上的状态。假如输入流按照id为Key进行了<code>keyBy</code>分组，形成一个<code>KeyedStream</code>，数据流中所有id为1的数据共享一个状态，可以访问和更新这个状态，以此类推，每个Key对应一个自己的状态。下图展示了Keyed State，因为一个算子子任务可以处理一到多个Key，算子子任务1处理了两种Key，两种Key分别对应自己的状态</p>
<p><img src="./pic/16fe9e3d101f8d69" alt="Keyed State示意图"></p>
</blockquote>
<h3 id="键控状态数据结构"><a href="#键控状态数据结构" class="headerlink" title="键控状态数据结构"></a>键控状态数据结构</h3><ul>
<li>值状态（value state）<ul>
<li>将状态表示为单个值</li>
</ul>
</li>
<li>列表状态（List state）<ul>
<li>将状态表示为一组数据的列表</li>
</ul>
</li>
<li>映射状态(Map state)<ul>
<li>将状态表示为一组key-value对</li>
</ul>
</li>
<li>聚合状态(Reducing state)<ul>
<li>将状态表示为一个用于聚合操作的列表</li>
</ul>
</li>
</ul>
<h4 id="异同"><a href="#异同" class="headerlink" title="异同"></a>异同</h4><ul>
<li><code>ValueState[T]</code>是单一变量的状态，T是某种具体的数据类型，比如<code>Double</code>、<code>String</code>，或我们自己定义的复杂数据结构。我们可以使用<code>value()</code>方法获取状态，使用<code>update(value: T)</code>更新状态。</li>
<li><code>MapState[K, V]</code>存储一个Key-Value map，其功能与Java的<code>Map</code>几乎相同。<code>get(key: K)</code>可以获取某个key下的value，<code>put(key: K, value: V)</code>可以对某个key设置value，<code>contains(key: K)</code>判断某个key是否存在，<code>remove(key: K)</code>删除某个key以及对应的value，<code>entries(): java.lang.Iterable[java.util.Map.Entry[K, V]]</code>返回<code>MapState</code>中所有的元素，<code>iterator(): java.util.Iterator[java.util.Map.Entry[K, V]]</code>返回一个迭代器。需要注意的是，<code>MapState</code>中的key和Keyed State的key不是同一个key。</li>
<li><code>ListState[T]</code>存储了一个由T类型数据组成的列表。我们可以使用<code>add(value: T)</code>或<code>addAll(values: java.util.List[T])</code>向状态中添加元素，使用<code>get(): java.lang.Iterable[T]</code>获取整个列表，使用<code>update(values: java.util.List[T])</code>来更新列表，新的列表将替换旧的列表。</li>
<li><code>ReducingState[T]</code>和<code>AggregatingState[IN, OUT]</code>与<code>ListState[T]</code>同属于<code>MergingState[T]</code>。与<code>ListState[T]</code>不同的是，<code>ReducingState[T]</code>只有一个元素，而不是一个列表。它的原理是新元素通过<code>add(value: T)</code>加入后，与已有的状态元素使用<code>ReduceFunction</code>合并为一个元素，并更新到状态里。<code>AggregatingState[IN, OUT]</code>与<code>ReducingState[T]</code>类似，也只有一个元素，只不过<code>AggregatingState[IN, OUT]</code>的输入和输出类型可以不一样。<code>ReducingState[T]</code>和<code>AggregatingState[IN, OUT]</code>与窗口上进行<code>ReduceFunction</code>和<code>AggregateFunction</code>很像，都是将新元素与已有元素做聚合。</li>
</ul>
<blockquote>
<p>注意，Flink的核心代码目前使用Java实现的，而Java的很多类型与Scala的类型不太相同，比如<code>List</code>和<code>Map</code>。这里不再详细解释Java和Scala的数据类型的异同，但是开发者在使用Scala调用这些接口，比如状态的接口，需要注意将Java的类型转为Scala的类型。对于<code>List</code>和<code>Map</code>的转换，只需要需要引用<code>import scala.collection.JavaConversions._</code>，并在必要的地方添加后缀<code>asScala</code>或<code>asJava</code>来进行转换。此外，Scala和Java的空对象使用习惯不太相同，Java一般使用<code>null</code>表示空，Scala一般使用<code>None</code>。</p>
</blockquote>
<h2 id="横向扩展问题"><a href="#横向扩展问题" class="headerlink" title="横向扩展问题"></a>横向扩展问题</h2><blockquote>
<p>状态的横向扩展问题主要是指修改Flink应用的并行度，确切的说，每个算子的并行实例数或算子子任务数发生了变化，应用需要关停或启动一些算子子任务，某份在原来某个算子子任务上的状态数据需要平滑更新到新的算子子任务上。其实，Flink的Checkpoint就是一个非常好的在各算子间迁移状态数据的机制。算子的本地状态将数据生成快照（snapshot），保存到分布式存储（如HDFS）上。</p>
<p>横向伸缩后，算子子任务个数变化，子任务重启，相应的状态从分布式存储上重建（restore）。</p>
</blockquote>
<p><img src="./pic/16fe9e3d10e81257" alt="Flink算子扩容示意图"></p>
<blockquote>
<p>对于Keyed State和Operator State这两种状态，他们的横向伸缩机制不太相同。由于每个Keyed State总是与某个Key相对应，当横向伸缩时，Key总会被自动分配到某个算子子任务上，因此Keyed State会自动在多个并行子任务之间迁移。对于一个非<code>KeyedStream</code>，流入算子子任务的数据可能会随着并行度的改变而改变。</p>
<p>如上图所示，假如一个应用的并行度原来为2，那么数据会被分成两份并行地流入两个算子子任务，每个算子子任务有一份自己的状态，当并行度改为3时，数据流被拆成3支，或者并行度改为1，数据流合并为1支，此时状态的存储也相应发生了变化。<strong>对于横向伸缩问题，Operator State有两种状态分配方式：一种是均匀分配，另一种是将所有状态合并，再分发给每个实例上。</strong></p>
</blockquote>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><blockquote>
<p>无论是Keyed State还是Operator State，Flink的状态都是基于本地的，即每个算子子任务维护着这个算子子任务对应的状态存储，算子子任务之间的状态不能相互访问。</p>
<p>在之前各算子的介绍中曾提到，为了自定义Flink的算子，我们可以重写Rich Function接口类，比如<code>RichFlatMapFunction</code>。使用Keyed State时，我们也可以通过重写Rich Function接口类，在里面创建和访问状态。对于Operator State，我们还需进一步实现<code>CheckpointedFunction</code>接口。</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>Keyed State</th>
<th>Operator State</th>
</tr>
</thead>
<tbody><tr>
<td>适用算子类型</td>
<td>只适用于<code>KeyedStream</code>上的算子</td>
<td>可以用于所有算子</td>
</tr>
<tr>
<td>状态分配</td>
<td>每个Key对应一个状态</td>
<td>一个算子子任务对应一个状态</td>
</tr>
<tr>
<td>创建和访问方式</td>
<td>重写Rich Function，通过里面的RuntimeContext访问</td>
<td>实现<code>CheckpointedFunction</code>等接口</td>
</tr>
<tr>
<td>横向扩展</td>
<td>状态随着Key自动在多个算子子任务上迁移</td>
<td>有多种状态重新分配的方式</td>
</tr>
<tr>
<td>支持的数据结构</td>
<td>ValueState、ListState、MapState等</td>
<td>ListState、BroadcastState等</td>
</tr>
</tbody></table>
<blockquote>
<p>声明一个键控状态</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">lazy</span> <span class="token keyword">val</span> lastTemp<span class="token operator">:</span> ValueState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>getRuntimeContext
 <span class="token punctuation">.</span>getState<span class="token punctuation">(</span><span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"lastTemp"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>读取状态</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> preTemp <span class="token operator">=</span> lastTemp<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>对状态赋值</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">lastTemp<span class="token punctuation">.</span>update<span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</blockquote>
<h2 id="状态后端（state-backends）"><a href="#状态后端（state-backends）" class="headerlink" title="状态后端（state backends）"></a>状态后端（state backends）</h2><ul>
<li>每传入一条数据，有状态的算子任务都会读取和更新状态</li>
<li>有效的状态访问对处理数据的低延迟至关重要，<strong>每个并行任务都会在本地维护他的状态</strong>，确保快速的状态访问</li>
<li><strong>状态存储、访问、维护，由一个可插入组件决定，这个组件就是状态后端</strong></li>
<li>状态后端负责：本地状态管理，检查点（checkpoint）状态写入远程存储</li>
</ul>
<blockquote>
<p><strong>需要注意的是，以上所述的State对象，仅仅用于与状态进行交互（更新、删除、清空等），而真正的状态值，有可能是存在内存、磁盘、或者其他分布式存储系统中。相当于我们只是持有了这个状态的句柄。实际上：这些状态有三种存储方式</strong></p>
<ol>
<li>MemoryStateBackend</li>
<li>FsStateBackend</li>
<li>RockDBStateBackend</li>
</ol>
</blockquote>
<h3 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h3><ul>
<li>内存级的状态后端，将键控状态作为内存中的对象进行管理，将他们存储在TaskManager的JVM上，将checkpoint存储在JobManager的内存中</li>
<li>快速，低延迟，但不稳定</li>
<li><img src="./pic/image-20201015102041957.png" alt="image-20201015102041957"></li>
<li><img src="./pic/171b030b65fa8f9b" alt="img"></li>
</ul>
<h3 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h3><ul>
<li>将checkpoint存储到远程持久化文件系统上（FileSystem），对于本地状态，和MemoryStateBackend一研发，也存储在TaskManager的JVM堆上</li>
<li>state数据保存在taskmanager的内存中，执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中，可以使用hdfs等分布式文件系统。</li>
<li>同时拥有内存级别的本地访问速度、更好的容错保护</li>
<li><img src="./pic/171b03550abd6a6c" alt="img"></li>
</ul>
<h3 id="RockDBStateBackend"><a href="#RockDBStateBackend" class="headerlink" title="RockDBStateBackend"></a>RockDBStateBackend</h3><ul>
<li>将所有状态序列化以后，存入本地的RocksDB中存储，同时RocksDB需要配置一个远端的filesystem。</li>
<li>uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到filesystem中。fail over的时候从filesystem中恢复到本地。</li>
<li>RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用</li>
<li><img src="./pic/171b04060dec3c46" alt="img"></li>
</ul>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> MemoryStateBackend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//设置每1秒做一次checkpoint，默认不开启checkpoint</span>
env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><img src="./pic/image-20201015101823119.png" alt="image-20201015101823119"></p>
<h2 id="状态编程-1"><a href="#状态编程-1" class="headerlink" title="状态编程"></a>状态编程</h2><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> TempChangeFlatMap<span class="token punctuation">(</span>threshold<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> RichFlatMapFunction<span class="token punctuation">[</span>SensorReading<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">private</span> <span class="token keyword">var</span> lastTempState<span class="token operator">:</span> ValueState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

  <span class="token keyword">override</span> <span class="token keyword">def</span> open<span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//初始化声明，变量</span>
    lastTempState <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getState<span class="token punctuation">(</span><span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"lastTemp"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> flatMap<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//获取上次温度值</span>
    <span class="token keyword">val</span> lasteTemp <span class="token operator">=</span> lastTempState<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//用当前温度和上次求差</span>
    <span class="token keyword">val</span> diff <span class="token operator">=</span> <span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature <span class="token operator">-</span> lasteTemp<span class="token punctuation">)</span><span class="token punctuation">.</span>abs
    <span class="token keyword">if</span> <span class="token punctuation">(</span>diff <span class="token operator">></span> threshold<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>id<span class="token punctuation">,</span> lasteTemp<span class="token punctuation">,</span> value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
    lastTempState<span class="token punctuation">.</span>update<span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">class</span> TempChange<span class="token punctuation">(</span>threshold<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> KeyedProcessFunction<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">//定义一个状态变量，保存上次温度</span>
  <span class="token keyword">lazy</span> <span class="token keyword">val</span> lastTempState<span class="token operator">:</span> ValueState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getState<span class="token punctuation">(</span><span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"lastTemp"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> processElement<span class="token punctuation">(</span>value<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> ctx<span class="token operator">:</span> KeyedProcessFunction<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> SensorReading<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span>#Context<span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//获取上次温度值</span>
    <span class="token keyword">val</span> lasteTemp <span class="token operator">=</span> lastTempState<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//用当前温度和上次求差</span>
    <span class="token keyword">val</span> diff <span class="token operator">=</span> <span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature <span class="token operator">-</span> lasteTemp<span class="token punctuation">)</span><span class="token punctuation">.</span>abs
    <span class="token keyword">if</span> <span class="token punctuation">(</span>diff <span class="token operator">></span> threshold<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>id<span class="token punctuation">,</span> lasteTemp<span class="token punctuation">,</span> value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span>
    lastTempState<span class="token punctuation">.</span>update<span class="token punctuation">(</span>value<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>主函数</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> state <span class="token operator">=</span> stream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> TempChangeFlatMap<span class="token punctuation">(</span><span class="token number">10.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> state <span class="token operator">=</span> stream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span><span class="token punctuation">.</span>process<span class="token punctuation">(</span><span class="token keyword">new</span> TempChange<span class="token punctuation">(</span><span class="token number">10.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<blockquote>
<p><strong>flatMapWithState</strong></p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> state <span class="token operator">=</span> stream<span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>flatMapWithState<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">&#123;</span>
    <span class="token comment">//如果没状态，数据没过来,,将温度存入状态</span>
    <span class="token keyword">case</span> <span class="token punctuation">(</span>input<span class="token operator">:</span> SensorReading<span class="token punctuation">,</span> None<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">(</span>List<span class="token punctuation">.</span>empty<span class="token punctuation">,</span> Some<span class="token punctuation">(</span>input<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment">//有状态，将温度与上一次比较</span>
    <span class="token keyword">case</span> <span class="token punctuation">(</span>input<span class="token operator">:</span>SensorReading<span class="token punctuation">,</span>lasteTemp<span class="token operator">:</span>Some<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">=></span><span class="token punctuation">&#123;</span>
      <span class="token keyword">val</span> diff<span class="token operator">=</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span>temperature<span class="token operator">-</span>lasteTemp<span class="token punctuation">.</span>get<span class="token punctuation">)</span><span class="token punctuation">.</span>abs
      <span class="token keyword">if</span><span class="token punctuation">(</span>diff<span class="token operator">></span><span class="token number">10.0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
        <span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span>id<span class="token punctuation">,</span>lasteTemp<span class="token punctuation">.</span>get<span class="token punctuation">,</span>input<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Some<span class="token punctuation">(</span>input<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token punctuation">&#123;</span>
        <span class="token punctuation">(</span>List<span class="token punctuation">.</span>empty<span class="token punctuation">,</span>Some<span class="token punctuation">(</span>input<span class="token punctuation">.</span>temperature<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h1><p><img src="./pic/image-20201015102414396.png" alt="image-20201015102414396"></p>
<p><img src="./pic/16a532cb9212780f" alt="img"></p>
<h2 id="一致性状态检查点（checkpoints）"><a href="#一致性状态检查点（checkpoints）" class="headerlink" title="一致性状态检查点（checkpoints）"></a>一致性状态检查点（checkpoints）</h2><blockquote>
<p>Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个<br>Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外<br>崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常</p>
</blockquote>
<p><img src="./pic/image-20201014203546210.png" alt="image-20201014203546210"></p>
<ul>
<li>Flink故障恢复的核心是应用状态的一致性检查点</li>
<li><strong>有状态流应用的一致检查点，其实就是所有任务的状态，在某个时间点的一份拷贝，这个时间点是所有任务恰好处理完一个相同的输入数据的时候</strong></li>
</ul>
<h3 id="从检查点恢复"><a href="#从检查点恢复" class="headerlink" title="从检查点恢复"></a>从检查点恢复</h3><p><img src="./pic/image-20201014210659806.png" alt="image-20201014210659806"></p>
<ul>
<li>在执行流应用程序期间，Flink会定期保存状态的一致性检查点</li>
<li>发生故障，Flink会使用最近一次检查点来一致恢复应用程序状态，重新启动处理流程</li>
</ul>
<blockquote>
<p>遇到故障，第一步重启应用</p>
<p><img src="./pic/image-20201014211746056.png" alt="image-20201014211746056"></p>
</blockquote>
<blockquote>
<p>第二步，从checkpoint中读取状态，将状态重置，从检查点重新启动应用程序以后，其内部状态与检查点完成时的状态完全相同</p>
<p><strong>恢复到处理数字5这个状态，重新处理一次数据</strong></p>
<p><img src="./pic/image-20201014211900205.png" alt="image-20201014211900205"></p>
</blockquote>
<blockquote>
<p>第三步，开始消费，并处理加检查点到发生故障之间的所有数据</p>
<p>这种检查点的保存和恢复机制可以为应用程序提供<strong>exectly-once</strong>的一致性，因为所有算子都会保存检查点并恢复其所有状态，这样一来所有的输入流就都会被重置到检查点完成时的位置</p>
<p><img src="./pic/image-20201014212207944.png" alt="image-20201014212207944"></p>
</blockquote>
<p>存在问题，假如sum_even和sum_odd这里的数据下游有sink算子，比如数据写入kafka或者数据库，会造成数据多消费</p>
<h3 id="检查点实现算法"><a href="#检查点实现算法" class="headerlink" title="检查点实现算法"></a>检查点实现算法</h3><ul>
<li>暂停应用，保存状态到检查点，重新恢复应用</li>
<li>Flink的改进<ul>
<li><strong>基于Chandy-Lamport算法的分布式快照</strong></li>
<li><strong>将检查点的保存与数据处理分开，不暂停应用</strong></li>
</ul>
</li>
</ul>
<blockquote>
<p>检查点分界线（Checkpoint Barrier）</p>
<ul>
<li>Flink用检查点分界线把一条流上的数据按照不同的检查点分开</li>
<li>分界线之前到来的数据导致的状态更改，都会被包含在当前分界线所属的检查点中，基于分界线之后的数据导致的所有更改，会被包含在之后的检查点中</li>
</ul>
</blockquote>
<h3 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h3><ul>
<li>现在有两个输入流的应用程序，用并行是source读取</li>
</ul>
<p><img src="./pic/image-20201014221214075.png" alt="image-20201014221214075"></p>
<ul>
<li>JobManager会向每个source任务发送一条带有检查点ID的信息，通过这种方式启动检查点</li>
</ul>
<p><img src="./pic/image-20201014221021023.png" alt="image-20201014221021023"></p>
<ul>
<li>数据源将他们的状态写入检查点，并发出一个检查点barrier</li>
<li><strong>状态后端在状态存入检查点后，会通知source任务，source任务会向JobManager确认检查点完成</strong></li>
</ul>
<p><img src="./pic/image-20201014221251371.png" alt="image-20201014221251371"></p>
<ul>
<li>分界线对齐：barrier向下游传递，sum任务会等待所有输入分区的barrier都到达</li>
<li>提前到达的分区数据会被缓存，尚未到达的分区数据正常处理，知道barrier到达</li>
</ul>
<p><img src="./pic/image-20201015105101059.png" alt="image-20201015105101059"></p>
<ul>
<li>当所有输入分区的barrier都到达时，任务将他的状态保存到状态后端的检查点中，将barrier向下游发送</li>
</ul>
<p><img src="./pic/image-20201015105334561.png" alt="image-20201015105334561"></p>
<ul>
<li>向下游转发检查点barrier后，任务继续处理数据</li>
</ul>
<p><img src="./pic/image-20201015105534224.png" alt="image-20201015105534224"></p>
<ul>
<li>sink任务向JobManager确认状态保存到checkpoint完毕</li>
<li>所有任务都确认状态保存到检查点，检查点完成</li>
</ul>
<h3 id="单流的barrier"><a href="#单流的barrier" class="headerlink" title="单流的barrier"></a>单流的barrier</h3><ol>
<li><strong>屏障作为数据流的一部分随着记录被注入到数据流中。屏障永远不会赶超通常的流记录，它会</strong><br><strong>严格遵循顺序。</strong></li>
<li><strong>屏障将数据流中的记录隔离成一系列的记录集合，并将一些集合中的数据加入到当前的快照</strong><br><strong>中，而另一些数据加入到下一个快照中。</strong></li>
<li><strong>每一个屏障携带着快照的ID，快照记录着ID并且将其放在快照数据的前面。</strong></li>
<li><strong>屏障不会中断流处理，因此非常轻量级</strong>。<br><img src="./pic/16e7de41fa51878c" alt="https://github.com/heibaiying"></li>
</ol>
<h3 id="多个流的Barrier"><a href="#多个流的Barrier" class="headerlink" title="多个流的Barrier"></a>多个流的Barrier</h3><ol>
<li>不止一个输入流的时的operator，需要在快照屏障上对齐(align)输入流，才会发射出去。 </li>
<li>可以看到1,2,3会一直放在Input buffer，直到另一个输入流的快照到达Operator</li>
</ol>
<p><img src="./pic/image-20201015060901805.png" alt="image-20201015060901805"></p>
<h2 id="Savepoint"><a href="#Savepoint" class="headerlink" title="Savepoint"></a>Savepoint</h2><blockquote>
<p>从已停止作业的运行状态中恢复</p>
</blockquote>
<ul>
<li>Savepoint:是一种特殊的checkpoint，只不过不像checkpoint定期的从系统中去触发的，它是用户通过命令触发，存储格式和checkpoint也是不相同的，会将数据按照一个标准的格式存储，不管配置什么样，Flink都会从这个checkpoint恢复，是用来做版本升级一个非常好的工具；</li>
<li>External Checkpoint：对已有checkpoint的一种扩展，就是说做完一次内部的一次Checkpoint后，还会在用户给定的一个目录中，多存储一份checkpoint的数据；</li>
<li><img src="./pic/image-20201015102637502.png" alt="image-20201015102637502"></li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token comment">//启用checkpoint，多久进行一次</span>
env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">6000</span><span class="token punctuation">)</span>
<span class="token comment">//带策略得启用checkpoint</span>
env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">6000</span><span class="token punctuation">,</span> CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span>
env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">6000</span><span class="token punctuation">,</span> CheckpointingMode<span class="token punctuation">.</span>AT_LEAST_ONCE<span class="token punctuation">)</span>

env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>AT_LEAST_ONCE<span class="token punctuation">)</span>
<span class="token comment">//设置超时</span>
env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span>
<span class="token comment">//fail以后，进行三次尝试重启，每次重启间隔500ms</span>
env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span> RestartStrategies<span class="token punctuation">.</span>fixedDelayRestart<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//300s内重启三次，每次时间间隔10秒</span>
    env<span class="token punctuation">.</span>setRestartStrategy<span class="token punctuation">(</span> RestartStrategies<span class="token punctuation">.</span>failureRateRestart<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>time<span class="token punctuation">.</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">,</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>time<span class="token punctuation">.</span><span class="token punctuation">.</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="状一致性"><a href="#状一致性" class="headerlink" title="状一致性"></a>状一致性</h1><h2 id="状态一致性"><a href="#状态一致性" class="headerlink" title="状态一致性"></a>状态一致性</h2><ul>
<li>有状态的流处理，内部每个算子都可以有自己的状态</li>
<li>对于流处理内部来说，状态一致性就是要计算结果准确</li>
<li>遇到故障以后可以恢复状态，结果是完全正确的</li>
</ul>
<p><img src="./pic/image-20201015111111567.png" alt="image-20201015111111567"></p>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li>AT_MOST_ONCE（最多一次）<ul>
<li>当任务故障的时候，最简单的做法是什么也不干，既不恢复丢失的状态，也不重播丢失的数据，<strong>语义就是最多处理一次事件</strong></li>
</ul>
</li>
<li>AT_LEAST_ONCE（至少一次）<ul>
<li>在大多数场景下我们不希望丢数据，这种保障是AT_LEAST_ONCE，<strong>所有事件都得到了处理，而这些事件还可能被处理多次</strong></li>
</ul>
</li>
<li>EXACTLY_ONCE（精确一次）<ul>
<li>恰好处理一次是最严格的保证，<strong>不仅仅是没有事件丢失，并且针对每个事件，内部状态仅更新一次</strong></li>
</ul>
</li>
</ul>
<h2 id="端到端的状态一致性"><a href="#端到端的状态一致性" class="headerlink" title="端到端的状态一致性"></a>端到端的状态一致性</h2><blockquote>
<p>在真实的流处理应用中，除了流处理器外，还有数据源和输出到持久化系统，端到端的状态一致性，意味着结果的正确性要贯穿整个流处理应用的全部，每一个组件都保证了自己的一致性，整个端到端的一致性级别，取决于所有组件中一致性最弱的组件</p>
</blockquote>
<ol>
<li>内部–checkpoints</li>
<li>source– 可重设数据的读取位置</li>
<li>sink端– 从故障恢复时，数据不会复写入外部系统<ol>
<li>幂等写入</li>
<li>事务写入</li>
</ol>
</li>
</ol>
<h3 id="幂等写入"><a href="#幂等写入" class="headerlink" title="幂等写入"></a>幂等写入</h3><blockquote>
<p>一个操作，重复执行很多次，但是只有一次导致结果更改，后面不再发生变化，后面重复执行不起作用</p>
</blockquote>
<p><img src="./pic/image-20201015144027233.png" alt="image-20201015144027233"></p>
<h3 id="事务写入"><a href="#事务写入" class="headerlink" title="事务写入"></a>事务写入</h3><ul>
<li>应用程序中一系列严密的操作，所有操作必须成功完成，否则每个操作中的所有更改都会被撤销</li>
<li>具有原子性：一个事务，要么全部成功，要么一个不做</li>
<li><strong>构建事务对应checkpoint，等真正的checkpoint完成的时候，才把对应结果写入sink中</strong></li>
<li>实现方法<ul>
<li>预写日志</li>
<li>两阶段提交</li>
</ul>
</li>
</ul>
<h4 id="预写日志（Write-Ahead-log-WAL）"><a href="#预写日志（Write-Ahead-log-WAL）" class="headerlink" title="预写日志（Write-Ahead-log,WAL）"></a>预写日志（Write-Ahead-log,WAL）</h4><ul>
<li>把数据结果当成状态保存，收到checkpoint完成的通知后，一次性写入sink系统</li>
<li>数据提前在状态后端做了缓存，无论什么sink系统，都可以实现</li>
<li>DataStream API提供了一个模板类：GenericWriteAheadSink，实现这种事务sink</li>
</ul>
<h4 id="两阶段提交（Two-Phase-Commit-2PC）"><a href="#两阶段提交（Two-Phase-Commit-2PC）" class="headerlink" title="两阶段提交（Two-Phase-Commit,2PC）"></a>两阶段提交（Two-Phase-Commit,2PC）</h4><ul>
<li>对于每个checkpoint，sink会启动一个事务，并接下来所有接受的数据添加到事务里</li>
<li>将这些数据写入外部sink系统，但不提交他们——只是预提交</li>
<li>当它收到checkpoint完成的通知以后，才正式提交事务，实现结果的真正写入</li>
<li>实现了exectly-once，需要一个提供事务支持的外部sink系统，Flink提供了TwoPhaseCommitSinkFunction接口</li>
</ul>
<blockquote>
<p>2PC对外部sink系统的要求</p>
<ul>
<li>外部sink系统必须提供事务支持，sink任务必须可以模拟外部系统上的事务</li>
<li>在checkpoint的间隔期间，开启一个事务并接受数据写入</li>
<li>收到checkpoint完成的通知之前，事务必须是“等待提交”的状态，在故障恢复的情况下，可能需要一些时间，如果这个时候sink系统关闭，未提交的数据就会丢失</li>
<li>sink任务必须在进程失败后恢复事务</li>
<li>提交事务必须是幂等操作</li>
</ul>
</blockquote>
<p><img src="./pic/image-20201015152457651.png" alt="image-20201015152457651"></p>
<h1 id="Flink-Kafka"><a href="#Flink-Kafka" class="headerlink" title="Flink+Kafka"></a>Flink+Kafka</h1><p><img src=".%5Cpic%5Cimage-20201020214345874.png" alt="image-20201020214345874"></p>
<h2 id="Kafka-Copnsumer容错"><a href="#Kafka-Copnsumer容错" class="headerlink" title="Kafka Copnsumer容错"></a>Kafka Copnsumer容错</h2><ul>
<li>checkpoint机制开启的时候，kafka consumer会定期把kafka的offset信息和其他operator的状态信息保存</li>
<li>job失败以后</li>
</ul>
<h2 id="端到端的一致性保证-必须手动开启checkpoint机制"><a href="#端到端的一致性保证-必须手动开启checkpoint机制" class="headerlink" title="端到端的一致性保证(必须手动开启checkpoint机制)"></a>端到端的一致性保证(必须手动开启checkpoint机制)</h2><ul>
<li>内部 —— 利用checkpoint机制，把状态存盘，发送故障的时候可以恢复，保证内部的状态一致性</li>
<li>source —— kafka consumer作为source，可以将偏移量保存下来，如果后续任务出现故障，恢复的时候，可以由连接器重置偏移量，重新消费数据，保证一致性</li>
<li>sink —— <strong>kafka producer作为sink，采用两阶段提交sink，需要实现一个TwoPhaseCommitSinkFunction，FlinkKafkaProducer011继承了TwoPhaseCommitSinkFunction方法</strong></li>
</ul>
<h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p><img src="./pic/image-20201015193251982.png" alt="image-20201015193251982"></p>
<ul>
<li>Jobmanager协调各个TaskManager进行checkpoint存储</li>
<li>checkpoint保存在StateBackend，默认StateBackend是内存级，也可以改成为文件级的进行持久化存储</li>
</ul>
<p><img src="./pic/image-20201015193600816.png" alt="image-20201015193600816"></p>
<ul>
<li>当checkpoint启动时，JobManager会将检查点分界线（barrier）注入数据流</li>
<li>barrier会在算子间传递下去</li>
</ul>
<p><img src="./pic/image-20201015193908465.png" alt="image-20201015193908465"></p>
<ul>
<li>每个算子会对当前的状态做个快照，保存到状态后端</li>
<li>checkpoint机制可以保证内部的状态一致性</li>
</ul>
<p><img src="./pic/image-20201015194122327.png" alt="image-20201015194122327"></p>
<ul>
<li>每个内部的transform任务遇到barrier时，都会把状态存到checkpoint里</li>
<li>sink任务首先把数据写入外部kafka，这些数据都属于预提交的事务，遇到barrier时，把状态保存在状态后端，并开启新的预提交事务</li>
</ul>
<p><img src="./pic/image-20201015194508559.png" alt="image-20201015194508559"></p>
<ul>
<li>当所有算子任务的快照完成，也就是这次checkpoint完成时，JobManager会向所有任务发通知，确认这次checkpoint完成</li>
<li>sink任务收到确认通知，正式提交之前的事务，kafka中未确认数据改为“已确认”</li>
</ul>
<h3 id="两阶段提交步骤"><a href="#两阶段提交步骤" class="headerlink" title="两阶段提交步骤"></a>两阶段提交步骤</h3><ul>
<li>第一条数据到达，开启一个kafka事务，正常写入kafka分区日志但标记为未提交，这就是预提交</li>
<li>JobManager触发checkpoint操作，barrier从source开始向下传递，遇到barrier的算子将状态存入状态后端，并通知jobmanager，并开启下一阶段的事务，用于提交下一个检查点的数据</li>
<li>JobManager收到所有任务的通知，发出确认信息，表示checkpoint完成</li>
<li>sink任务收到jobManager的确认信息，正式提交这段时间的数据</li>
<li>外部kafka关闭事务，提交的数据可以正常消费</li>
</ul>
<h2 id="flink消费kafka数据"><a href="#flink消费kafka数据" class="headerlink" title="flink消费kafka数据"></a>flink消费kafka数据</h2><h3 id="Kafka-Api"><a href="#Kafka-Api" class="headerlink" title="Kafka Api"></a>Kafka Api</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token punctuation">&#123;</span>Collections<span class="token punctuation">,</span> Properties<span class="token punctuation">&#125;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token punctuation">&#123;</span>ConsumerRecords<span class="token punctuation">,</span> KafkaConsumer<span class="token punctuation">&#125;</span>

<span class="token keyword">object</span> kafka_api <span class="token punctuation">&#123;</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// 配置信息</span>
    <span class="token keyword">val</span> prop <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"47.88.89.63:9092"</span><span class="token punctuation">)</span>
    <span class="token comment">// 指定消费者组</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"group01"</span><span class="token punctuation">)</span>
    <span class="token comment">// 指定消费位置: earliest/latest/none</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span>
    <span class="token comment">// 指定消费的key的反序列化方式</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span>
    <span class="token comment">// 指定消费的value的反序列化方式</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"session.timeout.ms"</span><span class="token punctuation">,</span> <span class="token string">"30000"</span><span class="token punctuation">)</span>
    <span class="token comment">// 得到Consumer实例</span>
    <span class="token keyword">val</span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> KafkaConsumer<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>prop<span class="token punctuation">)</span>
    <span class="token comment">// 首先需要订阅topic</span>
    kafkaConsumer<span class="token punctuation">.</span>subscribe<span class="token punctuation">(</span>Collections<span class="token punctuation">.</span>singletonList<span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">// 开始消费数据</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token comment">// 如果Kafak中没有消息，会隔timeout这个值读一次。比如上面代码设置了2秒，也是就2秒后会查一次。</span>
      <span class="token comment">// 如果Kafka中还有消息没有消费的话，会马上去读，而不需要等待。</span>
      <span class="token keyword">val</span> msgs<span class="token operator">:</span> ConsumerRecords<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> kafkaConsumer<span class="token punctuation">.</span>poll<span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span>
      <span class="token comment">// println(msgs.count())</span>
      <span class="token keyword">val</span> it <span class="token operator">=</span> msgs<span class="token punctuation">.</span>iterator<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>it<span class="token punctuation">.</span>hasNext<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">val</span> msg <span class="token operator">=</span> it<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span>
        println<span class="token punctuation">(</span>s<span class="token string">"partition: $&#123;msg.partition()&#125;, offset: $&#123;msg.offset()&#125;, key: $&#123;msg.key()&#125;, value: $&#123;msg.value()&#125;"</span><span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> myConsumer <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaConsumer010<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
myConsumer<span class="token punctuation">.</span>setStartFromEarliest<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment">// 尽可能从最早的记录开始</span>
myConsumer<span class="token punctuation">.</span>setStartFromLatest<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment">// 从最新的记录开始</span>
myConsumer<span class="token punctuation">.</span>setStartFromTimestamp<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>  <span class="token comment">// 从指定的时间开始（毫秒）</span>
myConsumer<span class="token punctuation">.</span>setStartFromGroupOffsets<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">// 默认的方法</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<ul>
<li><code>setStartFromGroupOffsets</code>（默认方法）：从 Kafka brokers 中的 consumer 组（consumer 属性中的 <code>group.id</code> 设置）提交的偏移量中开始读取分区。 如果找不到分区的偏移量，那么将会使用配置中的 <code>auto.offset.reset</code> 设置。</li>
<li><code>setStartFromEarliest()</code> 或者 <code>setStartFromLatest()</code>：从最早或者最新的记录开始消费，在这些模式下，Kafka 中的 committed offset 将被忽略，不会用作起始位置。</li>
<li><code>setStartFromTimestamp(long)</code>：从指定的时间戳开始。对于每个分区，其时间戳大于或等于指定时间戳的记录将用作起始位置。如果一个分区的最新记录早于指定的时间戳，则只从最新记录读取该分区数据。在这种模式下，Kafka 中的已提交 offset 将被忽略，不会用作起始位置。</li>
</ul>
<p>为每个分区指定consumer具体消费的offset</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> specificStartOffsets <span class="token operator">=</span> <span class="token keyword">new</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HashMap<span class="token punctuation">[</span>KafkaTopicPartition<span class="token punctuation">,</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span><span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
specificStartOffsets<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token keyword">new</span> KafkaTopicPartition<span class="token punctuation">(</span><span class="token string">"myTopic"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">23L</span><span class="token punctuation">)</span>
specificStartOffsets<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token keyword">new</span> KafkaTopicPartition<span class="token punctuation">(</span><span class="token string">"myTopic"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">31L</span><span class="token punctuation">)</span>
specificStartOffsets<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token keyword">new</span> KafkaTopicPartition<span class="token punctuation">(</span><span class="token string">"myTopic"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">43L</span><span class="token punctuation">)</span>

myConsumer<span class="token punctuation">.</span>setStartFromSpecificOffsets<span class="token punctuation">(</span>specificStartOffsets<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>上面的例子中使用的配置是指定从 <code>myTopic</code> 主题的 0 、1 和 2 分区的指定偏移量开始消费。offset 值是 consumer 应该为每个分区读取的下一条消息。请注意：如果 consumer 需要读取在提供的 offset 映射中没有指定 offset 的分区，那么它将回退到该特定分区的默认组偏移行为（即 <code>setStartFromGroupOffsets()</code>）。</p>
<p>请注意：当 Job 从故障中自动恢复或使用 savepoint 手动恢复时，<strong>这些起始位置配置方法不会影响消费的起始位置。在恢复时，每个 Kafka 分区的起始位置由存储在 savepoint 或 checkpoint 中的 offset 确定</strong>。</p>
</blockquote>
<h3 id="flink-API-推荐-集成两阶段提交的接口"><a href="#flink-API-推荐-集成两阶段提交的接口" class="headerlink" title="flink API(推荐)  集成两阶段提交的接口"></a>flink API(推荐)  集成两阶段提交的接口</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">object</span> kafkaConsume_flink <span class="token punctuation">&#123;</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment">//stream1.print("stream1").setParallelism(1)</span>
    <span class="token keyword">val</span> props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>

    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"47.88.89.63:9092"</span><span class="token punctuation">)</span>
    <span class="token comment">//props.put("bootstrap.servers", "node1:9092,node2:9092,node3:9092,node4:9092")</span>
    <span class="token comment">/**
      * Producer希望leader返回接受消息后的确认信息. 可选值 all, -1, 0 1. 默认值为1.
      * 1.> acks=0 不需要等待leader尽心确认. 此时retries设置无效. 响应里来自服务端的offset总是-1.
      * Producer只管发不管发送成功与否。延迟低，容易丢失数据。
      * 2.> acks=1 表示leader写入成功（但是并没有刷新到磁盘）后即向Producer响应。延迟中等，但是一旦
      * leader副本挂了，就会丢失数据。
      * 3.> acks=all 等待数据完成副本的复制, 等同于-1. 假如需要保证消息不丢失, 需要使用该设置. 同时
      * 需要设置unclean.leader.election.enable为true, 保证当ISR列表为空时, 选择其他存活的副本作为新的leader.
      */</span>
<span class="token comment">//    props.put("acks", "all")</span>

    <span class="token comment">/**
      * 设置大于零的值时，Producer会发送失败后会进行重试。
      */</span>
<span class="token comment">//    props.setProperty("retries", "0")</span>
<span class="token comment">//</span>
<span class="token comment">//    /**</span>
<span class="token comment">//      * Producer批量发送同一个partition消息以减少请求的数量从而提升客户端和服务端的性能，默认大小是16348 byte(16k).</span>
<span class="token comment">//      * 发送到broker的请求可以包含多个batch, 每个batch的数据属于同一个partition，太小的batch会降低吞吐.太大会浪费内存.</span>
<span class="token comment">//      */</span>
<span class="token comment">//    props.setProperty("batch.size", "16384")</span>
<span class="token comment">//</span>
<span class="token comment">//    /**</span>
<span class="token comment">//      * batch.size和liner.ms配合使用，前者限制大小后者限制时间。前者条件满足的时候，同一partition的消息会立即发送,</span>
<span class="token comment">//      * 此时linger.ms的设置无效，假如要发送的消息比较少, 则会等待指定的时间以获取更多的消息，此时linger.ms生效.</span>
<span class="token comment">//      * 默认设置为0ms(没有延迟).</span>
<span class="token comment">//      */</span>
<span class="token comment">//    props.setProperty("linger.ms", "1")</span>
<span class="token comment">//</span>
<span class="token comment">//    /**</span>
<span class="token comment">//      * Producer可以使用的最大内存来缓存等待发送到server端的消息.默认值33554432 byte(32m)</span>
<span class="token comment">//      */</span>
<span class="token comment">//    props.setProperty("buffer.memory", "33554432")</span>
<span class="token comment">//    props.setProperty("compression.type", "snappy")</span>
<span class="token comment">//    props.setProperty("max.request.size", "10485760")</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"student-HotItems"</span><span class="token punctuation">)</span>

    <span class="token comment">/**
      * topic不存在，则自动创建
      */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.create.topics.enable"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span>

    <span class="token comment">/**
      * 消费消息的起点
      */</span>
    <span class="token comment">//props.setProperty("auto.offset.reset", "earliest")</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"latest"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> stream3 <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaConsumer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"flink"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">)</span>

    stream3<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"kafka"</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"SourceTest"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>consumer 配置</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">    Properties props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"node1:9092,node2:9092,node3:9092,node4:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">/**
     * Kafka08
     */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.commit.enable"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">/**
     * kafka010
     */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.commit.interval.ms"</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"session.timeout.ms"</span><span class="token punctuation">,</span> <span class="token string">"30000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">/**
     * 用来限制每次consumer fetch数据的大小限制，只是限制partition的，无法限制到一次拉取的总量。
     */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"max.partition.fetch.bytes"</span><span class="token punctuation">,</span> <span class="token string">"10485760"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"fetch.message.max.bytes"</span><span class="token punctuation">,</span> <span class="token string">"3072000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.ByteArrayDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span>
<span class="token comment">//props.setProperty("auto.offset.reset", "latest")</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Kafka-consumer容错"><a href="#Kafka-consumer容错" class="headerlink" title="Kafka consumer容错"></a>Kafka consumer容错</h3><blockquote>
<p>伴随着启用 Flink 的 checkpointing 后，Flink Kafka Consumer 将使用 topic 中的记录，并以一致的方式定期检查其所有 Kafka offset 和其他算子的状态。如果 Job 失败，Flink 会将流式程序恢复到最新 checkpoint 的状态，并从存储在 checkpoint 中的 offset 开始重新消费 Kafka 中的消息。</p>
<p>因此，设置 checkpoint 的间隔定义了程序在发生故障时最多需要返回多少。</p>
<p>要使用容错的 Kafka Consumer，需要在执行环境中启用拓扑的 checkpointing。</p>
<p>如果未启用 checkpoint，那么 Kafka consumer 将定期向 Zookeeper 提交 offset。</p>
</blockquote>
<h3 id="Kafka-Consumer-动态加载topic"><a href="#Kafka-Consumer-动态加载topic" class="headerlink" title="Kafka Consumer 动态加载topic"></a>Kafka Consumer 动态加载topic</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> myConsumer <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaConsumer010<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
  java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>regex<span class="token punctuation">.</span>Pattern<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">"test-topic-[0-9]"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">,</span>
  properties<span class="token punctuation">)</span>

<span class="token keyword">val</span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">(</span>myConsumer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Kafka-consumer-offset自动提交"><a href="#Kafka-consumer-offset自动提交" class="headerlink" title="Kafka consumer offset自动提交"></a>Kafka consumer offset自动提交</h3><blockquote>
<p>checkpoint关闭时，可以通过下面设置配置自动提交</p>
<pre class="line-numbers language-none"><code class="language-none">enable.auto.commit
auto.commit.interval.ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>checkpoint开启时，执行checkpoint时才会保存offset，这样保证了kafka的offset和checkpoint的状态偏移量一致</p>
<ul>
<li><p>如果启用了 checkpointing，那么当 checkpointing 完成时，Flink Kafka Consumer 将提交的 offset 存储在 checkpoint 状态中。 这确保 Kafka broker 中提交的 offset 与 checkpoint 状态中的 offset 一致。 用户可以通过调用 consumer 上的 <code>setCommitOffsetsOnCheckpoints(boolean)</code> 方法来禁用或启用 offset 的提交(默认情况下，这个值是 true )。 注意，在这个场景中，<code>Properties</code> 中的自动定期 offset 提交设置会被完全忽略</p>
<ul>
<li>```scala<br> new FlinkKafkaConsumer011[String](“HotItems”, new SimpleStringSchema(), props).setCommitOffsetsOnCheckpoints(true)<pre class="line-numbers language-none"><code class="language-none">
*  如果禁用了 checkpointing，则 Flink Kafka Consumer 依赖于内部使用的 Kafka client 自动定期 offset 提交功能。 因此，要禁用或启用 offset 的提交，只需将 &#96;enable.auto.commit&#96; 或者 &#96;auto.commit.interval.ms&#96; 的Key 值设置为提供的 &#96;Properties&#96; 配置中的适当值

### kafka watermark生成

&#96;&#96;&#96;scala
val properties &#x3D; new Properties()
properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;)
properties.setProperty(&quot;group.id&quot;, &quot;test&quot;)

val myConsumer &#x3D; new FlinkKafkaConsumer010[String](&quot;topic&quot;, new SimpleStringSchema(), properties)
myConsumer.assignTimestampsAndWatermarks(new CustomWatermarkEmitter())
stream &#x3D; env
   .addSource(myConsumer)
   .print()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
</ul>
</blockquote>
<blockquote>
<p>在内部，每个 Kafka 分区执行一个 assigner 实例。当指定了这样的 assigner 时，对于从 Kafka 读取的每条消息，调用 <code>extractTimestamp(T element, long previousElementTimestamp)</code> 来为记录分配时间戳，并为 <code>Watermark getCurrentWatermark()</code>（定期形式）或 <code>Watermark checkAndGetNextWatermark(T lastElement, long extractedTimestamp)</code>（打点形式）以确定是否应该发出新的 watermark 以及使用哪个时间戳(生成watermark)。</p>
</blockquote>
<h2 id="flink向kafka发送数据"><a href="#flink向kafka发送数据" class="headerlink" title="flink向kafka发送数据"></a>flink向kafka发送数据</h2><h3 id="flink-api"><a href="#flink-api" class="headerlink" title="flink api"></a>flink api</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
  <span class="token keyword">val</span> stream1 <span class="token operator">=</span> env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
    SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_1"</span><span class="token punctuation">,</span> <span class="token number">1547718199</span><span class="token punctuation">,</span> <span class="token number">35.80018327300259</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_6"</span><span class="token punctuation">,</span> <span class="token number">1547718201</span><span class="token punctuation">,</span> <span class="token number">15.402984393403084</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_7"</span><span class="token punctuation">,</span> <span class="token number">1547718202</span><span class="token punctuation">,</span> <span class="token number">6.720945201171228</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    SensorReading<span class="token punctuation">(</span><span class="token string">"sensor_10"</span><span class="token punctuation">,</span> <span class="token number">1547718205</span><span class="token punctuation">,</span> <span class="token number">38.101067604893444</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>toString<span class="token operator">+</span><span class="token string">"_"</span><span class="token operator">+</span>System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>

  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"47.88.89.63:9092"</span><span class="token punctuation">)</span>
  <span class="token comment">//props.put("bootstrap.servers", "node1:9092,node2:9092,node3:9092,node4:9092")</span>
  <span class="token comment">/**
    * Producer希望leader返回接受消息后的确认信息. 可选值 all, -1, 0 1. 默认值为1.
    * 1.> acks=0 不需要等待leader尽心确认. 此时retries设置无效. 响应里来自服务端的offset总是-1.
    *     Producer只管发不管发送成功与否。延迟低，容易丢失数据。
    * 2.> acks=1 表示leader写入成功（但是并没有刷新到磁盘）后即向Producer响应。延迟中等，但是一旦
    *     leader副本挂了，就会丢失数据。
    * 3.> acks=all 等待数据完成副本的复制, 等同于-1. 假如需要保证消息不丢失, 需要使用该设置. 同时
    *     需要设置unclean.leader.election.enable为true, 保证当ISR列表为空时, 选择其他存活的副本作为新的leader.
    */</span>
  props<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span>
  <span class="token comment">/**
    * 设置大于零的值时，Producer会发送失败后会进行重试。
    */</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token string">"0"</span><span class="token punctuation">)</span>
  <span class="token comment">/**
    * Producer批量发送同一个partition消息以减少请求的数量从而提升客户端和服务端的性能，默认大小是16348 byte(16k).
    * 发送到broker的请求可以包含多个batch, 每个batch的数据属于同一个partition，太小的batch会降低吞吐.太大会浪费内存.
    */</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token string">"16384"</span><span class="token punctuation">)</span>
  <span class="token comment">/**
    * batch.size和liner.ms配合使用，前者限制大小后者限制时间。前者条件满足的时候，同一partition的消息会立即发送,
    * 此时linger.ms的设置无效，假如要发送的消息比较少, 则会等待指定的时间以获取更多的消息，此时linger.ms生效.
    * 默认设置为0ms(没有延迟).
    */</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
  <span class="token comment">/**
    * Producer可以使用的最大内存来缓存等待发送到server端的消息.默认值33554432 byte(32m)
    */</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token string">"33554432"</span><span class="token punctuation">)</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"compression.type"</span><span class="token punctuation">,</span> <span class="token string">"snappy"</span><span class="token punctuation">)</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"max.request.size"</span><span class="token punctuation">,</span> <span class="token string">"10485760"</span><span class="token punctuation">)</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="token punctuation">)</span>
  props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"student-group"</span><span class="token punctuation">)</span>
  stream1<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">)</span>
  env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"kafkaProduce"</span><span class="token punctuation">)</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="kafka-API"><a href="#kafka-API" class="headerlink" title="kafka  API"></a>kafka  API</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">object</span> kafkaProduce <span class="token punctuation">&#123;</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">val</span> dataStream <span class="token operator">=</span> env<span class="token punctuation">.</span>readTextFile<span class="token punctuation">(</span><span class="token string">"F:\\SynologyDrive\\BDCode\\FlinkProject\\UserBehaviorAnalysis\\HotItem\\src\\main\\resources\\UserBehavior.csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">new</span> KafkaMap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    dataStream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token string">"start"</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"kafkaProduce"</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>


<span class="token keyword">class</span> KafkaMap<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> RichMapFunction<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">var</span> props<span class="token operator">:</span> Properties <span class="token operator">=</span> _
  <span class="token keyword">var</span> produce<span class="token operator">:</span> KafkaProducer<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

  <span class="token keyword">override</span> <span class="token keyword">def</span> open<span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"47.88.89.63:9092"</span><span class="token punctuation">)</span>
    <span class="token comment">//    props.put("acks", "all")</span>
    <span class="token comment">//    props.setProperty("retries", "0")</span>
    <span class="token comment">//    props.setProperty("batch.size", "16384")</span>
    <span class="token comment">//    props.setProperty("linger.ms", "1")</span>
    <span class="token comment">//    props.setProperty("buffer.memory", "33554432")</span>
    <span class="token comment">//    props.setProperty("compression.type", "snappy")</span>
    <span class="token comment">//    props.setProperty("max.request.size", "10485760")</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"student-group"</span><span class="token punctuation">)</span>

    <span class="token comment">/**
      * topic不存在，自动创建
      */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"auto.create.topics.enable"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span>
    produce <span class="token operator">=</span> <span class="token keyword">new</span> KafkaProducer<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    produce<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> map<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> record <span class="token operator">=</span> <span class="token keyword">new</span> ProducerRecord<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"HotItems"</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span>
    produce<span class="token punctuation">.</span>send<span class="token punctuation">(</span>record<span class="token punctuation">)</span>
    Thread<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
    value
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>produce 配置</p>
</blockquote>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> props <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>

    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"47.88.89.63:9092"</span><span class="token punctuation">)</span>
    <span class="token comment">//props.put("bootstrap.servers", "node1:9092,node2:9092,node3:9092,node4:9092")</span>
    <span class="token comment">/**
      * Producer希望leader返回接受消息后的确认信息. 可选值 all, -1, 0 1. 默认值为1.
      * 1.> acks=0 不需要等待leader尽心确认. 此时retries设置无效. 响应里来自服务端的offset总是-1.
      *     Producer只管发不管发送成功与否。延迟低，容易丢失数据。
      * 2.> acks=1 表示leader写入成功（但是并没有刷新到磁盘）后即向Producer响应。延迟中等，但是一旦
      *     leader副本挂了，就会丢失数据。
      * 3.> acks=all 等待数据完成副本的复制, 等同于-1. 假如需要保证消息不丢失, 需要使用该设置. 同时
      *     需要设置unclean.leader.election.enable为true, 保证当ISR列表为空时, 选择其他存活的副本作为新的leader.
      */</span>
    props<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span>
    <span class="token comment">/**
      * 设置大于零的值时，Producer会发送失败后会进行重试。
      */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token string">"0"</span><span class="token punctuation">)</span>
    <span class="token comment">/**
      * Producer批量发送同一个partition消息以减少请求的数量从而提升客户端和服务端的性能，默认大小是16348 byte(16k).
      * 发送到broker的请求可以包含多个batch, 每个batch的数据属于同一个partition，太小的batch会降低吞吐.太大会浪费内存.
      */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token string">"16384"</span><span class="token punctuation">)</span>
    <span class="token comment">/**
      * batch.size和liner.ms配合使用，前者限制大小后者限制时间。前者条件满足的时候，同一partition的消息会立即发送,
      * 此时linger.ms的设置无效，假如要发送的消息比较少, 则会等待指定的时间以获取更多的消息，此时linger.ms生效.
      * 默认设置为0ms(没有延迟).
      */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
    <span class="token comment">/**
      * Producer可以使用的最大内存来缓存等待发送到server端的消息.默认值33554432 byte(32m)
      */</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token string">"33554432"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"compression.type"</span><span class="token punctuation">,</span> <span class="token string">"snappy"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"max.request.size"</span><span class="token punctuation">,</span> <span class="token string">"10485760"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="token punctuation">)</span>
    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"student-group"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Kafka-Producer官方实例"><a href="#Kafka-Producer官方实例" class="headerlink" title="Kafka Producer官方实例"></a>Kafka Producer官方实例</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> stream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token keyword">val</span> myProducer <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
        <span class="token string">"localhost:9092"</span><span class="token punctuation">,</span>         <span class="token comment">// broker 列表</span>
        <span class="token string">"my-topic"</span><span class="token punctuation">,</span>               <span class="token comment">// 目标 topic</span>
        <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">)</span>   <span class="token comment">// 序列化 schema</span>

<span class="token comment">// 0.10+ 版本的 Kafka 允许在将记录写入 Kafka 时附加记录的事件时间戳；</span>
<span class="token comment">// 此方法不适用于早期版本的 Kafka</span>
myProducer<span class="token punctuation">.</span>setWriteTimestampToKafka<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>

stream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span>myProducer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<ul>
<li><em>提供自定义属性</em>：producer 允许为内部 <code>KafkaProducer</code> 提供自定义属性配置。有关如何配置 Kafka Producer 的详细信息，请参阅 <a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation.html">Apache Kafka 文档</a>。</li>
<li><em>自定义分区器</em>：要将消息分配给特定的分区，可以向构造函数提供一个 <code>FlinkKafkaPartitioner</code> 的实现。这个分区器将被流中的每条记录调用，以确定消息应该发送到目标 topic 的哪个具体分区里。有关详细信息，请参阅 <a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/dev/connectors/kafka.html#kafka-producer-%E5%88%86%E5%8C%BA%E6%96%B9%E6%A1%88">Kafka Producer 分区方案</a>。</li>
<li><em>高级的序列化 schema</em>：与 consumer 类似，producer 还允许使用名为 <code>KeyedSerializationSchema</code> 的高级序列化 schema，该 schema 允许单独序列化 key 和 value。它还允许覆盖目标 topic，以便 producer 实例可以将数据发送到多个 topic。</li>
</ul>
</blockquote>
<h3 id="Kafka-Producer-分区方案"><a href="#Kafka-Producer-分区方案" class="headerlink" title="Kafka Producer 分区方案"></a>Kafka Producer 分区方案</h3><blockquote>
<p>默认情况下，如果没有为 Flink Kafka Producer 指定自定义分区程序，则 producer 将使用 <code>FlinkFixedPartitioner</code> 为每个 Flink Kafka Producer 并行子任务映射到单个 Kafka 分区（即，接收子任务接收到的所有消息都将位于同一个 Kafka 分区中）。</p>
<p>可以通过扩展 <code>FlinkKafkaPartitioner</code> 类来实现自定义分区程序。所有 Kafka 版本的构造函数都允许在实例化 producer 时提供自定义分区程序。 注意：分区器实现必须是可序列化的，因为它们将在 Flink 节点之间传输。此外，请记住分区器中的任何状态都将在作业失败时丢失，因为分区器不是 producer 的 checkpoint 状态的一部分。</p>
<p>也可以完全避免使用分区器，并简单地让 Kafka 通过其附加 key 写入的消息进行分区（使用提供的序列化 schema 为每条记录确定分区）。 为此，在实例化 producer 时提供 <code>null</code> 自定义分区程序，提供 <code>null</code> 作为自定义分区器是很重要的; 如上所述，如果未指定自定义分区程序，则默认使用 <code>FlinkFixedPartitioner</code>。</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala">stream1<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span><span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">(</span><span class="token string">"fuliangyu"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//默认发送到不同分区</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</blockquote>
<h3 id="Kafka-Produce产生watermark"><a href="#Kafka-Produce产生watermark" class="headerlink" title="Kafka Produce产生watermark"></a>Kafka Produce产生watermark</h3><blockquote>
<p>只有设置了 <code>setWriteTimestampToKafka(true)</code>，则 <code>FlinkKafkaProducer010</code> 才会发出记录时间戳。</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">new</span> FlinkKafkaProducer011<span class="token punctuation">(</span><span class="token string">"fuliangyu"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">.</span>setWriteTimestampToKafka<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


</blockquote>
<h1 id="Flink-Redis"><a href="#Flink-Redis" class="headerlink" title="Flink+Redis"></a>Flink+Redis</h1><h2 id="利用Redis的bitmap实现基于Flink的布隆过滤器"><a href="#利用Redis的bitmap实现基于Flink的布隆过滤器" class="headerlink" title="利用Redis的bitmap实现基于Flink的布隆过滤器"></a>利用Redis的bitmap实现基于Flink的布隆过滤器</h2><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">object</span> BoomFilterDemo <span class="token punctuation">&#123;</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    env<span class="token punctuation">.</span>setStreamTimeCharacteristic<span class="token punctuation">(</span>TimeCharacteristic<span class="token punctuation">.</span>EventTime<span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> stream <span class="token operator">=</span> env
      <span class="token punctuation">.</span>readTextFile<span class="token punctuation">(</span><span class="token string">"/Users/yuanzuo/Desktop/flink-tutorial/FlinkSZ1128/src/main/resources/UserBehavior.csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>line <span class="token keyword">=></span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">val</span> arr <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
        UserBehavior<span class="token punctuation">(</span>arr<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> arr<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> arr<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">,</span> arr<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> arr<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong <span class="token operator">*</span> <span class="token number">1000L</span><span class="token punctuation">)</span>
      <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>_<span class="token punctuation">.</span>behavior<span class="token punctuation">.</span>equals<span class="token punctuation">(</span><span class="token string">"pv"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>assignAscendingTimestamps<span class="token punctuation">(</span>_<span class="token punctuation">.</span>timestamp<span class="token punctuation">)</span> <span class="token comment">// 分配升序时间戳 DataStream</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>r <span class="token keyword">=></span> <span class="token punctuation">(</span><span class="token string">"key"</span><span class="token punctuation">,</span> r<span class="token punctuation">.</span>userId<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>hours<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>trigger<span class="token punctuation">(</span><span class="token keyword">new</span> UvTrigger<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>process<span class="token punctuation">(</span><span class="token keyword">new</span> UvProcessFunc<span class="token punctuation">)</span>

    stream<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> UvTrigger <span class="token keyword">extends</span> Trigger<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// 来一条元素调用一次</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> onElement<span class="token punctuation">(</span>element<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">,</span> timestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> window<span class="token operator">:</span> TimeWindow<span class="token punctuation">,</span> ctx<span class="token operator">:</span> Trigger<span class="token punctuation">.</span>TriggerContext<span class="token punctuation">)</span><span class="token operator">:</span> TriggerResult <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">// 来一个事件，就触发一次窗口计算，并清空窗口</span>
    TriggerResult<span class="token punctuation">.</span>FIRE_AND_PURGE
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> onProcessingTime<span class="token punctuation">(</span>time<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> window<span class="token operator">:</span> TimeWindow<span class="token punctuation">,</span> ctx<span class="token operator">:</span> Trigger<span class="token punctuation">.</span>TriggerContext<span class="token punctuation">)</span><span class="token operator">:</span> TriggerResult <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    TriggerResult<span class="token punctuation">.</span>CONTINUE
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> onEventTime<span class="token punctuation">(</span>time<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> window<span class="token operator">:</span> TimeWindow<span class="token punctuation">,</span> ctx<span class="token operator">:</span> Trigger<span class="token punctuation">.</span>TriggerContext<span class="token punctuation">)</span><span class="token operator">:</span> TriggerResult <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//窗口关闭是会触发该函数</span>
    <span class="token keyword">val</span> jedis <span class="token operator">=</span> <span class="token keyword">new</span> Jedis<span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">6379</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> windowEnd <span class="token operator">=</span> window<span class="token punctuation">.</span>getEnd<span class="token punctuation">.</span>toString
    <span class="token comment">//从redis中读取结果并打印</span>
    println<span class="token punctuation">(</span><span class="token keyword">new</span> Timestamp<span class="token punctuation">(</span>windowEnd<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span><span class="token punctuation">,</span> jedis<span class="token punctuation">.</span>hget<span class="token punctuation">(</span><span class="token string">"UvCount"</span><span class="token punctuation">,</span> windowEnd<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//在这打印时间</span>

    TriggerResult<span class="token punctuation">.</span>CONTINUE
  <span class="token punctuation">&#125;</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> clear<span class="token punctuation">(</span>window<span class="token operator">:</span> TimeWindow<span class="token punctuation">,</span> ctx<span class="token operator">:</span> Trigger<span class="token punctuation">.</span>TriggerContext<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> UvProcessFunc <span class="token keyword">extends</span> ProcessWindowFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> TimeWindow<span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
  <span class="token comment">// 连接到redis，用懒加载，只会加载一次</span>
  <span class="token keyword">lazy</span> <span class="token keyword">val</span> jedis <span class="token operator">=</span> <span class="token keyword">new</span> Jedis<span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">6379</span><span class="token punctuation">)</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> process<span class="token punctuation">(</span>key<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> context<span class="token operator">:</span> Context<span class="token punctuation">,</span> elements<span class="token operator">:</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//redis存储数据类型</span>
    <span class="token comment">// 窗口结束时间 ==> UV数</span>
    <span class="token comment">// 窗口结束时间 ==> bit数组</span>

    <span class="token comment">// 拿到key</span>
    <span class="token keyword">val</span> windowEnd <span class="token operator">=</span> context<span class="token punctuation">.</span>window<span class="token punctuation">.</span>getEnd<span class="token punctuation">.</span>toString

    <span class="token keyword">var</span> count <span class="token operator">=</span> <span class="token number">0L</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>jedis<span class="token punctuation">.</span>hget<span class="token punctuation">(</span><span class="token string">"UvCount"</span><span class="token punctuation">,</span> windowEnd<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      count <span class="token operator">=</span> jedis<span class="token punctuation">.</span>hget<span class="token punctuation">(</span><span class="token string">"UvCount"</span><span class="token punctuation">,</span> windowEnd<span class="token punctuation">)</span><span class="token punctuation">.</span>toLong
    <span class="token punctuation">&#125;</span>

    <span class="token comment">// 迭代器中只有一条元素，因为每来一条元素，窗口清空一次，见trigger</span>
    <span class="token keyword">val</span> userId <span class="token operator">=</span> elements<span class="token punctuation">.</span>head<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toString
    <span class="token comment">// 计算userId对应的bit数组的下标</span>
    <span class="token keyword">val</span> idx <span class="token operator">=</span> hash<span class="token punctuation">(</span>userId<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">20</span><span class="token punctuation">)</span>

    <span class="token comment">// 判断userId是否访问过</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>jedis<span class="token punctuation">.</span>getbit<span class="token punctuation">(</span>windowEnd<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> <span class="token comment">// 对应的bit为0的话，返回false，用户一定没访问过</span>
      jedis<span class="token punctuation">.</span>setbit<span class="token punctuation">(</span>windowEnd<span class="token punctuation">,</span> idx<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token comment">// 将idx对应的bit翻转为1</span>
      jedis<span class="token punctuation">.</span>hset<span class="token punctuation">(</span><span class="token string">"UvCount"</span><span class="token punctuation">,</span> windowEnd<span class="token punctuation">,</span> <span class="token punctuation">(</span>count <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString<span class="token punctuation">)</span> <span class="token comment">//写入结果</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token comment">// 为了方便理解，只实现一个哈希函数，返回值是Long，bit数组的下标</span>
<span class="token comment">// value: 字符串；size：bit数组的长度</span>
<span class="token keyword">def</span> hash<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> size<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">val</span> seed <span class="token operator">=</span> <span class="token number">61</span> <span class="token comment">// 种子，必须是质数，能够很好的防止相撞</span>
  <span class="token keyword">var</span> result <span class="token operator">=</span> <span class="token number">0L</span>
  <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token keyword">&lt;-</span> <span class="token number">0</span> until value<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    result <span class="token operator">=</span> result <span class="token operator">*</span> seed <span class="token operator">+</span> value<span class="token punctuation">.</span>charAt<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
  <span class="token punctuation">(</span>size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> result
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Flink-Table"><a href="#Flink-Table" class="headerlink" title="Flink Table"></a>Flink Table</h1><blockquote>
<p>Table API 和 SQL 集成在同一套 API 中。这套 API 的核心概念是<code>Table</code>，用作查询的输入和输出</p>
</blockquote>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- Either... (for the old planner that was available before Flink 1.9) --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-planner_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.11.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token comment">&lt;!-- or.. (for the new Blink planner) --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-planner-blink_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.11.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<ol>
<li>Blink 将批处理作业视作流处理的一种特例。严格来说，<code>Table</code> 和 <code>DataSet</code> 之间不支持相互转换，并且批处理作业也不会转换成 <code>DataSet</code> 程序而是转换成 <code>DataStream</code> 程序，流处理作业也一样。</li>
<li>Blink 计划器不支持 <code>BatchTableSource</code>，而是使用有界的 <code>StreamTableSource</code> 来替代。</li>
<li>旧计划器和 Blink 计划器中 <code>FilterableTableSource</code> 的实现是不兼容的。旧计划器会将 <code>PlannerExpression</code> 下推至 <code>FilterableTableSource</code>，而 Blink 计划器则是将 <code>Expression</code> 下推。</li>
<li>基于字符串的键值配置选项仅在 Blink 计划器中使用。（详情参见 <a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/dev/table/config.html">配置</a> ）</li>
<li><code>PlannerConfig</code> 在两种计划器中的实现（<code>CalciteConfig</code>）是不同的。</li>
<li>Blink 计划器会将多sink（multiple-sinks）优化成一张有向无环图（DAG），<code>TableEnvironment</code> 和 <code>StreamTableEnvironment</code> 都支持该特性。旧计划器总是将每个sink都优化成一个新的有向无环图，且所有图相互独立。</li>
<li>旧计划器目前不支持 catalog 统计数据，而 Blink 支持。</li>
</ol>
</blockquote>
<h1 id="Spark-Streaming-VS-Flink"><a href="#Spark-Streaming-VS-Flink" class="headerlink" title="Spark Streaming VS Flink"></a>Spark Streaming VS Flink</h1><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h3 id="运行角色"><a href="#运行角色" class="headerlink" title="运行角色"></a>运行角色</h3><h4 id="Spark-Streaming-运行时的角色-standalone-模式"><a href="#Spark-Streaming-运行时的角色-standalone-模式" class="headerlink" title="Spark Streaming 运行时的角色(standalone 模式)"></a>Spark Streaming 运行时的角色(standalone 模式)</h4><ul>
<li>Master:主要负责整体集群资源的管理和应用程序调度；</li>
<li>Worker:负责单个节点的资源管理，driver 和 executor 的启动等；</li>
<li>Driver:用户入口程序执行的地方，即 SparkContext 执行的地方，主要是 DAG 生成、stage 划分、task 生成及调度；</li>
<li>Executor:负责执行 task，反馈执行状态和执行结果。</li>
</ul>
<h4 id="Flink-运行时的角色-standalone-模式"><a href="#Flink-运行时的角色-standalone-模式" class="headerlink" title="Flink 运行时的角色(standalone 模式)"></a>Flink 运行时的角色(standalone 模式)</h4><ul>
<li>Jobmanager: 协调分布式执行，他们调度任务、协调 checkpoints、协调故障恢复等。至少有一个 JobManager。高可用情况下可以启动多个 JobManager，其中一个选举为 leader，其余为 standby；</li>
<li>Taskmanager: 负责执行具体的 tasks、缓存、交换数据流，至少有一个 TaskManager；</li>
<li>Slot: 每个 task slot 代表 TaskManager 的一个固定部分资源，Slot 的个数代表着 taskmanager 可并行执行的 task 数。</li>
</ul>
<h2 id="生态"><a href="#生态" class="headerlink" title="生态"></a>生态</h2><p><img src=".%5Cpic%5C16560d87ebfc9387" alt="img"></p>
<p><img src=".%5Cpic%5C16560dec4cfe489e" alt="img"></p>
<h2 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h2><blockquote>
<p>Spark Streaming 是微批处理，运行的时候需要指定批处理的时间，每次运行 job 时处理一个批次的数据</p>
</blockquote>
<blockquote>
<p>Flink 是基于事件驱动的，事件可以理解为消息。事件驱动的应用程序是一种状态应用程序，它会从一个或者多个流中注入事件，通过触发计算更新状态，或外部动作对注入的事件作出反应。</p>
</blockquote>
<h2 id="任务调度-1"><a href="#任务调度-1" class="headerlink" title="任务调度"></a>任务调度</h2><h3 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h3><blockquote>
<p>Spark Streaming 任务如上文提到的是基于微批处理的，实际上每个批次都是一个 Spark Core 的任务。对于编码完成的 Spark Core 任务在生成到最终执行结束主要包括以下几个部分：</p>
<ul>
<li>构建DAG图</li>
<li>划分stage</li>
<li>生成taskSet</li>
<li>调度task</li>
</ul>
</blockquote>
<p><img src=".%5Cpic%5C16560e2d30754931" alt="img"></p>
<p>spark对于 job 的调度执行有 fifo 和 fair 两种模式，Task 是根据数据本地性调度执行的。</p>
<h3 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h3><blockquote>
<p>对于 flink 的流任务客户端首先会生成 StreamGraph，接着生成 JobGraph，然后将 jobGraph 提交给 Jobmanager 由它完成 jobGraph 到 ExecutionGraph 的转变，最后由 jobManager 调度执行。</p>
</blockquote>
<p><img src=".%5Cpic%5C16560e34db72994e" alt="img"></p>
<blockquote>
<p>如图所示有一个由 data source、MapFunction和 ReduceFunction 组成的程序，data source 和 MapFunction 的并发度都为 4，而 ReduceFunction 的并发度为 3。一个数据流由 Source-Map-Reduce 的顺序组成，在具有 2 个TaskManager、每个 TaskManager 都有 3 个 Task Slot 的集群上运行</p>
<p><strong>可以看出 flink 的拓扑生成提交执行之后，除非故障，否则拓扑部件执行位置不变，并行度由每一个算子并行度决定，类似于 storm。而 spark Streaming 是每个批次都会根据数据本地性和资源情况进行调度，无固定的执行拓扑结构。 flink 是数据在拓扑结构里流动执行，而 Spark Streaming 则是对数据缓存批次并行处理</strong></p>
</blockquote>
<h2 id="时间机制"><a href="#时间机制" class="headerlink" title="时间机制"></a>时间机制</h2><h3 id="Flink-时间机制"><a href="#Flink-时间机制" class="headerlink" title="Flink 时间机制"></a>Flink 时间机制</h3><blockquote>
<p>flink 支持三种时间机制：事件时间，注入时间，处理时间，同时支持 watermark 机制处理滞后数据</p>
</blockquote>
<ul>
<li>处理时间</li>
</ul>
<p><strong>处理时间是指每台机器的系统时间</strong>，当流程序采用处理时间时将使用运行各个运算符实例的机器时间。处理时间是最简单的时间概念，不需要流和机器之间的协调，它能提供最好的性能和最低延迟。然而在分布式和异步环境中，处理时间不能提供消息事件的时序性保证，因为它受到消息传输延迟，消息在算子之间流动的速度等方面制约。</p>
<ul>
<li>事件时间</li>
</ul>
<p><strong>事件时间是指事件在其设备上发生的时间</strong>，这个时间在事件进入 flink 之前已经嵌入事件，然后 flink 可以提取该时间。基于事件时间进行处理的流程序可以保证事件在处理的时候的顺序性，但是基于事件时间的应用程序必须要结合 watermark 机制。基于事件时间的处理往往有一定的滞后性，因为它需要等待后续事件和处理无序事件，对于时间敏感的应用使用的时候要慎重考虑。</p>
<ul>
<li>注入时间</li>
</ul>
<p><strong>注入时间是事件注入到 flink 的时间</strong>。事件在 source 算子处获取 source 的当前时间作为事件注入时间，后续的基于时间的处理算子会使用该时间处理数据。</p>
<p>相比于事件时间，注入时间不能够处理无序事件或者滞后事件，但是应用程序无序指定如何生成 watermark。在内部注入时间程序的处理和事件时间类似，但是时间戳分配和 watermark 生成都是自动的。</p>
<p><img src=".%5Cpic%5C16560e630f3480fd" alt="img"></p>
<h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><blockquote>
<p>Spark Streaming 只支持处理时间，Structured streaming 支持处理时间和事件时间，同时支持 watermark 机制处理滞后数据。</p>
</blockquote>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul>
<li><a target="_blank" rel="noopener" href="https://juejin.im/post/6844904137709076488">Flink之state、checkpoint、savepoint</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.im/entry/6844903760762765326">Flink 原理与实现：深入理解Flink核心技术</a></li>
<li><a target="_blank" rel="noopener" href="https://juejin.im/post/6844903967940411405">Flink on YARN（上）</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/reflyalex/flink-learning">Flink Learning</a></li>
<li><a target="_blank" rel="noopener" href="http://wuchong.me/blog/2016/05/03/flink-internals-overview/">Flink执行拓扑结构</a></li>
</ul>
<h1 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">fuliangyu</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://fuliangyuzqm.github.io/tags/flink.html">https://fuliangyuzqm.github.io/tags/flink.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">fuliangyu</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: '9UNGkr3Dp4FiRz1sqecibL8f-gzGzoHsz',
        appKey: 'JxXPzxVqzEw4tHLe891YxU8o',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go'
    });
</script>

<!--酷Q推送-->


    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/tags/flink.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="">
                        
                        <span class="card-title"></span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-02-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            fuliangyu
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                本篇&nbsp;<i class="far fa-dot-circle"></i>
            </div>
            <div class="card">
                <a href="/tags/flink.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="">
                        
                        <span class="card-title"></span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-02-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            fuliangyu
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: fuliangyu<br />'
            + '文章作者: fuliangyu<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1,h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1,h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2021-2022</span>
            
            <a href="/about" target="_blank">fuliangyu</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">134.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2021";
                        var startMonth = "12";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://fuliangyuzqm.github.io/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1719398791@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1719398791" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1719398791" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<!-- hexo injector body_end start --><script data-pjax>function history_calendar_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>';
                console.log('已挂载history_calendar')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            history_calendar_injector_config()
        } </script><script data-pjax  src="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":300,"height":500,"hOffset":30,"vOffset":-10},"mobile":{"show":false},"react":{"opacity":1},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>
